title: 斯坦福机器学习课程 第四周 (3)神经网络应用实例
tags:
  - 算法
categories:
  - 算法
  - 机器学习
comments: true
date: 2016-09-11 19:22:00
mathjax: true
---

## 神经网络应用实例

[视频地址 part1](https://www.coursera.org/learn/machine-learning/lecture/rBZmG/examples-and-intuitions-i)

[视频地址 part2](https://www.coursera.org/learn/machine-learning/lecture/solUx/examples-and-intuitions-ii)

> 接下来将通过一个具体的例子来解释神经网络是如何计算关于输入的复杂的非线性函数的。

### 问题引入

考虑下面的问题：

我们有二进制的输入特征$x\_{1}$和$x\_{2}$，它们的取值要么是0，要么是1。这个例子中，我画出了两个正样本和两个负样本。

![](/img/16_09_11/001.png)

但你可以认为这是更复杂的学习问题的简化版本。在这个复杂问题中，我们可能在右上角有一堆正样本，在右下方有一堆用圆圈来表示的负样本。

![](/img/16_09_11/002.png)

我们想要做到的就是有一个非线性的决策边界来区分正负样本：

![](/img/16_09_11/003.png)

那么，神经网络是如何做到的呢？为了描述方便，我继续使用上面二进制输入特征的例子。

具体来讲，我们要计算的目标函数:

$$y=x\_{1} XNOR x\_{2}$$

> 求同或(都为真或都为假时，结果为真，否则结果为假)

或者也可以写作：

$$NOT(y=x\_{1} XOR x\_{2})$$

> 求异或(都为真或都为假时，结果为假，否则结果为真)再取反

### AND、OR、NOT的实现

#### AND

为了解释神经网络模型如何来拟合这种训练集。我们先讲解一个稍微简单一些的神经网络，它拟合了**“且运算”(AND)**：

![](/img/16_09_11/004.png)

假设我们有二进制输入$x\_{1}$和$x\_{2}$，目标函数是$y=x\_{1}ANDx\_{2}$，那么我们怎样得到一个具有单个神经元的神经网络来计算这个**逻辑与**呢？为了做到这一点，我们也需要画出偏置单元（即下图中+1的单元）：

![](/img/16_09_11/005.png)

接下来让我给这个网络分配一些权重(参数)：

![](/img/16_09_11/006.png)

所以我的假设函数是：

$$
h\_{Θ}(x)=g(-30 + 20x\_{1} + 20x\_{2})
$$

这里$Θ^{(1)}\_{10}$就是$-30$、$Θ^{(2)}\_{11}$就是$20$、$Θ^{(3)}\_{12}$就是$20$。

接下来介绍一下这个小神经元是怎样计算的。

回忆一下激励函数$g(z)$看起来是这样的：

![](/img/16_09_11/007.png)


再来看看我们的假设在各种情况下的输出：

|$x\_{1}$|$x\_{2}$|$h\_{Θ}(x)$|
|:-:|:-:|:-:|
|0|0|$g(-30)\approx0$|
|0|1|$g(-10)\approx0$|
|1|0|$g(-10)\approx0$|
|1|1|$g(10)\approx1$|

这就是逻辑“与”的计算结果。

---

#### OR

下面的神经网络使用同样的原理实现了“或”的功能：

![](/img/16_09_11/008.png)

假设函数为：

$$
h\_{Θ}(x)=g(-10 + 20x\_{1} + 20x\_{2})
$$

|$x\_{1}$|$x\_{2}$|$h\_{Θ}(x)$|
|:-:|:-:|:-:|
|0|0|$g(-10)\approx0$|
|0|1|$g(10)\approx1$|
|1|0|$g(10)\approx1$|
|1|1|$g(30)\approx1$|

---

#### NOT

下面的神经网络使用同样的原理实现了“非”的功能：

![](/img/16_09_11/009.png)

假设函数为：

$$
h\_{Θ}(x)=g(10 - 20x\_{1})
$$

|$x\_{1}$|$h\_{Θ}(x)$|
|:-:|:-:|
|0|$g(10)\approx1$|
|1|$g(-10)\approx0$|

### 一个更复杂的例子

下面的神经网络使用同样的原理实现了“$(NOTx\_{1})AND(NOTx\_{2})$”的功能：

![](/img/16_09_11/010.png)

假设函数为：

$$
h\_{Θ}(x)=g(10 - 20x\_{1} - 20x\_{2})
$$

|$x\_{1}$|$x\_{2}$|$h\_{Θ}(x)$|
|:-:|:-:|:-:|
|0|0|$g(10)\approx1$|
|0|1|$g(-10)\approx0$|
|1|0|$g(-10)\approx0$|
|1|1|$g(-30)\approx0$|



----

### 求解	XNOR

接下来我们使用上面求解的以下三个神经网络，就可以来运算$x\_{1}XNORx\_{2}$了：

![](/img/16_09_11/011.png)

为了拟合$x\_{1}XNORx\_{2}$的非线性的样本分布：

![](/img/16_09_11/001.png)

我们可以构建以下神经网络的隐藏层：

![](/img/16_09_11/012.png)

对应的真值表如下：

|$x\_{1}$|$x\_{2}$|$a\_{1}^{(2)}$|$a\_{2}^{(2)}$|$h\_{Θ}(x)$|
|:-:|:-:|:-:|:-:|:-:|
|0|0|**0**|**1**||
|0|1|**0**|**0**||
|1|0|**0**|**0**||
|1|1|**1**|**0**|||

有了$a\_{1}^{(2)}$、$a\_{2}^{(2)}$后，我们加入偏置单元，然后就可以得到输出层了：

![](/img/16_09_11/012.png)

最终的真值表如下：

|$x\_{1}$|$x\_{2}$|$a\_{1}^{(2)}$|$a\_{2}^{(2)}$|$h\_{Θ}(x)$|
|:-:|:-:|:-:|:-:|:-:|
|0|0|0|1|**1**|
|0|1|0|0|**0**|
|1|0|0|0|**0**|
|1|1|1|0|**1**|

通过一个含有输入层、隐藏层、输出层的神经网络，我们最终拟合了$x\_{1}XNORx\_{2}$。

> 更一般的理解是：在输入层中，我们有原始输入值，然后我们建立了一个隐藏层，用来计算稍微复杂一些的输入量的函数，然后通过添加另一个层我们得到了一个更复杂一点的函数，这就是神经网络可以计算较复杂函数的某种直观解释。
> 
> 我们知道，当层数很多的时候，你有一个相对简单的输入量的函数作为第二层，而第三层可以建立在此基础上来计算更加复杂一些的函数，然后再下一层，又可以计算再复杂一些的函数：

![](/img/16_09_11/014.png)

### 手写识别的展示

接下来，将展示一段视频，来源于**阳乐昆(Yann LeCun)**，他是一名教授，供职于纽约大学，也是神经网络研究早期的奠基者之一，也是这一领域 大牛。他的很多理论和想法现在都已经被应用于各种各样的产品和应用中，遍布全世界。所以我想向大家展示一段他早期工作中的视频，这段视频中，他使用神经网络算法进行手写数字的识别。你也许记得，这门课刚开始的时候，我说过关于神经网络的一个早期成就，就是应用神经网络读取邮政编码，以帮助我们进行邮递。那么这便是其中的一项尝试。

视频说明：

![](/img/16_09_11/015.png)

视频如下：

<iframe width="560" height="315" src="https://www.youtube.com/embed/yxuRnBEczUU" frameborder="0" allowfullscreen></iframe>

## 神经网络的多类别分类

[视频地址](https://www.coursera.org/learn/machine-learning/lecture/gFpiW/multiclass-classification)

> 这一节将介绍**如何使用神经网络做多类别分类**。
> 
> 在多类别分类中，通常有不止一个类别需要我们去区分，在上一节最后的视频中，我们提到了有关手写数字识别的问题，这实际上正是一个多类别分类的问题。因为识别数字从0到9，正好是10个类别。

我们处理多类别分类的方法实际上是基于一个**多神经网络算法**而延伸出来的。

让我们来看看下面这个例子：

还是一个有关计算机视觉识别的例子，就像我之前介绍过的识别汽车的例子一样，但与之不同的是现在我们希望处理的是四个类别的分类问题，四个类别分别是行人、轿车、摩托车、卡车：

![](/img/16_09_11/016.png)

任意给出一副图片，我们需要知道图片上是这四个类别中的哪一个。

对于这样的一个问题，我们的做法是，**建立一个具有四个输出单元的神经网络**：

![](/img/16_09_11/017.png)

也就是说，此时神经网络的输出是一个思维向量。因此现在的输出需要用一个向量来表示，这个向量中有四个元素，而我们要做的是对第一个输出元素进行分辨图片上是不是一个行人(Pedestrian)，然后对第二个元素分辨它是不是一辆轿车(Car)，对第三个元素分辨它是不是摩托车(Motorcycle)，对第四个元素分辨它是不是一辆卡车(Truck)。

因此，如果图上是行人的话，我希望输出结果是：

$$
h\_{Θ}(x)\approx
\begin{bmatrix}
1 \\\\
0 \\\\
0 \\\\
0
\end{bmatrix}
$$

如果图上是轿车的话，我希望输出结果是：

$$
h\_{Θ}(x)\approx
\begin{bmatrix}
0 \\\\
1 \\\\
0 \\\\
0
\end{bmatrix}
$$

如果图上是摩托车的话，我希望输出结果是：

$$
h\_{Θ}(x)\approx
\begin{bmatrix}
0 \\\\
0 \\\\
1 \\\\
0
\end{bmatrix}
$$

如果图上是卡车的话，我希望输出结果是：

$$
h\_{Θ}(x)\approx
\begin{bmatrix}
0 \\\\
0 \\\\
0 \\\\
1
\end{bmatrix}
$$

所以，这和我们介绍逻辑回归时讨论过的一对多方法其实是一样的，只不过现在我们有四个逻辑回归的分类器，而我们需要对每一个分类器都分别进行识别分类。

