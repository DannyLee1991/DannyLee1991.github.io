title: 关于机器学习的一些思考
tags:
  - 机器学习
categories:
  - 机器学习
comments: true
date: 2017-03-05 16:40:58
---

我大概是在两年前开始正式关注机器学习领域的，当时一心想做一个基于机器学习的五子棋程序，希望能达到机器自动理解五子棋游戏规则的效果，但没能成功，于是我开始找一些机器学习领域的课程和书籍开始啃。

当时机器学习在国内还是一个很少听到的名词，但当我学习这方面的东西的时候，我深深的感受到这个领域的东西和我之前学到的技术不是一个维度的东西，并且它将深远的影响未来的发展。直到后来AlphaGo的出现，以及Google开源了TensorFlow，这一系列的大事件的发生，悄然在业内刮起了一股人工智能风。

TensorFlow在开源之初，国内的**极客学院**发起了文档的翻译工作，还记的在其翻译文档的首页这样写到：

> 你正在阅读的项目可能会比 Android 系统更加深远地影响着世界！

不管这句话说得是否过于夸大，但TensorFlow在github上开源一个月之内就收到了10000+的star，这是github上机器学习领域也是python领域star增长最快的项目了。截止目前，TensorFlow的star为49227，已经超过了linux的42490。可见，机器学习的发展速度之迅猛，是不容小视的。

本文是我对机器学习领域的一些见解和思考，主要涉及**机器学习的定义**，**机器学习的学习方式**以及**相关概念的理解**。你会看到很多教科书上看不到的解读，虽然不是很严谨，但有助于你对一些概念建立起直觉上的理解，从而帮助你更好的了解这一领域的知识。

## 思考1：机器学习是什么

### 机器学习定义

> 机器学习(Machine Learning, ML)是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。

这是百度百科给出的定义，更加通俗的解释一下，机器学习是人工智能领域下的子领域，通过对大量现有数据的分析运算来对未知数据进行预测的一种学科。（虽然说法不严谨，但这种解释有助于理解）

将机器学习的通用模型类比于养一个小孩：

- 训练过程就像是养一个小孩子
- 如果小孩子小的时候接触到了正确的教育（这里正确的教育就是**训练数据集**）
- 如果小孩子本身的悟性很高（悟性很高类比于有很好的**学习算法**）
- 那么这个孩子经过一段时间的成长学习后（类比于机器学习的**训练**阶段）
- 会成为一个有用之才（得到和很好的**假设函数**，即训练模型）
- 当他遇到新的人和事的时候（接受**测试数据**）
- 就能够处理的很好（**预测结果**）

这就是机器学习的通用模型，虽然不是严谨的学术定义，但相信这能使你建立一种直觉上的认识。

### 这是一项新技术吗？

机器学习目前处于学术界迈向工业界的一个过程，其核心算法几十年前就有了，理念也绝非新鲜事物，达到工业级别是一个时间问题，而现在**我们就处在这一学术界迈向工业界的关键阶段**。

其实，机器学习的核心概念早在第一台计算机制造之前就已经产生了。这里也不做过多介绍，大家可以自行去搜索。

## 思考2：如何学习机器学习

### 学习框架 or 学习算法?

完全没有学过这一领域的东西，是否应该直接上手TensorFlow之类的框架呢？

框架只是工具，不管是TensorFlow还是Caffe还是Torch，都是对算法的封装，很多之前做其他方面开发的程序员，在接触一个框架或者工具时，都倾向于追求能达到“直接去调用一下就得到结果”这样的效果，但机器学习领域的框架并不是如此，它要求你对机器学习领域的算法有一定了解，要明白自己在做什么。

所以先对这个领域的算法知识有个掌握之后，再去学习和使用框架来实践操作可能是效率更高的一种学习模式。相反，直接上手来学习框架，期望直接调用一些API就得出结果的想法会让你有种寸步难行的感觉。

这里安利一下[coursera](https://www.coursera.org/)上的吴恩达老师的[机器学习](https://www.coursera.org/learn/machine-learning)课程（可能会需要翻墙才能访问，自行购买vpn）。这门课深入浅出的讲解了机器学习领域的流行的算法的实现原理。

> 介绍一下吴恩达老师，在最强大脑第四季开播之前，可能知道他的人很少。吴恩达是华裔美国人，是斯坦福大学计算机科学系和电子工程系副教授，人工智能实验室主任，是Coursera的联合创始人。之前是google负责google大脑项目，后来在14年5月16日加入百度，担任百度首席科学家，负责百度研究院的领导工作，尤其是Baidu Brain计划。这是中国互联网公司迄今为止引进的最重量级人物。

### 深入底层 or 关注上层？

在技术领域一直流传着这样一种理念：底层的就是牛X的。上层技术变化无常，但底层技术万变不离其宗。再加上底层技术的学习成本远高于上层技术，而且吃透了底层技术能够对上层技术有更深刻的理解，导致程序员对底层技术有一种神圣的向往情节。

技术领域，专注细节不是坏事，但对于机器学习这个领域呢？恐怕我们需要重新考量一下这种思维模式了。

其实在机器学习领域，也是提倡对底层实现算法有一定的了解的，但并不代表我们要去亲自实现一些算法，比如神经网络中的反向传播算法的实现，很多框架都已经写的很完善了，而且都是数值计算领域的专家来实现的高质量高性能的代码，我们没必要花时间和精力来重新造轮子，也没必要去研究他们是如何造的这个轮子。我们更应该把宝贵的时间留在理解这些算法的原理上，以及学会使用这些算法来应用到实际中的问题，这才是把好钢用到了刀刃上。

实际上，正确的学习方式是，首先学习并理解算法原理，在直觉层面建立起对算法的认识，然后快速动手实践，将学到的算法应用到小项目里，不用太过在意写的东西是不是很挫，重要的是开始写！然后再不断的完善你的项目。带着一些问题去继续学习，你会有更多的收获。

### 不要想太多有的没的

可能很多人跟我一样，刚开始了解这一领域的东西的时候，很是兴奋，感觉造出一个通用人工智能指日可待了。再加上近些年随着人工智能概念的兴起，出来了一批相关影视作品和科幻小说，更让我们对人工智能产生了一系列不切实际的想法。

对于这一点，我想说明的是，不要过分执迷于AI能创建出智能大脑的想法，除非你是业内出类拔萃的专家。科幻小说与电影只是一种艺术表现手法，并不代表着未来。通常，人们看不懂看不透的地方就容易形成骗局，通用智能虽然是人工智能一直以来在追求的一个目标，但目前主流学术发展方向并没有朝着这方面走。机器学习、深度学习的确在飞速的进步，未来也会波及到很多行业，但这个学科归根结底还是一门基于数据的学科，并没有达到拥有情感、独立思考等这方面的能力，实际上，绝大多数业内专家对这方面的想法是持有厌恶态度的，倒是相关的社科类软文在这个时代被吹上了天。

因此，与其花时间想这些有的没的，还不如花时间脚踏实地的去学习一下算法、写写代码，除非你想成为一个科幻小说作家。

## 思考3：机器学习中一些概念的解读

机器学习领域中有很多很有趣、很耐人寻味的原理值得细细品味，下面是我对其中部分概念的直觉上的理解，可能你在教科书或者教学视频上看不到这种解读，但这些概念所折射出来的现象也许就是我所描述的那样。当然，如果你没有看过这个领域，甚至没有写过代码也没关系，我保证能让你能读得懂。

### 神经网络

**神经网络**是机器学习领域出镜率很高的一个词汇，很多人对它的理解一直是停留在“**很牛X，很复杂**”的状态。下面用一个例子来解释神经网络的使用原理：

假设你有一个下周六是否要去电影院看电影的决定。这个决定的结果无非只有两种：**去**或者**不去**。

影响你去或不去的因素有很多：

- 是否有人陪
- 是否有想看的电影
- 是否有时间
- 天气是否足够好
- ...

我相信你可以列出足够多的理由来拒绝周末去看电影，但为了方便描述起见，我们先用三个条件：**是否有人陪**、**是否有想看的电影**、**是否有时间**。

好，现在我们来用三个圈来表示这三个条件。

![](/img/17_03_05/002.png)

圆圈中间的数值代表对做出去看电影的决策的影响程度，可以看到这里**是否有时间**的影响程度是最大的（这里的每个小圈，其实就是神经网络中的**神经元**，上面的数值就是**权值**）。

我们接下来把我们的神经网络补充完整：

![](/img/17_03_05/003.png)

我们又加了两个圈和一些箭头。好，对应图中，如果我们现在**有想看的电影，可是没有人陪，但有时间**，那么我们的计算方式就是:

![](/img/17_03_05/004.png)

$$
(-1)×0.3 + 1×0.6 + 1×1.0 = 1.3 
$$

输出结果是一个大于0的值：1.3，代表我们会做出去看电影的决定。

类似的，假如我们**有人陪，有想看的电影，但是没时间**：

$$
1×0.3 + 1×0.6 + (-1)×1.0 = -0.1
$$

是一个负数，代表我们不会去看电影。

这就是一个训练好的神经网络的使用方式，这幅图就是一个典型的三层神经网络，从左到右依次是**输出层**、**隐藏层**、**输出层**，其中0.3，0.6，1.0是通过**训练**得出的**权值**。

![](/img/17_03_05/005.png)

我相信你对神经网络还是有很多疑问，比如0.3，0.6和1.0是怎么得来的（实际上是通过**反向传播算法**得来的），但神经网络运作的大体模式就是这样，希望你能对它产生一种宏观层面的认识。

### 偏拟合 和 过拟合

**偏拟合**和**过拟合**具体是什么意思呢？不要被陌生的名词吓到。

首先要说明的是，这两个词都不是褒义词，都是我们不想看到的一种状态。

其实所谓**偏拟合**就是相当于某一领域经验不足的人，由于经历的事情太少，容易做出一些错误的判断，这种现象就是**偏拟合**。

所谓**过拟合**，恰恰相反，是指某一领域经验非常丰富的人，由于经历的事情太多，反而容易对新的事物产生偏见（因为既往的经验会告诉他这是不对的），从而产生错误的决定。

教科书上不会这么解释**偏拟合**和**过拟合**的概念，但事实上这个概念描述的就是这样的现象。是不是我们身边随处可见这两种现象呢？

### 查准率 和 召回率

假设我们现在写了个用于预测病人是否患有肺癌的程序，我们出入了100个病人的体征数据，然后来告知这一批病人有谁不幸得了肺癌。

假设我们的预测准确率为98%，这个结果乍一看是不是很高呢？但我告诉你另一个事实，那就是我们只有两个病人是真正患有肺癌的，然而我们的算法正确的识别了两者中的一位，并且还错误的认为在98名没有患有肺癌的患者里有一位癌症患者。那这还是一个好结果吗？

很明显，100个人里只有两个人患有癌症，其中一个还预测错误，这是一个很差的结果，但我们的准确率为98%，因为我们预测对了100个人中的98个人，所以从准确率上来看并不差，但实际结果却很差。

这就是典型的**偏斜类**问题。

也许有人会说，这表明了数据会说谎，但实际情况是，数据并没有说谎，只不过我们看待数据的方式不够科学。

科学的方式就是引入**查准率**和**召回率**。

在这里:

$$
查准率 = \frac{在预测患有肺癌的病人中，预测正确的数量} {预测患有肺癌的病人数量}
$$

$$
召回率 = \frac{在预测患有肺癌的病人中，预测正确的数量} {实际患有肺癌病人的数量}
$$

可见，**查准率**和**召回率**都是越高越好的。

那么我们的例子中**查准率**和**召回率**的真实值分别为：

$$
查准率 = \frac{在预测患有肺癌的病人中，预测正确的数量} {预测患有肺癌的病人数量} = \frac{1} {2} = 0.5
$$

$$
召回率 = \frac{在预测患有肺癌的病人中，预测正确的数量} {实际患有肺癌病人的数量} = \frac{1} {2} = 0.5
$$

我们的查准率和召回率都很低。所以换个角度来看待数据，会有新的发现。

查准率和召回率是两个维度的数据，有的时候我们为了追求高查准率，会得到一个低召回率的结果；有的时候我们为了追求高召回率，却会得到一个低查准率的结果。这种顾此失彼的状态，也不是我们想要。

所以我们引入了一个叫做**Fscore**的方法来对两种进行一个整体的衡量，其表达式为：

$$
Fscore = \frac{查准率×召回率} {查准率+召回率}
$$

这里我们的$Fscore=0.25$。

我们生活中也处处充满着**准确率高但查准率和召回率低的例子**：

我们往往会有这种体验，一些成功的名人说的话似乎都很有道理，但其实他们说的有道理的话似乎都比较“大”；而有些人，专注于某一特定领域的专家，在发表一些观点的时候，用词都非常谨慎，因为他们在描述一件具体的事物。

所以，我们会发现，**越“大”的话，越容易获得较高的准确率；越“专”的话，越不容易获得较高的准确率**。

所以带着这种角度，我们去审视一下：

- 失败是成功之母。
- 天才是99%的汗水加1%的灵感。
- ...

类似这类的**鸡汤名言**，我们会有新的思考。我们会发现，真正的牛人说的话，不仅仅准确率高，而且查准率和召回率也很高。

### 无监督学习

**无监督学习**是相对于**监督学习**而言的。那么什么是**监督学习**呢？

**监督学习**通俗的将就是我们告诉机器一堆格式为：

**bulabulabula的东西，是xxx**

来预测未知类别的数据：

**bulabulabula的东西，是？**

例如通过体征来预测性别：

已有100个数据：

- 身高175cm，短发，70kg的人是男性
- 身高165cm，长发，48kg的人是女性
- ...

那么：

- 身高170cm，长发，55kg的人是？

这种预测类别已知的机器学习，就是**监督学习**。典型的**监督学习**的案例有**语音识别**、**图像识别**、**人脸识别**等等。

所谓**无监督学习**就是我们并不能知道数据所属的类别，通过算法使数据自动地按照相似的类别聚合起来，即所谓的**聚类算法**。

我们俗话所说的**物以类聚，人以群分**就是无监督学习的体现。

其实，仔细想想，人类社会的发展演化过程，是不是就是一个大型的**无监督学习**的过程呢？我们都是这个学习过程中的一环，是这个大型的神经网络中的一个神经元，我们社会的发展形态和目标在各个阶段都是不一样的，即使我们无法过远地预测到未来进化的方向，但我们一直在自我学习的过程中不断进化。也许这正是生命的本质。

----

以上观点可能不是很严谨，也不是正统的机器学习理论，是本人对机器学习的一些思考。如有概念上的错误，欢迎斧正。也欢迎在评论区和我一起讨论**机器学习**的相关问题。

非常感谢您能读完我的文章，最后安利一下我的一个实验项目[智能背词算法](http://118.190.96.169:3389/iw/help/)，目前处于数据采集阶段，具体使用方式见帮助页面。谢谢~