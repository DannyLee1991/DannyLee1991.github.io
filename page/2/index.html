<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="愿你的努力终取得成果">
<meta property="og:type" content="website">
<meta property="og:title" content="圣巢">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="圣巢">
<meta property="og:description" content="愿你的努力终取得成果">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="DannyLee">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>圣巢</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">圣巢</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/03/09/%E3%80%90%E7%BF%BB%E8%AF%91%E3%80%91kaggle%E7%AB%9E%E8%B5%9B%20%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="DannyLee">
      <meta itemprop="description" content="愿你的努力终取得成果">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="圣巢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/03/09/%E3%80%90%E7%BF%BB%E8%AF%91%E3%80%91kaggle%E7%AB%9E%E8%B5%9B%20%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/" class="post-title-link" itemprop="url">【翻译】kaggle竞赛 房价预测</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-03-09 22:08:55" itemprop="dateCreated datePublished" datetime="2018-03-09T22:08:55+00:00">2018-03-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-10 17:00:48" itemprop="dateModified" datetime="2021-02-10T17:00:48+00:00">2021-02-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a target="_blank" rel="noopener" href="https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python">原文链接</a></p>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>如果你有一些R或者Python的经验，并且掌握一些基本的机器学习知识。对于完成机器学习在线课程的数据科学学生来说，这是一个很适合练手的比赛。</p>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>如果让一个想要买房的人来描述他们梦想中的住宅，他们可能不会从地下室天花板的高度或与东西方地铁的距离开始描述。但是这个游乐场比赛的数据集证明，购房者考虑的主要因素中，对价格谈判的影响远远超过卧室或白色栅栏的数量的影响。</p>
<p>有79个解释变量描述（几乎）爱荷华州埃姆斯的住宅房屋的每个方面，这个竞赛的目标是需要你来预测每个房屋的最终价格。</p>
<h3 id="实践技能"><a href="#实践技能" class="headerlink" title="实践技能"></a>实践技能</h3><ul>
<li>创意特征工程</li>
<li>先进的回归算法技术，如随机森林和梯度提升</li>
</ul>
<h3 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h3><p><a target="_blank" rel="noopener" href="http://www.amstat.org/publications/jse/v19n3/decock.pdf">Ames Housing数据集</a>由Dean De Cock编制，用于数据科学教育。对于那些寻找比Boston Housing数据集更现代化的扩展版本数据集的数据科学家来说，这的确是一个很赞的选择。</p>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><h3 id="文件描述"><a href="#文件描述" class="headerlink" title="文件描述"></a>文件描述</h3><ul>
<li>train.csv - 训练集</li>
<li>test.csv - 测试集</li>
<li>data_description.txt - 记录了每个特征的完整描述信息，最初由Dean De Cock编写，后来做了略微的改动</li>
<li>sample_submission.csv - 来自销售年份和月份的线性回归的基准提交，批量平方英尺和卧室数量（a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms）</li>
</ul>
<h3 id="字段信息"><a href="#字段信息" class="headerlink" title="字段信息"></a>字段信息</h3><p>以下是您可以在数据描述文件中找到的简要版本。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">字段名</th>
<th style="text-align:left">英文解释</th>
<th style="text-align:left">中文解释</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">SalePrice</td>
<td style="text-align:left">the property’s sale price in dollars. This is the target variable that you’re trying to predict.</td>
<td style="text-align:left">房屋的销售价格以美元计价。这是你试图预测的目标变量。</td>
</tr>
<tr>
<td style="text-align:center">MSSubClass</td>
<td style="text-align:left">The building class</td>
<td style="text-align:left">建筑类</td>
</tr>
<tr>
<td style="text-align:center">MSZoning</td>
<td style="text-align:left">The general zoning classification</td>
<td style="text-align:left">一般分区分类</td>
</tr>
<tr>
<td style="text-align:center">LotFrontage</td>
<td style="text-align:left">Linear feet of street connected to property</td>
<td style="text-align:left">连接到财产的街道的线性脚</td>
</tr>
<tr>
<td style="text-align:center">LotArea</td>
<td style="text-align:left">Lot size in square feet</td>
<td style="text-align:left">地块面积（平方英尺）</td>
</tr>
<tr>
<td style="text-align:center">Street</td>
<td style="text-align:left">Type of road access</td>
<td style="text-align:left">道路通行类型</td>
</tr>
<tr>
<td style="text-align:center">Alley</td>
<td style="text-align:left">Type of alley access</td>
<td style="text-align:left">胡同通道的类型</td>
</tr>
<tr>
<td style="text-align:center">LotShape</td>
<td style="text-align:left">General shape of property</td>
<td style="text-align:left">财产的一般形状</td>
</tr>
<tr>
<td style="text-align:center">LandContour</td>
<td style="text-align:left">Flatness of the property</td>
<td style="text-align:left">物业的平整度</td>
</tr>
<tr>
<td style="text-align:center">Utilities</td>
<td style="text-align:left">Type of utilities available</td>
<td style="text-align:left">可用的实用程序类型</td>
</tr>
<tr>
<td style="text-align:center">LotConfig</td>
<td style="text-align:left">Lot configuration</td>
<td style="text-align:left">批量配置</td>
</tr>
<tr>
<td style="text-align:center">LandSlope</td>
<td style="text-align:left">Slope of property</td>
<td style="text-align:left">财产的倾斜</td>
</tr>
<tr>
<td style="text-align:center">Neighborhood</td>
<td style="text-align:left">Physical locations within Ames city limits</td>
<td style="text-align:left">Ames城市限制内的物理位置</td>
</tr>
<tr>
<td style="text-align:center">Condition1</td>
<td style="text-align:left">Proximity to main road or railroad</td>
<td style="text-align:left">靠近主干道或铁路</td>
</tr>
<tr>
<td style="text-align:center">Condition2</td>
<td style="text-align:left">Proximity to main road or railroad (if a second is present)</td>
<td style="text-align:left">靠近主要道路或铁路（如果存在第二个）</td>
</tr>
<tr>
<td style="text-align:center">BldgType</td>
<td style="text-align:left">Type of dwelling</td>
<td style="text-align:left">住宅类型</td>
</tr>
<tr>
<td style="text-align:center">HouseStyle</td>
<td style="text-align:left">Style of dwelling</td>
<td style="text-align:left">住宅风格</td>
</tr>
<tr>
<td style="text-align:center">OverallQual</td>
<td style="text-align:left">Overall material and finish quality</td>
<td style="text-align:left">总体材料和加工质量</td>
</tr>
<tr>
<td style="text-align:center">OverallCond</td>
<td style="text-align:left">Overall condition rating</td>
<td style="text-align:left">总体状况的评价</td>
</tr>
<tr>
<td style="text-align:center">YearBuilt</td>
<td style="text-align:left">Original construction date</td>
<td style="text-align:left">原始施工日期</td>
</tr>
<tr>
<td style="text-align:center">YearRemodAdd</td>
<td style="text-align:left">Remodel date</td>
<td style="text-align:left">重构日期</td>
</tr>
<tr>
<td style="text-align:center">RoofStyle</td>
<td style="text-align:left">Type of roof</td>
<td style="text-align:left">屋顶类型</td>
</tr>
<tr>
<td style="text-align:center">RoofMatl</td>
<td style="text-align:left">Roof material</td>
<td style="text-align:left">屋顶材料</td>
</tr>
<tr>
<td style="text-align:center">Exterior1st</td>
<td style="text-align:left">Exterior covering on house</td>
<td style="text-align:left">房屋外墙</td>
</tr>
<tr>
<td style="text-align:center">Exterior2nd</td>
<td style="text-align:left">Exterior covering on house (if more than one material)</td>
<td style="text-align:left">房屋外墙（如果多于一种）</td>
</tr>
<tr>
<td style="text-align:center">MasVnrType</td>
<td style="text-align:left">Masonry veneer type</td>
<td style="text-align:left">Masonry贴面类型</td>
</tr>
<tr>
<td style="text-align:center">MasVnrArea</td>
<td style="text-align:left">Masonry veneer area in square feet</td>
<td style="text-align:left">砖石面积平方英尺</td>
</tr>
<tr>
<td style="text-align:center">ExterQual</td>
<td style="text-align:left">Exterior material quality</td>
<td style="text-align:left">外部材料质量</td>
</tr>
<tr>
<td style="text-align:center">ExterCond</td>
<td style="text-align:left">Present condition of the material on the exterior</td>
<td style="text-align:left">外部材料的现状</td>
</tr>
<tr>
<td style="text-align:center">Foundation</td>
<td style="text-align:left">Type of foundation</td>
<td style="text-align:left">基础类型</td>
</tr>
<tr>
<td style="text-align:center">BsmtQual</td>
<td style="text-align:left">Height of the basement</td>
<td style="text-align:left">地下室的高度</td>
</tr>
<tr>
<td style="text-align:center">BsmtCond</td>
<td style="text-align:left">General condition of the basement</td>
<td style="text-align:left">地下室的一般状况</td>
</tr>
<tr>
<td style="text-align:center">BsmtExposure</td>
<td style="text-align:left">Walkout or garden level basement walls</td>
<td style="text-align:left">罢工或花园级地下室的墙壁</td>
</tr>
<tr>
<td style="text-align:center">BsmtFinType1</td>
<td style="text-align:left">Quality of basement finished area</td>
<td style="text-align:left">地下室成品面积质量</td>
</tr>
<tr>
<td style="text-align:center">BsmtFinSF1</td>
<td style="text-align:left">Type 1 finished square feet</td>
<td style="text-align:left">1型方形脚</td>
</tr>
<tr>
<td style="text-align:center">BsmtFinType2</td>
<td style="text-align:left">Quality of second finished area (if present)</td>
<td style="text-align:left">第二个完成区域的质量（如果存在）</td>
</tr>
<tr>
<td style="text-align:center">BsmtFinSF2</td>
<td style="text-align:left">Type 2 finished square feet</td>
<td style="text-align:left">2型完成的平方英尺</td>
</tr>
<tr>
<td style="text-align:center">BsmtUnfSF</td>
<td style="text-align:left">Unfinished square feet of basement area</td>
<td style="text-align:left">未完成的地下室面积</td>
</tr>
<tr>
<td style="text-align:center">TotalBsmtSF</td>
<td style="text-align:left">Total square feet of basement area</td>
<td style="text-align:left">地下室面积的平方英尺</td>
</tr>
<tr>
<td style="text-align:center">Heating</td>
<td style="text-align:left">Type of heating</td>
<td style="text-align:left">加热类型</td>
</tr>
<tr>
<td style="text-align:center">HeatingQC</td>
<td style="text-align:left">Heating quality and condition</td>
<td style="text-align:left">供热质量和条件</td>
</tr>
<tr>
<td style="text-align:center">CentralAir</td>
<td style="text-align:left">Central air conditioning</td>
<td style="text-align:left">中央空调</td>
</tr>
<tr>
<td style="text-align:center">Electrical</td>
<td style="text-align:left">Electrical system</td>
<td style="text-align:left">电气系统</td>
</tr>
<tr>
<td style="text-align:center">1stFlrSF</td>
<td style="text-align:left">First Floor square feet</td>
<td style="text-align:left">一楼平方英尺</td>
</tr>
<tr>
<td style="text-align:center">2ndFlrSF</td>
<td style="text-align:left">Second floor square feet</td>
<td style="text-align:left">二楼平方英尺</td>
</tr>
<tr>
<td style="text-align:center">LowQualFinSF</td>
<td style="text-align:left">Low quality finished square feet (all floors)</td>
<td style="text-align:left">低质量成品平方英尺（所有楼层）</td>
</tr>
<tr>
<td style="text-align:center">GrLivArea</td>
<td style="text-align:left">Above grade (ground) living area square feet</td>
<td style="text-align:left">以上（地面）生活区平方英尺</td>
</tr>
<tr>
<td style="text-align:center">BsmtFullBath</td>
<td style="text-align:left">Basement full bathrooms</td>
<td style="text-align:left">地下室完整的浴室</td>
</tr>
<tr>
<td style="text-align:center">BsmtHalfBath</td>
<td style="text-align:left">Basement half bathrooms</td>
<td style="text-align:left">地下室半浴室</td>
</tr>
<tr>
<td style="text-align:center">FullBath</td>
<td style="text-align:left">Full bathrooms above grade</td>
<td style="text-align:left">全年以上的浴室</td>
</tr>
<tr>
<td style="text-align:center">HalfBath</td>
<td style="text-align:left">Half baths above grade</td>
<td style="text-align:left">半浴半高</td>
</tr>
<tr>
<td style="text-align:center">Bedroom</td>
<td style="text-align:left">Number of bedrooms above basement level</td>
<td style="text-align:left">地下室数量</td>
</tr>
<tr>
<td style="text-align:center">Kitchen</td>
<td style="text-align:left">Number of kitchens</td>
<td style="text-align:left">厨房数量</td>
</tr>
<tr>
<td style="text-align:center">KitchenQual</td>
<td style="text-align:left">Kitchen quality</td>
<td style="text-align:left">厨房质量</td>
</tr>
<tr>
<td style="text-align:center">TotRmsAbvGrd</td>
<td style="text-align:left">Total rooms above grade (does not include bathrooms)</td>
<td style="text-align:left">房间总数（不含浴室）</td>
</tr>
<tr>
<td style="text-align:center">Functional</td>
<td style="text-align:left">Home functionality rating</td>
<td style="text-align:left">家庭功能评级</td>
</tr>
<tr>
<td style="text-align:center">Fireplaces</td>
<td style="text-align:left">Number of fireplaces</td>
<td style="text-align:left">壁炉数量</td>
</tr>
<tr>
<td style="text-align:center">FireplaceQu</td>
<td style="text-align:left">Fireplace quality</td>
<td style="text-align:left">壁炉质量</td>
</tr>
<tr>
<td style="text-align:center">GarageType</td>
<td style="text-align:left">Garage location</td>
<td style="text-align:left">车库位置</td>
</tr>
<tr>
<td style="text-align:center">GarageYrBlt</td>
<td style="text-align:left">Year garage was built</td>
<td style="text-align:left">年建车库</td>
</tr>
<tr>
<td style="text-align:center">GarageFinish</td>
<td style="text-align:left">Interior finish of the garage</td>
<td style="text-align:left">车库内部装修</td>
</tr>
<tr>
<td style="text-align:center">GarageCars</td>
<td style="text-align:left">Size of garage in car capacity</td>
<td style="text-align:left">车库的车库容量</td>
</tr>
<tr>
<td style="text-align:center">GarageArea</td>
<td style="text-align:left">Size of garage in square feet</td>
<td style="text-align:left">平方英尺车库大小</td>
</tr>
<tr>
<td style="text-align:center">GarageQual</td>
<td style="text-align:left">Garage quality</td>
<td style="text-align:left">车库质量</td>
</tr>
<tr>
<td style="text-align:center">GarageCond</td>
<td style="text-align:left">Garage condition</td>
<td style="text-align:left">车库条件</td>
</tr>
<tr>
<td style="text-align:center">PavedDrive</td>
<td style="text-align:left">Paved driveway</td>
<td style="text-align:left">铺设的车道</td>
</tr>
<tr>
<td style="text-align:center">WoodDeckSF</td>
<td style="text-align:left">Wood deck area in square feet</td>
<td style="text-align:left">木甲板面积平方英尺</td>
</tr>
<tr>
<td style="text-align:center">OpenPorchSF</td>
<td style="text-align:left">Open porch area in square feet</td>
<td style="text-align:left">平方英尺开放门廊</td>
</tr>
<tr>
<td style="text-align:center">EnclosedPorch</td>
<td style="text-align:left">Enclosed porch area in square feet</td>
<td style="text-align:left">封闭的门廊面积平方英尺</td>
</tr>
<tr>
<td style="text-align:center">3SsnPorch</td>
<td style="text-align:left">Three season porch area in square feet</td>
<td style="text-align:left">三季门廊面积平方英尺</td>
</tr>
<tr>
<td style="text-align:center">ScreenPorch</td>
<td style="text-align:left">Screen porch area in square feet</td>
<td style="text-align:left">屏幕门廊面积平方英尺</td>
</tr>
<tr>
<td style="text-align:center">PoolArea</td>
<td style="text-align:left">Pool area in square feet</td>
<td style="text-align:left">游泳池面积平方英尺</td>
</tr>
<tr>
<td style="text-align:center">PoolQC</td>
<td style="text-align:left">Pool quality</td>
<td style="text-align:left">游泳池质量</td>
</tr>
<tr>
<td style="text-align:center">Fence</td>
<td style="text-align:left">Fence quality</td>
<td style="text-align:left">栅栏质量</td>
</tr>
<tr>
<td style="text-align:center">MiscFeature</td>
<td style="text-align:left">Miscellaneous feature not covered in other categories</td>
<td style="text-align:left">其他类别未涉及的其他功能</td>
</tr>
<tr>
<td style="text-align:center">MiscVal</td>
<td style="text-align:left">$Value of miscellaneous feature</td>
<td style="text-align:left">$杂项功能的值</td>
</tr>
<tr>
<td style="text-align:center">MoSold</td>
<td style="text-align:left">Month Sold</td>
<td style="text-align:left">月销售</td>
</tr>
<tr>
<td style="text-align:center">YrSold</td>
<td style="text-align:left">Year Sold</td>
<td style="text-align:left">年销售</td>
</tr>
<tr>
<td style="text-align:center">SaleType</td>
<td style="text-align:left">Type of sale</td>
<td style="text-align:left">销售类型</td>
</tr>
<tr>
<td style="text-align:center">SaleCondition</td>
<td style="text-align:left">Condition of sale</td>
<td style="text-align:left">销售条件</td>
</tr>
</tbody>
</table>
</div>
<h2 id="用Python进行全面的数据探索"><a href="#用Python进行全面的数据探索" class="headerlink" title="用Python进行全面的数据探索"></a>用Python进行全面的数据探索</h2><blockquote>
<p>Pedro Marcelino 创建</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python">link</a></p>
<p><strong>‘The most difficult thing in life is to know yourself’</strong></p>
<p>这句话引用自古希腊米利都的Thales。Thales是希腊/印第安哲学家，数学家和天文学家，被公认为西方文明中第一位享有娱乐和参与科学思想的人（来源：<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Thales">https://en.wikipedia.org/wiki/Thales</a>）。</p>
<p>我不会说了解数据是数据科学中最困难的事情，但这的确是一件非常耗时的事情。很多人可能会忽略这一步骤，就直接下水了。</p>
<p>所以我试着在下水之前先学会游泳。基于Hair等人（2013）整理的’Examining your data’一章中，我尽我所能对数据进行全面而非详尽的分析。我没有在这个内核中上报严谨的研究过程，但我希望它对社区有所帮助，所以我分享了我如何将这些数据分析原理应用于这个问题的思路。</p>
<p>尽管我给这些章写了一些奇怪的名字，但我们在这个内核中所做的是：</p>
<ul>
<li>1.<strong>理解问题</strong>：我们将研究每个变量，并对这个问题的意义和重要性进行哲学分析。</li>
<li>2.<strong>单变量研究</strong>：我们只关注因变量（’SalePrice’）并尝试更多地了解它。</li>
<li>3.<strong>多变量研究</strong>：我们将尝试了解因变量和自变量之间的关系。</li>
<li>4.<strong>基本的清理工作</strong>：我们将清理数据集并处理缺失的数据，异常值和分类变量。</li>
<li>5.<strong>测试假设</strong>：我们将检查我们的数据是否符合大多数多元技术所需的假设。</li>
</ul>
<p>现在，让我们好好玩吧！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 邀请人们来参加Kaggle聚会</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入数据</span></span><br><span class="line">df_train = pd.read_csv(<span class="string">&#x27;../input/train.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查描述信息</span></span><br><span class="line">df_train.columns</span><br></pre></td></tr></table></figure>
<p>输出结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Index([&#39;Id&#39;, &#39;MSSubClass&#39;, &#39;MSZoning&#39;, &#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;Street&#39;,</span><br><span class="line">       &#39;Alley&#39;, &#39;LotShape&#39;, &#39;LandContour&#39;, &#39;Utilities&#39;, &#39;LotConfig&#39;,</span><br><span class="line">       &#39;LandSlope&#39;, &#39;Neighborhood&#39;, &#39;Condition1&#39;, &#39;Condition2&#39;, &#39;BldgType&#39;,</span><br><span class="line">       &#39;HouseStyle&#39;, &#39;OverallQual&#39;, &#39;OverallCond&#39;, &#39;YearBuilt&#39;, &#39;YearRemodAdd&#39;,</span><br><span class="line">       &#39;RoofStyle&#39;, &#39;RoofMatl&#39;, &#39;Exterior1st&#39;, &#39;Exterior2nd&#39;, &#39;MasVnrType&#39;,</span><br><span class="line">       &#39;MasVnrArea&#39;, &#39;ExterQual&#39;, &#39;ExterCond&#39;, &#39;Foundation&#39;, &#39;BsmtQual&#39;,</span><br><span class="line">       &#39;BsmtCond&#39;, &#39;BsmtExposure&#39;, &#39;BsmtFinType1&#39;, &#39;BsmtFinSF1&#39;,</span><br><span class="line">       &#39;BsmtFinType2&#39;, &#39;BsmtFinSF2&#39;, &#39;BsmtUnfSF&#39;, &#39;TotalBsmtSF&#39;, &#39;Heating&#39;,</span><br><span class="line">       &#39;HeatingQC&#39;, &#39;CentralAir&#39;, &#39;Electrical&#39;, &#39;1stFlrSF&#39;, &#39;2ndFlrSF&#39;,</span><br><span class="line">       &#39;LowQualFinSF&#39;, &#39;GrLivArea&#39;, &#39;BsmtFullBath&#39;, &#39;BsmtHalfBath&#39;, &#39;FullBath&#39;,</span><br><span class="line">       &#39;HalfBath&#39;, &#39;BedroomAbvGr&#39;, &#39;KitchenAbvGr&#39;, &#39;KitchenQual&#39;,</span><br><span class="line">       &#39;TotRmsAbvGrd&#39;, &#39;Functional&#39;, &#39;Fireplaces&#39;, &#39;FireplaceQu&#39;, &#39;GarageType&#39;,</span><br><span class="line">       &#39;GarageYrBlt&#39;, &#39;GarageFinish&#39;, &#39;GarageCars&#39;, &#39;GarageArea&#39;, &#39;GarageQual&#39;,</span><br><span class="line">       &#39;GarageCond&#39;, &#39;PavedDrive&#39;, &#39;WoodDeckSF&#39;, &#39;OpenPorchSF&#39;,</span><br><span class="line">       &#39;EnclosedPorch&#39;, &#39;3SsnPorch&#39;, &#39;ScreenPorch&#39;, &#39;PoolArea&#39;, &#39;PoolQC&#39;,</span><br><span class="line">       &#39;Fence&#39;, &#39;MiscFeature&#39;, &#39;MiscVal&#39;, &#39;MoSold&#39;, &#39;YrSold&#39;, &#39;SaleType&#39;,</span><br><span class="line">       &#39;SaleCondition&#39;, &#39;SalePrice&#39;],</span><br><span class="line">      dtype&#x3D;&#39;object&#39;)</span><br></pre></td></tr></table></figure>
<h3 id="1-那么，我们能得到什么呢？"><a href="#1-那么，我们能得到什么呢？" class="headerlink" title="1.那么，我们能得到什么呢？"></a>1.那么，我们能得到什么呢？</h3><p>为了理解我们的数据，我们可以看看每个变量，并试图理解它们的含义以及与这个问题的相关性。我知道这个工作很耗时，但它会给我们数据集增添一些味道。</p>
<p>为了在我们的分析中掌握一些规则，我们可以创建一个Excel电子表格，其中包含以下列：</p>
<ul>
<li><strong>变量名</strong> - 变量名称。</li>
<li><strong>类型</strong> - 识别变量的类型。该字段有两种可能的值：’数值型’或’类别型’。“数值型”是指值为数字的变量，而“类别型”是指值为类别的变量。</li>
<li><strong>细分</strong> - 识别变量的细分。我们可以定义三个可能的部分：building，space或location。当我们说“building”时，我们是指与建筑物的物理特性相关的变量（例如’OverallQual’&lt;总体材料和加工质量&gt;）。当我们说“space”时，我们是指报告房屋空间属性的变量（例如’TotalBsmtSF’&lt;地下室面积的平方英尺&gt;）。最后，当我们说’location’时，我们说的是指能提供有关房屋所在地的信息（例如’Neighborhood’<Ames城市限制内的物理位置>）的变量。</li>
<li><strong>期望</strong> - 我们对’SalePrice’中的可变影响力的期望。我们可以使用“高”，“中”和“低”作为可能值的分类比例。</li>
<li><strong>结论</strong> - 在我们快速查看数据后，可以得出关于变量重要性的结论。我们可以保持与“期望”相同的分类尺度。</li>
<li><strong>评论</strong> - 我们手动赋予的通用评论信息。</li>
</ul>
<p>虽然“类型”和“细分”仅供以后使用参考，但“期望”一栏非常重要，因为它有助于我们发展我们的“第六感”。为了填补这个专栏，我们应该阅读所有变量的描述，并逐个问自己：</p>
<ul>
<li>当我们买房子时，我们是否考虑这个变量？（例如，当我们想到梦想中的房子时，我们是否在意它的’砌体贴面类型’？）</li>
<li>如果是这样，这个变量有多重要？（例如，外部材料这个属性的影响到底是“非常大”还是“非常小”，或者是“一般”呢）？</li>
<li>这些信息是否已在任何其他变量中描述过？（例如，如果’LandContour’&lt;物业的平整度&gt;给出了房产的平坦性，我们是否真的需要知道’LandSlope’&lt;物业的倾斜度&gt;？）。</li>
</ul>
<p>经过这个艰巨的练习之后，我们可以过滤电子表格并仔细查看具有“高”’期望’的变量。然后，我们可以绘制出这些变量和’SalePrice’之间的一些散点图，填入’结论’栏，这只是我们预期的修正。</p>
<p>我经历了这个过程并得出结论，下面的变量可以在这个问题中发挥重要作用：</p>
<ul>
<li>OverallQual&lt;总体材料和加工质量&gt;（这是一个我不喜欢的变量，因为我不知道它是如何计算的;你可以把使用所有其他可用变量来预测’OverallQual’来作为一个有趣的练习）。</li>
<li>YearBuilt&lt;原始施工日期&gt;</li>
<li>TotalBsmtSF&lt;地下室面积的平方英尺&gt;</li>
<li>GrLivArea&lt;以上（地面）生活区平方英尺&gt;</li>
</ul>
<p>我选择了两个’building’变量（’OverallQual’和’YearBuilt’）和两个’space’变量（’TotalBsmtSF’和’GrLivArea’）。这可能有点意外，因为它违背了房地产的核心，即在房地产中重要的影响因素是“位置”、“位置”和“位置”。对于类别变量，这种快速数据检查过程可能有点苛刻。例如，我预计’Neigborhood’变量更具相关性，但在数据检查之后，我最终排除了它。也许这与使用散点图而不是箱图有关，它更适合分类变量可视化。我们对数据进行可视化的方式通常会影响到我们的结论。</p>
<p>但是，这个练习的要点是想一想我们的数据和期望值，所以我认为我们达到了目标。现在是’少一点谈话，多一点行动’的时候了。让我们开始吧！</p>
<h3 id="2-首先要做的是分析’SalePrice’"><a href="#2-首先要做的是分析’SalePrice’" class="headerlink" title="2.首先要做的是分析’SalePrice’"></a>2.首先要做的是分析’SalePrice’</h3><p>‘SalePrice’是我们所追求的理由。就像我们要参加派对时一样。我们总是有一个理由去那里。比如，和女性交往也许就是我们去参加派对的原因。 （免责声明：根据您的喜好将其适应男性，跳舞或酒精）。</p>
<p>让我们来构建一个使用女性来比喻‘SalePrice’的小故事 — ‘我们如何认识’SalePrice’’的故事。</p>
<p><em>这一切都始于我们的Kaggle派对。当我们在舞池里寻找一段时间舞伴之后，我们看到一个女孩在酒吧附近使用舞蹈鞋。这说明了她在那里跳舞。我们花了很多时间进行预测建模并参与分析竞赛，因此与女孩谈话并不是我们的主要能力之一。即便如此，我们试了一下：</em></p>
<p><em>嗨，我是Kaggly！你呢？ ‘SalePrice’？多么美丽的名字！你知道’SalePrice’，你能给我提供一些关于你的数据吗？我刚刚开发了一个模型来计算两个人之间关系成功的可能性。我想在我们身上试一试！’</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 描述性统计数据汇总</span></span><br><span class="line">df_train[<span class="string">&#x27;SalePrice&#x27;</span>].describe()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">count      1460.000000</span><br><span class="line">mean     180921.195890</span><br><span class="line">std       79442.502883</span><br><span class="line">min       34900.000000</span><br><span class="line">25%      129975.000000</span><br><span class="line">50%      163000.000000</span><br><span class="line">75%      214000.000000</span><br><span class="line">max      755000.000000</span><br><span class="line">Name: SalePrice, dtype: float64</span><br></pre></td></tr></table></figure>
<p><em>很好……看起来你的最低价格大于零。很棒！你没有那些会毁掉我的模特的个人特质！你可以寄给我一些你的照片吗？……就像你在沙滩上……或者在健身房里自拍的那种一样？“</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 直方图</span><br><span class="line">sns.distplot(df_train[&#39;SalePrice&#39;]);</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/001.png" alt=""></p>
<p><em>啊!我看到你在出门的时候使用了seaborn化妆……太优雅了！我也看到你：</em></p>
<ul>
<li><strong><em>偏离正态分布。</em></strong></li>
<li><strong><em>有明显的正偏态。</em></strong></li>
<li><strong><em>显示尖锐度。</em></strong></li>
</ul>
<p><em>这很有趣！’SalePrice’，你能给我你的身体指标吗？’</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 偏度和峰度</span><br><span class="line">print(&quot;Skewness: %f&quot; % df_train[&#39;SalePrice&#39;].skew())</span><br><span class="line">print(&quot;Kurtosis: %f&quot; % df_train[&#39;SalePrice&#39;].kurt())</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Skewness: 1.882876</span><br><span class="line">Kurtosis: 6.536282</span><br></pre></td></tr></table></figure>
<p><em>‘Amazing！如果我的爱情计算器是正确的，我们的成功概率是97.834657％。我想我们应该再见面！如果下星期五有空，请留下我的电话号码并给我打电话。再见！</em></p>
<h4 id="‘SalePrice’，她的好友和她的兴趣"><a href="#‘SalePrice’，她的好友和她的兴趣" class="headerlink" title="‘SalePrice’，她的好友和她的兴趣"></a>‘SalePrice’，她的好友和她的兴趣</h4><p><em>选择你将要战斗的地形是重要的军事智慧。离开了“SalePrice”，我们就去了她的Facebook。请注意，这不是在跟踪她。我们只是对她做深入的研究。</em></p>
<p><em>据她介绍，我们有一些共同的朋友。除了Chuck Norris之外，我们都知道’GrLivArea’和’TotalBsmtSF’。此外，我们也有共同的兴趣，如’OverallQual’和’YearBuilt’。这看起来我们有希望！</em></p>
<p><em>为了充分利用我们的研究成果，我们将首先仔细研究我们的共同朋友的概况，然后我们将重点关注我们的共同利益。</em></p>
<p><strong>与数值变量的关系</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制 GrLivArea/SalePrice 的散点图</span></span><br><span class="line">var = <span class="string">&#x27;GrLivArea&#x27;</span></span><br><span class="line">data = pd.concat([df_train[<span class="string">&#x27;SalePrice&#x27;</span>], df_train[var]], axis=<span class="number">1</span>)</span><br><span class="line">data.plot.scatter(x=var, y=<span class="string">&#x27;SalePrice&#x27;</span>, ylim=(<span class="number">0</span>,<span class="number">800000</span>));</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/002.png" alt=""></p>
<p><em>嗯……看起来’SalePrice’和’GrLivArea’是真正的老朋友，具有线性关系。</em></p>
<p><em>那么’TotalBsmtSF’呢？</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 绘制 TotalBsmtSF&#x2F;SalePrice 的散点图</span><br><span class="line">var &#x3D; &#39;TotalBsmtSF&#39;</span><br><span class="line">data &#x3D; pd.concat([df_train[&#39;SalePrice&#39;], df_train[var]], axis&#x3D;1)</span><br><span class="line">data.plot.scatter(x&#x3D;var, y&#x3D;&#39;SalePrice&#39;, ylim&#x3D;(0,800000));</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/003.png" alt=""></p>
<p><em>‘TotalBsmtSF’也是’SalePrice’的好朋友，但这似乎是一种更加情感化的关系！在一开始的时候，一切似乎都很顺利，突然间，他们的关系呈现出强烈的线性（指数？）反应，一切都在变化。此外，很明显，有时’TotalBsmtSF’本身就会关闭，并且对’SalePrice’给予零分。</em></p>
<p><strong>与类别特征的关系</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 绘制 OverallQual&#x2F;SalePrice 的箱图</span><br><span class="line">var &#x3D; &#39;OverallQual&#39;</span><br><span class="line">data &#x3D; pd.concat([df_train[&#39;SalePrice&#39;], df_train[var]], axis&#x3D;1)</span><br><span class="line">f, ax &#x3D; plt.subplots(figsize&#x3D;(8, 6))</span><br><span class="line">fig &#x3D; sns.boxplot(x&#x3D;var, y&#x3D;&quot;SalePrice&quot;, data&#x3D;data)</span><br><span class="line">fig.axis(ymin&#x3D;0, ymax&#x3D;800000);</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/004.png" alt=""></p>
<p><em>像所有漂亮女孩一样，’SalePrice’很享受’OverallQual’。提醒自己：考虑麦当劳是否适合作为第一次约会的场所。</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var &#x3D; &#39;YearBuilt&#39;</span><br><span class="line">data &#x3D; pd.concat([df_train[&#39;SalePrice&#39;], df_train[var]], axis&#x3D;1)</span><br><span class="line">f, ax &#x3D; plt.subplots(figsize&#x3D;(16, 8))</span><br><span class="line">fig &#x3D; sns.boxplot(x&#x3D;var, y&#x3D;&quot;SalePrice&quot;, data&#x3D;data)</span><br><span class="line">fig.axis(ymin&#x3D;0, ymax&#x3D;800000);</span><br><span class="line">plt.xticks(rotation&#x3D;90);</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/005.png" alt=""></p>
<p><em>虽然这不是一个强烈的趋势，但我认为相比旧的东西，’SalePrice’更喜欢在新的东西上花钱</em></p>
<p><strong>注意：</strong>我们不知道’SalePrice’是否处于不变价格。不变的价格试图消除通货膨胀的影响。如果’SalePrice’价格不是固定的，那么它应该是这样的，因为多年来价格是可比的。</p>
<p><strong>综上所述</strong>，我们可以得出以下结论：</p>
<ul>
<li>‘GrLivArea’和’TotalBsmtSF’似乎与’SalePrice’线性相关。这两种关系都是积极的，这意味着随着一个变量增加，另一个变量也增加。在’TotalBsmtSF’的情况下，我们可以看到线性关系的斜率特别高。</li>
<li>‘OverallQual’和’YearBuilt’似乎也与’SalePrice’有关。在’OverallQual’的情况下，这种关系似乎更强一些，箱子图显示了销售价格随整体质量的变化情况。</li>
</ul>
<p>我们只分析了四个变量，但还有很多其他的我们应该分析。这里的诀窍似乎是选择正确的特征（特征选择），而不是它们之间复杂关系的定义（特征工程）。</p>
<h3 id="3-保持客观，理性工作"><a href="#3-保持客观，理性工作" class="headerlink" title="3.保持客观，理性工作"></a>3.保持客观，理性工作</h3><p>到现在为止，我们只是遵循我们的直觉，分析了我们认为重要的变量。尽管我们努力为我们的分析提供客观性，但我们必须说，我们的出发点是主观的。</p>
<p>作为一名工程师，我对这种方法感到不舒服。我所有的教育都是为了培养一个训练有素的头脑，能够抵挡主观性的思维。因为如果在结构工程中扮演主观性的角色，你会发现主观的想法是站不住脚的。</p>
<p>所以，让我们克服惯性，做一个更客观的分析。</p>
<p><strong>‘等离子汤’</strong></p>
<p>“一开始除了等离子汤以外没有其他任何东西。在我们研究宇宙学的时候，我们知道这些短暂的时刻，在很大程度上是推测得出的。然而，科学已经根据今天宇宙已知的情况设计了可能发生的事情的一些草图。’（来源：<a target="_blank" rel="noopener" href="http://umich.edu/~gs265/bigbang.htm">http://umich.edu/~gs265/bigbang.htm</a>）</p>
<p>为了探索宇宙，我们将从一些实用的食谱开始，以理解我们的“等离子汤”：</p>
<ul>
<li>相关矩阵（热图样式）。</li>
<li>‘SalePrice’相关矩阵（放大热图样式）。</li>
<li>最相关的变量之间的散点图（move like Jagger样式）</li>
</ul>
<p><strong>相关矩阵（热图样式）</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#相关矩阵</span><br><span class="line">corrmat &#x3D; df_train.corr()</span><br><span class="line">f, ax &#x3D; plt.subplots(figsize&#x3D;(12, 9))</span><br><span class="line">sns.heatmap(corrmat, vmax&#x3D;.8, square&#x3D;True);</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/006.png" alt=""></p>
<p>在我看来，这张热图是快速了解我们的“等离子汤”及其关系的最佳方式。 （谢谢你@seaborn！）</p>
<p>乍一看，有两个红色的正方形引起了我的注意。第一个引用’TotalBsmtSF’和’1stFlrSF’变量，第二个引用’GarageX’变量。两种情况都表明这些变量之间的相关性有多大。实际上，这种相关性非常强，可以表明多重共线性的情况。如果我们考察了这些变量，我们可以得出相同的结论。热图非常适合检测这种情况，并且在像我们这样的特征选择占主导地位的问题中，它们是必不可少的工具。</p>
<p>另一件引起我注意的事情是’SalePrice’相关性。我们可以看到我们众所周知的’GrLivArea’，’TotalBsmtSF’和’OverallQual’这样明显的变量在向我们说“Hi！”，但我们也可以看到许多其他应该考虑的变量。这就是我们接下来要做的。</p>
<p><strong>‘SalePrice’相关矩阵（放大热图样式）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SalePrice相关矩阵</span></span><br><span class="line">k = <span class="number">10</span> <span class="comment">#热图的变量数</span></span><br><span class="line">cols = corrmat.nlargest(k, <span class="string">&#x27;SalePrice&#x27;</span>)[<span class="string">&#x27;SalePrice&#x27;</span>].index</span><br><span class="line">cm = np.corrcoef(df_train[cols].values.T)</span><br><span class="line">sns.<span class="built_in">set</span>(font_scale=<span class="number">1.25</span>)</span><br><span class="line">hm = sns.heatmap(cm, cbar=<span class="literal">True</span>, annot=<span class="literal">True</span>, square=<span class="literal">True</span>, fmt=<span class="string">&#x27;.2f&#x27;</span>, annot_kws=&#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">10</span>&#125;, yticklabels=cols.values, xticklabels=cols.values)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/007.png" alt=""></p>
<p>根据我们的水晶球显示，这些是与“SalePrice”最相关的变量。因此我得出以下结论：</p>
<ul>
<li>OverallQual’，’GrLivArea’和’TotalBsmtSF’与’SalePrice’密切相关。需要检查！</li>
<li>‘GarageCars’和’GarageArea’也是一些与强度相关的变量。但是，正如我们在最后一点所讨论的那样，车库所能容纳的车辆数量是车库面积的结果。’GarageCars’和’GarageArea’就像孪生兄弟。你永远无法区分它们。因此，我们只需要分析其中的一个变量（我们可以保留’GarageCars’，因为它与’SalePrice’的关联性更高）。</li>
<li>‘TotalBsmtSF’和’1stFloor’也似乎是双胞胎兄弟。我们可以只保留’TotalBsmtSF’（重新阅读’那么，我们能得到什么呢？’部分）。</li>
<li>‘FullBath’?? 真的需要吗?</li>
<li>‘TotRmsAbvGrd’和’GrLivArea’，再次是双胞胎兄弟。这是来自切尔诺贝利的数据集吗？</li>
<li>啊……’YearBuilt’……看起来’YearBuilt’与’SalePrice’略有关联。老实说，对于’YearBuilt’变量来说，我是有一些额外的顾虑的，因为这让我觉得我们应该做一些时间序列分析来分析这一变量。我会把这个问题作为你的homework。</li>
</ul>
<p>我们继续看散点图。</p>
<p>‘SalePrice’和相关变量之间的散点图（move like Jagger style）</p>
<p>前方高能！我第一次看到这些散点图的时候，我完全震惊了。</p>
<p>在如此短的空间里有如此多的信息.​​…..这真是太神奇了。再一次谢谢@seaborn！你让我’move like Jagger’！</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制散点图</span></span><br><span class="line">sns.<span class="built_in">set</span>()</span><br><span class="line">cols = [<span class="string">&#x27;SalePrice&#x27;</span>, <span class="string">&#x27;OverallQual&#x27;</span>, <span class="string">&#x27;GrLivArea&#x27;</span>, <span class="string">&#x27;GarageCars&#x27;</span>, <span class="string">&#x27;TotalBsmtSF&#x27;</span>, <span class="string">&#x27;FullBath&#x27;</span>, <span class="string">&#x27;YearBuilt&#x27;</span>]</span><br><span class="line">sns.pairplot(df_train[cols], size = <span class="number">2.5</span>)</span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/008.png" alt=""></p>
<p>虽然我们已经知道一些主要的变量，但这个巨大的散点图给了我们关于变量关系的一个合理的解释。</p>
<p>我们可能会对’TotalBsmtSF’和’GrLiveArea’组成的散点图感兴趣。在这个图中，我们可以看到许多点画出了一条线，几乎就像一个边界。这种结果是完全有道理的，并且大多数的点保持在该线以下。地下室的面积可以等于地面上的居住面积，但预计地下室面积不会超过地上居住面积（除非你想购买的是地堡）。</p>
<p>关于’SalePrice’和’YearBuilt’的情况也可以让我们进一步思考。在“点云”的底部，我们看到一个看起来几乎是一个指数函数的曲线。我们也可以在’点云’的上限中看到同样的趋势。另外，请注意过去几年中的一系列点数是如何保持在这个极限之上的（我只是想说价格增速正在变快）。</p>
<p>好吧，现在我们已经完成了足够多的罗夏测试。让我们来探讨下一步的内容：缺失数据！</p>
<h3 id="4-缺失的数据"><a href="#4-缺失的数据" class="headerlink" title="4.缺失的数据"></a>4.缺失的数据</h3><p>在考虑缺失数据时的几个重要问题：</p>
<ul>
<li>缺失的数据有多普遍？</li>
<li>丢失数据是随机现象的还是有一定的规律？</li>
</ul>
<p>这些问题的答案很重要，因为缺少数据可能意味着样本量减少。这可能会使我们的分析工作无法进行。此外，从实质的角度来看，我们需要确保缺失的数据流程没有偏见，并确保没有将一些不易洞察的事实所隐藏。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 缺失数据</span></span><br><span class="line">total = df_train.isnull().<span class="built_in">sum</span>().sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">percent = (df_train.isnull().<span class="built_in">sum</span>()/df_train.isnull().count()).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">missing_data = pd.concat([total, percent], axis=<span class="number">1</span>, keys=[<span class="string">&#x27;Total&#x27;</span>, <span class="string">&#x27;Percent&#x27;</span>])</span><br><span class="line">missing_data.head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left">Total</th>
<th style="text-align:left">Percent</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">PoolQC</td>
<td style="text-align:left">1453</td>
<td style="text-align:left">0.995205</td>
</tr>
<tr>
<td style="text-align:left">MiscFeature</td>
<td style="text-align:left">1406</td>
<td style="text-align:left">0.963014</td>
</tr>
<tr>
<td style="text-align:left">Alley</td>
<td style="text-align:left">1369</td>
<td style="text-align:left">0.937671</td>
</tr>
<tr>
<td style="text-align:left">Fence</td>
<td style="text-align:left">1179</td>
<td style="text-align:left">0.807534</td>
</tr>
<tr>
<td style="text-align:left">FireplaceQu</td>
<td style="text-align:left">690</td>
<td style="text-align:left">0.472603</td>
</tr>
<tr>
<td style="text-align:left">LotFrontage</td>
<td style="text-align:left">259</td>
<td style="text-align:left">0.177397</td>
</tr>
<tr>
<td style="text-align:left">GarageCond</td>
<td style="text-align:left">81</td>
<td style="text-align:left">0.055479</td>
</tr>
<tr>
<td style="text-align:left">GarageType</td>
<td style="text-align:left">81</td>
<td style="text-align:left">0.055479</td>
</tr>
<tr>
<td style="text-align:left">GarageYrBlt</td>
<td style="text-align:left">81</td>
<td style="text-align:left">0.055479</td>
</tr>
<tr>
<td style="text-align:left">GarageFinish</td>
<td style="text-align:left">81</td>
<td style="text-align:left">0.055479</td>
</tr>
<tr>
<td style="text-align:left">GarageQual</td>
<td style="text-align:left">81</td>
<td style="text-align:left">0.055479</td>
</tr>
<tr>
<td style="text-align:left">BsmtExposure</td>
<td style="text-align:left">38</td>
<td style="text-align:left">0.026027</td>
</tr>
<tr>
<td style="text-align:left">BsmtFinType2</td>
<td style="text-align:left">38</td>
<td style="text-align:left">0.026027</td>
</tr>
<tr>
<td style="text-align:left">BsmtFinType1</td>
<td style="text-align:left">37</td>
<td style="text-align:left">0.025342</td>
</tr>
<tr>
<td style="text-align:left">BsmtCond</td>
<td style="text-align:left">37</td>
<td style="text-align:left">0.025342</td>
</tr>
<tr>
<td style="text-align:left">BsmtQual</td>
<td style="text-align:left">37</td>
<td style="text-align:left">0.025342</td>
</tr>
<tr>
<td style="text-align:left">MasVnrArea</td>
<td style="text-align:left">8</td>
<td style="text-align:left">0.005479</td>
</tr>
<tr>
<td style="text-align:left">MasVnrType</td>
<td style="text-align:left">8</td>
<td style="text-align:left">0.005479</td>
</tr>
<tr>
<td style="text-align:left">Electrical</td>
<td style="text-align:left">1</td>
<td style="text-align:left">0.000685</td>
</tr>
<tr>
<td style="text-align:left">Utilities</td>
<td style="text-align:left">0</td>
<td style="text-align:left">0.000000</td>
</tr>
</tbody>
</table>
</div>
<p>让我们分析一下这个表里的信息，来理解如何处理丢失的数据。</p>
<p>我们会考虑当超过15％的数据丢失时，删除相应的变量并假设它从来都不存在。这意味着在这些情况下，我们不会尝试填补缺失数据。按照这个逻辑，我们应该删除一组变量（例如’PoolQC’，’MiscFeature’，’Alley’等）。这么做的重点是：我们会错过这些数据吗？我不这么认为。这些变量中没有一个看起来很重要，因为其中大多数不是我们在购买房屋时考虑的方面（或许这就是这些数据会缺失的原因？）。此外，仔细观察变量，像’PoolQC’，’MiscFeature’和’FireplaceQu’这样的变量是异常值的强有力候选者，所以我们很乐意删除它们。</p>
<p>在其余的案例中，我们可以看到“GarageX”系列的变量具有相同数量的缺失数据。我敢打赌，缺少的数据来自同一组观察结果（我不会检查它，缺失值只有5％的占比）。由于表示关于车库信息的最重要信息的字段是“GarageCars”，并且考虑到我们只是谈论了5％的缺失数据，所以我将删除提及的“GarageX”变量。同样的逻辑适用于’BsmtX’变量。</p>
<p>关于’MasVnrArea’和’MasVnrType’，我们可以认为这些变量不是必需的。此外，它们与已经考虑过的“YearBuilt”和“OverallQual”有很强的相关性。因此，如果我们删除’MasVnrArea’和’MasVnrType’这两个变量，我们不会丢失信息。</p>
<p>最后，我们在’Electrical’中有一个缺失的观察。由于这只是一个观察，我们将删除此记录并保留该变量。</p>
<p>总之，为了处理缺失的数据，我们将删除所有缺少数据的变量，但变量’Electrical’除外。在’Electrical’中，我们只需删除缺少数据的观察结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 缺失数据处理</span></span><br><span class="line">df_train = df_train.drop((missing_data[missing_data[<span class="string">&#x27;Total&#x27;</span>] &gt; <span class="number">1</span>]).index,<span class="number">1</span>)</span><br><span class="line">df_train = df_train.drop(df_train.loc[df_train[<span class="string">&#x27;Electrical&#x27;</span>].isnull()].index)</span><br><span class="line">df_train.isnull().<span class="built_in">sum</span>().<span class="built_in">max</span>() <span class="comment">#just checking that there&#x27;s no missing data missing...</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0</span><br></pre></td></tr></table></figure>
<h3 id="离群值！"><a href="#离群值！" class="headerlink" title="离群值！"></a>离群值！</h3><p>离群值也是我们应该意识到的。为什么？因为异常值可以显着影响我们的模型，并且可以成为宝贵的信息来源，为某些特定行为提供解释。</p>
<p>离群值是一个复杂的问题，值得给与更多关注。在这里，我们将通过“SalePrice”的标准偏差和一组散点图进行快速分析。</p>
<p><strong>单变量分析</strong></p>
<p>这里主要关心的是建立一个阈值，将观测定义为异常值。为此，我们将标准化数据。在此情况下，数据标准化意味着将数据值转换为平均值为0，标准偏差为1。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 标准化数据</span><br><span class="line">saleprice_scaled &#x3D; StandardScaler().fit_transform(df_train[&#39;SalePrice&#39;][:,np.newaxis]);</span><br><span class="line">low_range &#x3D; saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]</span><br><span class="line">high_range&#x3D; saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]</span><br><span class="line">print(&#39;outer range (low) of the distribution:&#39;)</span><br><span class="line">print(low_range)</span><br><span class="line">print(&#39;\nouter range (high) of the distribution:&#39;)</span><br><span class="line">print(high_range)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">outer range (low) of the distribution:</span><br><span class="line">[[-1.83820775]</span><br><span class="line"> [-1.83303414]</span><br><span class="line"> [-1.80044422]</span><br><span class="line"> [-1.78282123]</span><br><span class="line"> [-1.77400974]</span><br><span class="line"> [-1.62295562]</span><br><span class="line"> [-1.6166617 ]</span><br><span class="line"> [-1.58519209]</span><br><span class="line"> [-1.58519209]</span><br><span class="line"> [-1.57269236]]</span><br><span class="line"></span><br><span class="line">outer range (high) of the distribution:</span><br><span class="line">[[3.82758058]</span><br><span class="line"> [4.0395221 ]</span><br><span class="line"> [4.49473628]</span><br><span class="line"> [4.70872962]</span><br><span class="line"> [4.728631  ]</span><br><span class="line"> [5.06034585]</span><br><span class="line"> [5.42191907]</span><br><span class="line"> [5.58987866]</span><br><span class="line"> [7.10041987]</span><br><span class="line"> [7.22629831]]</span><br></pre></td></tr></table></figure>
<p>对’SalePrice’的新衣服，感觉如何？：</p>
<ul>
<li>低范围值与0相似且不太远。</li>
<li>高范围值远离0，大概是7.多的值。</li>
</ul>
<p>目前，我们不会将这些值视为异常值，但我们应该小心这两个值。</p>
<p><strong>双变量分析</strong></p>
<p>我们已经了解了以下散点图。但是，当我们从新的角度来看事物时，总会有一些东西需要发现。正如Alan Kay所说，“视角的改变相当于提高80点智商”。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 双变量分析SalePrice&#x2F;GrLivArea</span><br><span class="line">var &#x3D; &#39;GrLivArea&#39;</span><br><span class="line">data &#x3D; pd.concat([df_train[&#39;SalePrice&#39;], df_train[var]], axis&#x3D;1)</span><br><span class="line">data.plot.scatter(x&#x3D;var, y&#x3D;&#39;SalePrice&#39;, ylim&#x3D;(0,800000));</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/009.png" alt=""></p>
<p>它所揭示的是：</p>
<ul>
<li>这两个变量中，更大的’GrLivArea’的数据看起来很奇怪，这些较大的’GrLivArea’离群了。我们可以推测为什么会发生这种情况。也许这些样本是农业领域的，这样想可以解释低价的原因。我不确定这一点，但我确信这两点并不代表典型案例。因此，我们将它们定义为异常值并删除它们。</li>
<li>顶部的两个观察结果是那些7.多的那两个，我们应该小心处理这些观察结果。他们看起来像两个特殊情况，但他们似乎正在追随上涨的趋势。出于这个原因，我们会保留它们。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">＃ 删除点</span><br><span class="line">df_train.sort_values(by = <span class="string">&#x27;GrLivArea&#x27;</span>, ascending = <span class="literal">False</span>)[:<span class="number">2</span>]</span><br><span class="line">df_train = df_train.drop(df_train[df_train[<span class="string">&#x27;Id&#x27;</span>] == <span class="number">1299</span>].index)</span><br><span class="line">df_train = df_train.drop(df_train[df_train[<span class="string">&#x27;Id&#x27;</span>] == <span class="number">524</span>].index)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 双变量分析SalePrice/GrLivArea</span></span><br><span class="line">var = <span class="string">&#x27;TotalBsmtSF&#x27;</span></span><br><span class="line">data = pd.concat([df_train[<span class="string">&#x27;SalePrice&#x27;</span>], df_train[var]], axis=<span class="number">1</span>)</span><br><span class="line">data.plot.scatter(x=var, y=<span class="string">&#x27;SalePrice&#x27;</span>, ylim=(<span class="number">0</span>,<span class="number">800000</span>));</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/010.png" alt=""></p>
<p>我们可以想象消除一些观察结果（例如TotalBsmtSF&gt; 3000的结果），但我认为这么做不值得。我们可以接受这些值，所以我们不会做任何事情。</p>
<h3 id="5-硬核部分"><a href="#5-硬核部分" class="headerlink" title="5.硬核部分"></a>5.硬核部分</h3><p>在Ayn Rand的小说“阿特拉斯耸耸肩”中，有一个经常重复的问题：John Galt是谁？本书很大一部分是关于寻求发现这个问题的答案。</p>
<p>我现在体会到了Rand的感受，’SalePrice’是谁呢？</p>
<p>这个问题的答案在于测试多变量分析统计基础的假设。我们已经做了一些数据清理，并发现了很多关于’SalePrice’的信息。现在是深入了解’SalePrice’如何符合统计假设的时候了，这些假设使我们能够应用多元技术。</p>
<p>根据Hair et al. (2013)，我们应该测试四个假设：</p>
<ul>
<li><strong>正态性</strong> - 当我们谈论正态性时，我们的意思是数据应该看起来像正态分布。这很重要，因为几个统计测试依赖于此（例如t-statistics）。在本练习中，我们将检查’SalePrice’的单变量正态性（这是一种有限的方法）。请记住，单变量正态性并不能确保多元正态性（这是我们想要的），但这么做是有帮助的。需要考虑的另一个细节是，在大样本（&gt; 200个观测值）的情况下，正态性不是一个重要的问题。但是，如果我们解决正态性问题，就可以避免很多其他问题（例如异质性），这就是我们进行这种分析的主要原因。</li>
<li><strong>方差齐性</strong> - 希望我写的是对的。 方差齐性指的是“假设变量（一个或多个）在预测​​变量范围内表现出相同的方差水平”（Hair et al。，2013）。考虑方差齐性是合理的，因为我们希望误差项在自变量的所有值中都是相同的。</li>
<li><strong>线性</strong> - 评估线性的最常见方法是检查散点图并搜索线性模式。如果模式不是线性的，那么可以尝试探索数据转换。但是，在这里我们去转换数据，因为我们看到的大多数散点图似乎都具有线性关系。</li>
<li><strong>缺少相关错误</strong> - 如定义所示，相关的错误发生在一个错误与另一个错误相关时。例如，如果一个正误差系统地产生负误差，则意味着这些变量之间存在关系。这通常以时间序列发生，其中一些模式与时间相关。我们在这里不会涉及这一点。但是，如果您检测到某些内容，请尝试添加一个可以解释您获得的效果的变量。这是相关错误的最常见解决方案。</li>
</ul>
<p>你认为猫王会对这个漫长的解释说些什么？ ‘请少一点谈话，多一点行动’？可能……顺便说一下，你知道Elvis最后一次承受的重大的打击是什么吗？</p>
<p>(…)</p>
<p>是浴室的地板。</p>
<p><strong>寻找正态性</strong></p>
<p>这里的要点是以非常精益的方式测试’SalePrice’。我们将这样做：</p>
<ul>
<li><strong>直方图</strong> - 峰度和偏度。</li>
<li><strong>正态概率图</strong> - 数据分布应该紧跟代表正态分布的对角线。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 直方图和正态概率图</span><br><span class="line">sns.distplot(df_train[&#39;SalePrice&#39;], fit&#x3D;norm);</span><br><span class="line">fig &#x3D; plt.figure()</span><br><span class="line">res &#x3D; stats.probplot(df_train[&#39;SalePrice&#39;], plot&#x3D;plt)</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/011.png" alt=""></p>
<p><img src="/img/18_03_11/012.png" alt=""></p>
<p>好吧，’SalePrice’不服从正态分布。它显示’顶峰’呈现出正偏斜状态，并且不遵循对角线。</p>
<p>但一切都没有丢失。简单的数据转换可以解决问题。这是您可以在统计书籍中学到的很棒的东西之一：如果是正偏态，使用log函数转换通常效果不错。当我发现这一点时，我感觉自己就像一个霍格沃茨的学生发现了一个新的咒语一样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">＃ 应用log函数转换</span><br><span class="line">df_train[<span class="string">&#x27;SalePrice&#x27;</span>] = np.log(df_train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转换的直方图和正态概率分布图</span></span><br><span class="line">sns.distplot(df_train[<span class="string">&#x27;SalePrice&#x27;</span>], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(df_train[<span class="string">&#x27;SalePrice&#x27;</span>], plot=plt)</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/013.png" alt=""></p>
<p><img src="/img/18_03_11/014.png" alt=""></p>
<p>完成！让我们来看看’GrLivArea’的情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">＃ 直方图和正态概率分布图</span><br><span class="line">sns.distplot(df_train[<span class="string">&#x27;GrLivArea&#x27;</span>], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(df_train[<span class="string">&#x27;GrLivArea&#x27;</span>], plot=plt)</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/015.png" alt=""></p>
<p><img src="/img/18_03_11/016.png" alt=""></p>
<p>看起来有点歪…</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据转换</span></span><br><span class="line">df_train[<span class="string">&#x27;GrLivArea&#x27;</span>] = np.log(df_train[<span class="string">&#x27;GrLivArea&#x27;</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转换的直方图和正态概率分布图</span></span><br><span class="line">sns.distplot(df_train[<span class="string">&#x27;GrLivArea&#x27;</span>], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(df_train[<span class="string">&#x27;GrLivArea&#x27;</span>], plot=plt)</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/017.png" alt=""></p>
<p><img src="/img/18_03_11/018.png" alt=""></p>
<p>下一个…</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直方图和正态概率分布图</span></span><br><span class="line">sns.distplot(df_train[<span class="string">&#x27;TotalBsmtSF&#x27;</span>], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(df_train[<span class="string">&#x27;TotalBsmtSF&#x27;</span>], plot=plt)</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/019.png" alt=""></p>
<p><img src="/img/18_03_11/020.png" alt=""></p>
<p>好的，现在我们要处理几个大麻烦了：</p>
<ul>
<li>总体来说，数据分布呈现偏斜状态。</li>
<li>有大量的零值观察（比如没有地下室的房屋）。</li>
<li>0是不能求log的，这是一个很大的问题。</li>
</ul>
<p>为了在这里应用log转换，我们将创建一个变量来获得有或没有地下室（二进制变量）的效果。然后，我们将对所有非零观测值进行对数转换，忽略零值。这样我们就可以转换数据，而不会失去有或没有地下室的影响。</p>
<p>我不确定这种方法是否正确。但这对我来说似乎是正确的。这就是我所说的“高风险工程”。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为新变量创建列（一个足够了，因为它是一个二进制分类特征）</span></span><br><span class="line"><span class="comment"># 如果 area&gt;0 值为1，否则 值为0</span></span><br><span class="line">df_train[<span class="string">&#x27;HasBsmt&#x27;</span>] = pd.Series(<span class="built_in">len</span>(df_train[<span class="string">&#x27;TotalBsmtSF&#x27;</span>]), index=df_train.index)</span><br><span class="line">df_train[<span class="string">&#x27;HasBsmt&#x27;</span>] = <span class="number">0</span> </span><br><span class="line">df_train.loc[df_train[<span class="string">&#x27;TotalBsmtSF&#x27;</span>]&gt;<span class="number">0</span>,<span class="string">&#x27;HasBsmt&#x27;</span>] = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据转换</span></span><br><span class="line">df_train.loc[df_train[<span class="string">&#x27;HasBsmt&#x27;</span>]==<span class="number">1</span>,<span class="string">&#x27;TotalBsmtSF&#x27;</span>] = np.log(df_train[<span class="string">&#x27;TotalBsmtSF&#x27;</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直方图和正态概率分布图</span></span><br><span class="line">sns.distplot(df_train[df_train[<span class="string">&#x27;TotalBsmtSF&#x27;</span>]&gt;<span class="number">0</span>][<span class="string">&#x27;TotalBsmtSF&#x27;</span>], fit=norm);</span><br><span class="line">fig = plt.figure()</span><br><span class="line">res = stats.probplot(df_train[df_train[<span class="string">&#x27;TotalBsmtSF&#x27;</span>]&gt;<span class="number">0</span>][<span class="string">&#x27;TotalBsmtSF&#x27;</span>], plot=plt)</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/021.png" alt=""></p>
<p><img src="/img/18_03_11/022.png" alt=""></p>
<p><strong>在第一次尝试中寻找“方差齐性”</strong></p>
<p>测试两个度量变量的同方差性的最佳方法是图形化。对不同特征使用相同的分布方式，生成锥形（样本在一侧分布的少，另一侧分布的多）或钻石（大量点分布在中心区域）等形状的分布情况。</p>
<p>绘制SalePrice’和’GrLivArea’的分布：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">＃散点图</span><br><span class="line">plt.scatter(df_train[<span class="string">&#x27;GrLivArea&#x27;</span>], df_train[<span class="string">&#x27;SalePrice&#x27;</span>]);</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/023.png" alt=""></p>
<p>此散点图的旧版本（在对数转换之前）具有圆锥形状（返回并检查’SalePrice’和相关变量之间的散点图（move like Jagger style））。如您所见，当前的散点图不再具有圆锥形状。这是正态化的力量！只要确保一些变量的正态性，我们解决了同方差问题。</p>
<p>我们继续检查’SalePrice’和’TotalBsmtSF’。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">＃散点图</span><br><span class="line">plt.scatter(df_train[df_train[<span class="string">&#x27;TotalBsmtSF&#x27;</span>]&gt;<span class="number">0</span>][<span class="string">&#x27;TotalBsmtSF&#x27;</span>], df_train[df_train[<span class="string">&#x27;TotalBsmtSF&#x27;</span>]&gt;<span class="number">0</span>][<span class="string">&#x27;SalePrice&#x27;</span>]);</span><br></pre></td></tr></table></figure>
<p><img src="/img/18_03_11/024.png" alt=""></p>
<p>总的来说，’SalePrice’在’TotalBsmtSF’范围内表现出相等的变化水平。Cool!</p>
<h3 id="Last-but-not-the-least-虚拟变量"><a href="#Last-but-not-the-least-虚拟变量" class="headerlink" title="Last but not the least, 虚拟变量"></a>Last but not the least, 虚拟变量</h3><p>简单模式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">＃ 虚拟变量转换</span><br><span class="line">df_train = pd.get_dummies(df_train)</span><br></pre></td></tr></table></figure>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>到了练习的最后部分。</p>
<p>在整个这个kernel中，我们实践了许多由Hair等人提出的策略。 （2013年）。我们对变量进行了哲学研究，我们单独分析了“SalePrice”，并且与最相关的变量进行了分析，我们处理了缺失的数据和异常值，我们测试了一些基本的统计假设，甚至将分类变量转换为虚拟变量。 Python帮助我们轻松完成了很多工作。</p>
<p>但是我们的任务还没有结束。别忘了，我们的故事还停留在对’SalePrice’的Facebook的研究那一步呢。现在是时候打电话给’SalePrice’并邀请她共进晚餐。试着预测她的行为。你认为她是一个喜欢正规化线性回归方法的女孩吗？或者你认为她喜欢合奏方法？或者也许别的东西？</p>
<p>答案由你找出。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="http://pmarcelino.com/">作者blog</a></p>
<p><a target="_blank" rel="noopener" href="https://www.amazon.com/Multivariate-Data-Analysis-Joseph-Hair/dp/0138132631">Hair等人，2013，多变量数据分析，第7版</a></p>
<h2 id="致谢-1"><a href="#致谢-1" class="headerlink" title="致谢"></a>致谢</h2><p>感谢JoãoRico的审阅。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/12/20/%E3%80%90%E5%8E%9F%E5%88%9B%E3%80%91AI-QI%E9%87%8F%E5%8C%96%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%E7%88%AC%E5%9D%91%E7%AC%94%E8%AE%B0-%E5%B0%8F%E5%BF%83%E5%81%8F%E6%96%9C%E7%B1%BB%E9%97%AE%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="DannyLee">
      <meta itemprop="description" content="愿你的努力终取得成果">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="圣巢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/12/20/%E3%80%90%E5%8E%9F%E5%88%9B%E3%80%91AI-QI%E9%87%8F%E5%8C%96%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA%E7%88%AC%E5%9D%91%E7%AC%94%E8%AE%B0-%E5%B0%8F%E5%BF%83%E5%81%8F%E6%96%9C%E7%B1%BB%E9%97%AE%E9%A2%98/" class="post-title-link" itemprop="url">【原创】AI-QI量化平台搭建爬坑笔记-小心偏斜类问题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-12-20 14:54:00" itemprop="dateCreated datePublished" datetime="2017-12-20T14:54:00+00:00">2017-12-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-10 17:00:48" itemprop="dateModified" datetime="2021-02-10T17:00:48+00:00">2021-02-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>原创文章，转载请注明出处</p>
</blockquote>
<p>首先安利一波广告：</p>
<p>最近利用业余时间搭建了一个智能量化投资平台，代码已经全部开源：<a target="_blank" rel="noopener" href="https://github.com/DannyLee1991/ai_qi">https://github.com/DannyLee1991/ai_qi</a></p>
<p>目前已经实现的功能有：</p>
<ul>
<li>数据的抓取（数据来源<a href="tushare.org">tushare</a>}）</li>
</ul>
<p><img src="/img/17_12_20/001.png" alt=""></p>
<ul>
<li>数据入库，并在界面上可以执行sql操作</li>
</ul>
<p><img src="/img/17_12_20/002.png" alt=""></p>
<ul>
<li>数据可视化</li>
</ul>
<p><img src="/img/17_12_20/003.png" alt=""><br><img src="/img/17_12_20/004.png" alt=""></p>
<ul>
<li>数据集创建</li>
</ul>
<p>数据集管理</p>
<p><img src="/img/17_12_20/005.png" alt=""></p>
<p>数据集创建</p>
<p><img src="/img/17_12_20/006.png" alt=""></p>
<p>数据集查看</p>
<p><img src="/img/17_12_20/005.png" alt=""></p>
<ul>
<li>数据预处理</li>
</ul>
<p>// 暂无界面</p>
<p>正在开发中的功能：</p>
<ul>
<li>数据建模</li>
<li>接入交易接口</li>
<li>…</li>
</ul>
<p>各个已有的功能目前也只是做了部分实现，先把各个环节打通，然后在慢慢填充。最终的目标是利用机器学习算法来预测分析各种投资数据。</p>
<p>欢迎各位大牛拍砖指导~</p>
<hr>
<p>好，以上不是本文的重点，本文重点是这两天在建立第一个模型过程中遇到的一个坑。</p>
<hr>
<h3 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h3><p>第一个模型，我准备使用日交易数据来预测次日的涨跌幅度，使用的数据来自日交易数据表：</p>
<p><img src="/img/17_12_20/008.png" alt=""></p>
<p>这是对应的原始数据集详情信息：</p>
<p><img src="/img/17_12_20/009.png" alt=""></p>
<p>其中  除了X的<strong>‘date’(时间)</strong>特征之外，其他的特征都是float类型的数据。暂时先剔除这一维度的数据，所以最后用来训练的X的shape是<code>(292583, 15)</code>。</p>
<p>Y的shape不变，是<code>(292583, 1)</code>。</p>
<p>Y的数据类型也是float。</p>
<blockquote>
<p>这里先解释一下<strong>Y</strong>的含义：Y对应的数据是涨跌幅，但和与之对应的X的数据并不是同一天的，这里<strong>日期间隔1</strong>的含义是Y取的是相对于X的数据的时间的下一日的数据，因为我们要预测的是次日涨跌幅。</p>
</blockquote>
<p>对于分类模型，我们的Y应该是类别标签，而不能是连续型数值，所以我们应该把当前的float类型的Y，转换成某种类别标签来表示。</p>
<p>一种很容易理解的方式，就是float转int，简单粗暴：</p>
<p>eg:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y &#x3D; [1.1, 2.6, 3.5, -1.8, ...]</span><br></pre></td></tr></table></figure>
<p>转换为int之后</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y &#x3D; [1, 2, 3, -1, ...]</span><br></pre></td></tr></table></figure>
<p>但这里有一个小坑，负数的标签在带入到tensorflow中训练是会报错的，所以把标签数据+10，全部转为大于等于0的数据，处理之后的效果为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y &#x3D; [11, 12, 13, 9, ...]</span><br></pre></td></tr></table></figure>
<p>在经过上述的预处理之后，Y被处理成了21个类别（-10到10之间一共21个int值）的数据集。</p>
<p>然后就是将数据打乱，按照6:2:2的比例将数据分割为<strong>训练集</strong>、<strong>验证集</strong>和<strong>测试集</strong>。</p>
<hr>
<h3 id="带入训练"><a href="#带入训练" class="headerlink" title="带入训练"></a>带入训练</h3><p>仿照tensorflow的<a target="_blank" rel="noopener" href="https://www.tensorflow.org/get_started/estimator">demo</a>，将数据带入一个DNN模型，进行训练。</p>
<p>没有进行什么特殊的调参，最终准确率竟然达到了接近50%！</p>
<p><img src="/img/17_12_20/010.png" alt=""></p>
<p>要知道这是21个类别的分类问题，50%的准确率已经远远高于均匀分布情况下随机选择的准确率（大约是4.8%）了。</p>
<p>于是我觉得21类数据，准确率就能达到这么高，那如果我将类别改为2类，准确率应该会大幅提升的。</p>
<p>于是我重新将Y的数据改为了0和1两种类别，0代表跌1代表涨。</p>
<p>但实际情况，并没有好很多，准确率大概达到52%左右。</p>
<p>看到这种结果，第一时间，我是怀疑自己代码有没有哪里写错，但经过排查，并没有发现有什么异常。</p>
<p>后来，又尝试将数据分为4类，8类来训练，得到的结果依然是50%左右。</p>
<p>WTF？</p>
<h3 id="原来是偏斜类在搞鬼"><a href="#原来是偏斜类在搞鬼" class="headerlink" title="原来是偏斜类在搞鬼"></a>原来是偏斜类在搞鬼</h3><blockquote>
<p><a target="_blank" rel="noopener" href="http://t.cn/RSh83NE">这里有篇关于偏斜类的文章</a>，值得一看。</p>
</blockquote>
<p>我将原始数据绘制成柱状图之后，发现了问题所在：</p>
<p><img src="/img/17_12_20/011.png" alt=""></p>
<p>数据在各个类别上<strong>并不是均匀分布的</strong>，大部分都聚集在了10（对应涨跌幅为0%）的位置上。而我训练出来的模型，带入一批测试数据后，预测结果也都是10。</p>
<p>也就是说，我们的分类器，就算完全没有识别能力，输入任何值，输出的结果都是10这种类别，那么这个分类器就有50%的准确率！！！</p>
<p>这是一个很傻的结果，就好比一个完全不懂股票的人，你问他某只股票明天会不会涨，他只要回答：“明天不涨不跌”，那么他就有50%的概率猜对了。</p>
<p>好吧，这并不是我们想要的效果，那么我们如何避免这种情况呢？</p>
<h3 id="想办法让各个类别的数据呈现均匀分布"><a href="#想办法让各个类别的数据呈现均匀分布" class="headerlink" title="想办法让各个类别的数据呈现均匀分布"></a>想办法让各个类别的数据呈现均匀分布</h3><p>我想到的办法是在标签数据生成的过程中做些手脚。使得各个类别的数据呈现出均匀分布的情况。</p>
<p>所以我写了一个函数，用来将数据处理成均匀分布的标签：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def uniform_distribution(Y, n, l_type&#x3D;&#39;b&#39;):</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    平均分布</span><br><span class="line"></span><br><span class="line">    将Y按照值的大小进行均匀分布的方式分割成n等分</span><br><span class="line">    并生成对应的类别标签</span><br><span class="line"></span><br><span class="line">    :param Y: 数据源  形状为(num,)</span><br><span class="line">    :param n: 将数据分割为n等分</span><br><span class="line">    :param l_type: 分割数据之后 标签的取值类别&#123;&#39;b&#39;,&#39;s&#39;,&#39;n&#39;&#125;</span><br><span class="line">                &#39;b&#39; : 类别标签为区间范围内的最大值</span><br><span class="line">                &#39;s&#39; : 类别标签为区间范围内的最小值</span><br><span class="line">                &#39;n&#39; : 类别标签为区间范围内的平均值</span><br><span class="line"></span><br><span class="line">    :return:</span><br><span class="line"></span><br><span class="line">    eg：</span><br><span class="line">    Y &#x3D; [1,1,2,3,4,4,5,6,7]</span><br><span class="line">    n &#x3D; 5</span><br><span class="line">    l_type &#x3D; &#39;b&#39;</span><br><span class="line">    result &#x3D; [1 1 3 3 4 4 6 6 7]</span><br><span class="line"></span><br><span class="line">    n &#x3D; 3</span><br><span class="line">    l_type &#x3D; &#39;s&#39;</span><br><span class="line">    result &#x3D; [1 1 1 2 2 2 4 4 4]</span><br><span class="line"></span><br><span class="line">    n &#x3D; 5</span><br><span class="line">    l_type &#x3D; &#39;n&#39;</span><br><span class="line">    result &#x3D; [ 1.   1.   2.   2.   3.5  3.5  5.   5.   6.5]</span><br><span class="line"></span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line"></span><br><span class="line">    node_list &#x3D; gen_nodelist(Y, n)</span><br><span class="line">    toY &#x3D; []</span><br><span class="line">    for num in Y:</span><br><span class="line">    	# 这里虽然得到的是float类型的值，但tensorflow的类别标签 只能是int类型，所以将对应的索引作为标签值来使用</span><br><span class="line">        index, val &#x3D; get_label(num, node_list, l_type)</span><br><span class="line">        toY.append(index)</span><br><span class="line"></span><br><span class="line">    print(&quot;node list &gt;&gt;&quot;)</span><br><span class="line">    print(node_list)</span><br><span class="line">    return np.array(toY)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_label(num, node_list, l_type):</span><br><span class="line">    # 下限</span><br><span class="line">    lm &#x3D; 0</span><br><span class="line">    # 上限</span><br><span class="line">    um &#x3D; 0</span><br><span class="line">    target &#x3D; 0</span><br><span class="line"></span><br><span class="line">    # 节点区间是(lm,um]</span><br><span class="line">    for index, node in enumerate(node_list):</span><br><span class="line">        if node &gt;&#x3D; num:</span><br><span class="line">            if index &gt; 0:</span><br><span class="line">                um &#x3D; node</span><br><span class="line">                lm &#x3D; node_list[index - 1]</span><br><span class="line">                target &#x3D; index</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">    label &#x3D; &#39;&#39;</span><br><span class="line">    if l_type &#x3D;&#x3D; &#39;s&#39;:</span><br><span class="line">        label &#x3D; lm</span><br><span class="line">    elif l_type &#x3D;&#x3D; &#39;b&#39;:</span><br><span class="line">        label &#x3D; um</span><br><span class="line">    elif l_type &#x3D;&#x3D; &#39;n&#39;:</span><br><span class="line">        label &#x3D; (lm + um) &#x2F; 2</span><br><span class="line"></span><br><span class="line">    return target, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def gen_nodelist(data, n):</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    生成节点列表  节点是指示数据的分割点</span><br><span class="line">    :param data: 原始数据 需要被分割的数据</span><br><span class="line">    :param n: 分割的份数</span><br><span class="line">    :return:</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    sorted_list &#x3D; sorted(data)</span><br><span class="line">    size &#x3D; len(sorted_list)</span><br><span class="line">    node_list &#x3D; []</span><br><span class="line">    block_size &#x3D; math.ceil(size &#x2F; n)</span><br><span class="line">    for index, item in enumerate(sorted_list):</span><br><span class="line">        if (index + 1) % block_size &#x3D;&#x3D; 0:</span><br><span class="line">            node_list.append(item)</span><br><span class="line">        elif index &#x3D;&#x3D; 0:</span><br><span class="line">            node_list.append(item)</span><br><span class="line">        elif index &#x3D;&#x3D; size - 1:</span><br><span class="line">            node_list.append(item)</span><br><span class="line"></span><br><span class="line">    return node_list</span><br></pre></td></tr></table></figure>
<p>用这个函数重新预处理我们的Y，这里我们将Y分为10种类别，Y按照以下的标签值，重新赋值：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[-10.08, -2.3900000000000001, -1.4199999999999999, -0.84999999999999998, -0.40999999999999998, 0.0, 0.28999999999999998, 0.68999999999999995, 1.24, 2.25, 10.16]</span><br></pre></td></tr></table></figure>
<p>可以看到，这些标签值并不是线性的，这是因为我们的数据不是均匀分布的。</p>
<p>按照这种标签处理之后，将数据绘制成柱状图后，如下：</p>
<p><img src="/img/17_12_20/012.png" alt=""></p>
<p>接下来带入训练就比较正常了。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/11/30/10%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8BPandas/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="DannyLee">
      <meta itemprop="description" content="愿你的努力终取得成果">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="圣巢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/11/30/10%E5%88%86%E9%92%9F%E4%B8%8A%E6%89%8BPandas/" class="post-title-link" itemprop="url">10分钟上手Pandas</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-11-30 11:17:00" itemprop="dateCreated datePublished" datetime="2017-11-30T11:17:00+00:00">2017-11-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-10 17:00:48" itemprop="dateModified" datetime="2021-02-10T17:00:48+00:00">2021-02-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/10min.html">原文地址</a></p>
<p>这是关于pandas的一个简短的介绍，主要面向的是新手用户。你可以在<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/cookbook.html#cookbook">Cookbook</a>查看更多复杂的使用方式。</p>
<p>通常情况下，我们按照下面这种方式引入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In [1]: import pandas as pd</span><br><span class="line"></span><br><span class="line">In [2]: import numpy as np</span><br><span class="line"></span><br><span class="line">In [3]: import matplotlib.pyplot as plt</span><br></pre></td></tr></table></figure>
<h2 id="对象创建"><a href="#对象创建" class="headerlink" title="对象创建"></a>对象创建</h2><p>见<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dsintro">数据结构介绍部分</a>。</p>
<p>通过传入一个list的数值来创建一个<code>Series</code>，pandas会创建一个默认的整数索引:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [4]: s &#x3D; pd.Series([1,3,5,np.nan,6,8])</span><br><span class="line"></span><br><span class="line">In [5]: s</span><br><span class="line">Out[5]: </span><br><span class="line">0    1.0</span><br><span class="line">1    3.0</span><br><span class="line">2    5.0</span><br><span class="line">3    NaN</span><br><span class="line">4    6.0</span><br><span class="line">5    8.0</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<p>通过传入一个numpy数组来创建一个’DataFrame’，带有一个datetime的索引以及标签列:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">In [6]: dates &#x3D; pd.date_range(&#39;20130101&#39;, periods&#x3D;6)</span><br><span class="line"></span><br><span class="line">In [7]: dates</span><br><span class="line">Out[7]: </span><br><span class="line">DatetimeIndex([&#39;2013-01-01&#39;, &#39;2013-01-02&#39;, &#39;2013-01-03&#39;, &#39;2013-01-04&#39;,</span><br><span class="line">               &#39;2013-01-05&#39;, &#39;2013-01-06&#39;],</span><br><span class="line">              dtype&#x3D;&#39;datetime64[ns]&#39;, freq&#x3D;&#39;D&#39;)</span><br><span class="line"></span><br><span class="line">In [8]: df &#x3D; pd.DataFrame(np.random.randn(6,4), index&#x3D;dates, columns&#x3D;list(&#39;ABCD&#39;))</span><br><span class="line"></span><br><span class="line">In [9]: df</span><br><span class="line">Out[9]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-01  0.469112 -0.282863 -1.509059 -1.135632</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232 -1.087401</span><br><span class="line">2013-01-06 -0.673690  0.113648 -1.478427  0.524988</span><br></pre></td></tr></table></figure>
<p>通过传入一个可以转换为类series（series-like）的字典对象来创建一个<code>DataFrame</code>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [10]: df2 &#x3D; pd.DataFrame(&#123; &#39;A&#39; : 1.,</span><br><span class="line">   ....:                      &#39;B&#39; : pd.Timestamp(&#39;20130102&#39;),</span><br><span class="line">   ....:                      &#39;C&#39; : pd.Series(1,index&#x3D;list(range(4)),dtype&#x3D;&#39;float32&#39;),</span><br><span class="line">   ....:                      &#39;D&#39; : np.array([3] * 4,dtype&#x3D;&#39;int32&#39;),</span><br><span class="line">   ....:                      &#39;E&#39; : pd.Categorical([&quot;test&quot;,&quot;train&quot;,&quot;test&quot;,&quot;train&quot;]),</span><br><span class="line">   ....:                      &#39;F&#39; : &#39;foo&#39; &#125;)</span><br><span class="line">   ....: </span><br><span class="line"></span><br><span class="line">In [11]: df2</span><br><span class="line">Out[11]: </span><br><span class="line">     A          B    C  D      E    F</span><br><span class="line">0  1.0 2013-01-02  1.0  3   test  foo</span><br><span class="line">1  1.0 2013-01-02  1.0  3  train  foo</span><br><span class="line">2  1.0 2013-01-02  1.0  3   test  foo</span><br><span class="line">3  1.0 2013-01-02  1.0  3  train  foo</span><br></pre></td></tr></table></figure>
<p>查看不同列的数据类型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [12]: df2.dtypes</span><br><span class="line">Out[12]: </span><br><span class="line">A           float64</span><br><span class="line">B    datetime64[ns]</span><br><span class="line">C           float32</span><br><span class="line">D             int32</span><br><span class="line">E          category</span><br><span class="line">F            object</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure>
<p>如果你正在使用IPython，使用Tab自动补全功能会自动识别所有的属性以及自定义的列，下图中是所有能够被自动识别的属性的一个子集：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [13]: df2.&lt;TAB&gt;</span><br><span class="line">df2.A                  df2.bool</span><br><span class="line">df2.abs                df2.boxplot</span><br><span class="line">df2.add                df2.C</span><br><span class="line">df2.add_prefix         df2.clip</span><br><span class="line">df2.add_suffix         df2.clip_lower</span><br><span class="line">df2.align              df2.clip_upper</span><br><span class="line">df2.all                df2.columns</span><br><span class="line">df2.any                df2.combine</span><br><span class="line">df2.append             df2.combine_first</span><br><span class="line">df2.apply              df2.compound</span><br><span class="line">df2.applymap           df2.consolidate</span><br><span class="line">df2.D</span><br></pre></td></tr></table></figure>
<p>正如你所看的，这里的列<code>A</code>,<code>B</code>,<code>C</code>和<code>D</code>是自动补全的，为了简洁，其余的属性被截断。</p>
<h2 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h2><p>详情请参阅:<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/basics.html#basics">Basics section</a></p>
<p>查看frame中头部和尾部的行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [14]: df.head()</span><br><span class="line">Out[14]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-01  0.469112 -0.282863 -1.509059 -1.135632</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232 -1.087401</span><br><span class="line"></span><br><span class="line">In [15]: df.tail(3)</span><br><span class="line">Out[15]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232 -1.087401</span><br><span class="line">2013-01-06 -0.673690  0.113648 -1.478427  0.524988</span><br></pre></td></tr></table></figure>
<p>显示索引，列和底层numpy数据:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">In [16]: df.index</span><br><span class="line">Out[16]: </span><br><span class="line">DatetimeIndex([&#39;2013-01-01&#39;, &#39;2013-01-02&#39;, &#39;2013-01-03&#39;, &#39;2013-01-04&#39;,</span><br><span class="line">               &#39;2013-01-05&#39;, &#39;2013-01-06&#39;],</span><br><span class="line">              dtype&#x3D;&#39;datetime64[ns]&#39;, freq&#x3D;&#39;D&#39;)</span><br><span class="line"></span><br><span class="line">In [17]: df.columns</span><br><span class="line">Out[17]: Index([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;], dtype&#x3D;&#39;object&#39;)</span><br><span class="line"></span><br><span class="line">In [18]: df.values</span><br><span class="line">Out[18]: </span><br><span class="line">array([[ 0.4691, -0.2829, -1.5091, -1.1356],</span><br><span class="line">       [ 1.2121, -0.1732,  0.1192, -1.0442],</span><br><span class="line">       [-0.8618, -2.1046, -0.4949,  1.0718],</span><br><span class="line">       [ 0.7216, -0.7068, -1.0396,  0.2719],</span><br><span class="line">       [-0.425 ,  0.567 ,  0.2762, -1.0874],</span><br><span class="line">       [-0.6737,  0.1136, -1.4784,  0.525 ]])</span><br></pre></td></tr></table></figure>
<p><code>describe()</code>函数对于数据的快速统计汇总：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [19]: df.describe()</span><br><span class="line">Out[19]: </span><br><span class="line">              A         B         C         D</span><br><span class="line">count  6.000000  6.000000  6.000000  6.000000</span><br><span class="line">mean   0.073711 -0.431125 -0.687758 -0.233103</span><br><span class="line">std    0.843157  0.922818  0.779887  0.973118</span><br><span class="line">min   -0.861849 -2.104569 -1.509059 -1.135632</span><br><span class="line">25%   -0.611510 -0.600794 -1.368714 -1.076610</span><br><span class="line">50%    0.022070 -0.228039 -0.767252 -0.386188</span><br><span class="line">75%    0.658444  0.041933 -0.034326  0.461706</span><br><span class="line">max    1.212112  0.567020  0.276232  1.071804</span><br></pre></td></tr></table></figure>
<p>对数据的转置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [20]: df.T</span><br><span class="line">Out[20]: </span><br><span class="line">   2013-01-01  2013-01-02  2013-01-03  2013-01-04  2013-01-05  2013-01-06</span><br><span class="line">A    0.469112    1.212112   -0.861849    0.721555   -0.424972   -0.673690</span><br><span class="line">B   -0.282863   -0.173215   -2.104569   -0.706771    0.567020    0.113648</span><br><span class="line">C   -1.509059    0.119209   -0.494929   -1.039575    0.276232   -1.478427</span><br><span class="line">D   -1.135632   -1.044236    1.071804    0.271860   -1.087401    0.524988</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>按轴进行排序</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [21]: df.sort_index(axis&#x3D;1, ascending&#x3D;False)</span><br><span class="line">Out[21]: </span><br><span class="line">                   D         C         B         A</span><br><span class="line">2013-01-01 -1.135632 -1.509059 -0.282863  0.469112</span><br><span class="line">2013-01-02 -1.044236  0.119209 -0.173215  1.212112</span><br><span class="line">2013-01-03  1.071804 -0.494929 -2.104569 -0.861849</span><br><span class="line">2013-01-04  0.271860 -1.039575 -0.706771  0.721555</span><br><span class="line">2013-01-05 -1.087401  0.276232  0.567020 -0.424972</span><br><span class="line">2013-01-06  0.524988 -1.478427  0.113648 -0.673690</span><br></pre></td></tr></table></figure>
<p>按值进行排序</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [22]: df.sort_values(by&#x3D;&#39;B&#39;)</span><br><span class="line">Out[22]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860</span><br><span class="line">2013-01-01  0.469112 -0.282863 -1.509059 -1.135632</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-06 -0.673690  0.113648 -1.478427  0.524988</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232 -1.087401</span><br></pre></td></tr></table></figure>
<h2 id="选择"><a href="#选择" class="headerlink" title="选择"></a>选择</h2><blockquote>
<p><strong>注意：</strong>虽然用于选择和设置的标准的Python/Numpy表达式非常直观，可用于交互式工作，但对于生产代码，我们推荐优化的pandas数据访问方法<code>.at</code>，<code>.iat</code>，<code>.loc</code>，<code>.iloc</code>和<code>.ix</code>。</p>
</blockquote>
<p>详情请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing">Indexing and Selecing Data</a>和 <a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/advanced.html#advanced">MultiIndex / Advanced Indexing</a>。</p>
<h3 id="获取"><a href="#获取" class="headerlink" title="获取"></a>获取</h3><p>选择一个单独的列，这将会返回一个<code>Series</code>，等同于<code>df.A</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [23]: df[&#39;A&#39;]</span><br><span class="line">Out[23]: </span><br><span class="line">2013-01-01    0.469112</span><br><span class="line">2013-01-02    1.212112</span><br><span class="line">2013-01-03   -0.861849</span><br><span class="line">2013-01-04    0.721555</span><br><span class="line">2013-01-05   -0.424972</span><br><span class="line">2013-01-06   -0.673690</span><br><span class="line">Freq: D, Name: A, dtype: float64</span><br></pre></td></tr></table></figure>
<p>通过<code>[]</code>进行选择，这将会对行进行切片:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [24]: df[0:3]</span><br><span class="line">Out[24]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-01  0.469112 -0.282863 -1.509059 -1.135632</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804</span><br><span class="line"></span><br><span class="line">In [25]: df[&#39;20130102&#39;:&#39;20130104&#39;]</span><br><span class="line">Out[25]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860</span><br></pre></td></tr></table></figure>
<h3 id="通过标签选择"><a href="#通过标签选择" class="headerlink" title="通过标签选择"></a>通过标签选择</h3><p>详情请参加<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-label">Selection by Label</a></p>
<p>使用标签获取横截面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [26]: df.loc[dates[0]]</span><br><span class="line">Out[26]: </span><br><span class="line">A    0.469112</span><br><span class="line">B   -0.282863</span><br><span class="line">C   -1.509059</span><br><span class="line">D   -1.135632</span><br><span class="line">Name: 2013-01-01 00:00:00, dtype: float64</span><br></pre></td></tr></table></figure>
<p>通过标签选择多轴</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [27]: df.loc[:,[&#39;A&#39;,&#39;B&#39;]]</span><br><span class="line">Out[27]: </span><br><span class="line">                   A         B</span><br><span class="line">2013-01-01  0.469112 -0.282863</span><br><span class="line">2013-01-02  1.212112 -0.173215</span><br><span class="line">2013-01-03 -0.861849 -2.104569</span><br><span class="line">2013-01-04  0.721555 -0.706771</span><br><span class="line">2013-01-05 -0.424972  0.567020</span><br><span class="line">2013-01-06 -0.673690  0.113648</span><br></pre></td></tr></table></figure>
<p>显示包括两个端点的标签切片：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [28]: df.loc[&#39;20130102&#39;:&#39;20130104&#39;,[&#39;A&#39;,&#39;B&#39;]]</span><br><span class="line">Out[28]: </span><br><span class="line">                   A         B</span><br><span class="line">2013-01-02  1.212112 -0.173215</span><br><span class="line">2013-01-03 -0.861849 -2.104569</span><br><span class="line">2013-01-04  0.721555 -0.706771</span><br></pre></td></tr></table></figure>
<p>减少返回的对象的尺寸:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In [29]: df.loc[&#39;20130102&#39;,[&#39;A&#39;,&#39;B&#39;]]</span><br><span class="line">Out[29]: </span><br><span class="line">A    1.212112</span><br><span class="line">B   -0.173215</span><br><span class="line">Name: 2013-01-02 00:00:00, dtype: float64</span><br></pre></td></tr></table></figure>
<p>获得标量值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [30]: df.loc[dates[0],&#39;A&#39;]</span><br><span class="line">Out[30]: 0.46911229990718628</span><br></pre></td></tr></table></figure>
<p>快速访问一个标量（与上一个方法等价）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [31]: df.at[dates[0],&#39;A&#39;]</span><br><span class="line">Out[31]: 0.46911229990718628</span><br></pre></td></tr></table></figure>
<h3 id="按位置选择"><a href="#按位置选择" class="headerlink" title="按位置选择"></a>按位置选择</h3><p>详情请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-integer">Selection by Position</a></p>
<p>通过传入的整数位置来选择：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [32]: df.iloc[3]</span><br><span class="line">Out[32]: </span><br><span class="line">A    0.721555</span><br><span class="line">B   -0.706771</span><br><span class="line">C   -1.039575</span><br><span class="line">D    0.271860</span><br><span class="line">Name: 2013-01-04 00:00:00, dtype: float64</span><br></pre></td></tr></table></figure>
<p>可以做类似numpy/python的整数切片操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In [33]: df.iloc[3:5,0:2]</span><br><span class="line">Out[33]: </span><br><span class="line">                   A         B</span><br><span class="line">2013-01-04  0.721555 -0.706771</span><br><span class="line">2013-01-05 -0.424972  0.567020</span><br></pre></td></tr></table></figure>
<p>可以做类似于numpy/python风格的列出指定索引位置的行列列表的操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [34]: df.iloc[[1,2,4],[0,2]]</span><br><span class="line">Out[34]: </span><br><span class="line">                   A         C</span><br><span class="line">2013-01-02  1.212112  0.119209</span><br><span class="line">2013-01-03 -0.861849 -0.494929</span><br><span class="line">2013-01-05 -0.424972  0.276232</span><br></pre></td></tr></table></figure>
<p>选择具体的行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In [35]: df.iloc[1:3,:]</span><br><span class="line">Out[35]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804</span><br></pre></td></tr></table></figure>
<p>选择具体的列</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [36]: df.iloc[:,1:3]</span><br><span class="line">Out[36]: </span><br><span class="line">                   B         C</span><br><span class="line">2013-01-01 -0.282863 -1.509059</span><br><span class="line">2013-01-02 -0.173215  0.119209</span><br><span class="line">2013-01-03 -2.104569 -0.494929</span><br><span class="line">2013-01-04 -0.706771 -1.039575</span><br><span class="line">2013-01-05  0.567020  0.276232</span><br><span class="line">2013-01-06  0.113648 -1.478427</span><br></pre></td></tr></table></figure>
<p>明确地获取一个值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [37]: df.iloc[1,1]</span><br><span class="line">Out[37]: -0.17321464905330858</span><br></pre></td></tr></table></figure>
<p>快速访问一个标量（等同于上面的方法）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [38]: df.iat[1,1]</span><br><span class="line">Out[38]: -0.17321464905330858</span><br></pre></td></tr></table></figure>
<h3 id="布尔索引操作"><a href="#布尔索引操作" class="headerlink" title="布尔索引操作"></a>布尔索引操作</h3><p>使用单一列的值来选取数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [39]: df[df.A &gt; 0]</span><br><span class="line">Out[39]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-01  0.469112 -0.282863 -1.509059 -1.135632</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860</span><br></pre></td></tr></table></figure>
<p>从DataFrame选取符合布尔判断条件的数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [40]: df[df &gt; 0]</span><br><span class="line">Out[40]: </span><br><span class="line">                   A         B         C         D</span><br><span class="line">2013-01-01  0.469112       NaN       NaN       NaN</span><br><span class="line">2013-01-02  1.212112       NaN  0.119209       NaN</span><br><span class="line">2013-01-03       NaN       NaN       NaN  1.071804</span><br><span class="line">2013-01-04  0.721555       NaN       NaN  0.271860</span><br><span class="line">2013-01-05       NaN  0.567020  0.276232       NaN</span><br><span class="line">2013-01-06       NaN  0.113648       NaN  0.524988</span><br></pre></td></tr></table></figure>
<p>使用<code>isin()</code>方法来过滤：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">In [41]: df2 &#x3D; df.copy()</span><br><span class="line"></span><br><span class="line">In [42]: df2[&#39;E&#39;] &#x3D; [&#39;one&#39;, &#39;one&#39;,&#39;two&#39;,&#39;three&#39;,&#39;four&#39;,&#39;three&#39;]</span><br><span class="line"></span><br><span class="line">In [43]: df2</span><br><span class="line">Out[43]: </span><br><span class="line">                   A         B         C         D      E</span><br><span class="line">2013-01-01  0.469112 -0.282863 -1.509059 -1.135632    one</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209 -1.044236    one</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804    two</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  0.271860  three</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232 -1.087401   four</span><br><span class="line">2013-01-06 -0.673690  0.113648 -1.478427  0.524988  three</span><br><span class="line"></span><br><span class="line">In [44]: df2[df2[&#39;E&#39;].isin([&#39;two&#39;,&#39;four&#39;])]</span><br><span class="line">Out[44]: </span><br><span class="line">                   A         B         C         D     E</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  1.071804   two</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232 -1.087401  four</span><br></pre></td></tr></table></figure>
<h3 id="设置数据"><a href="#设置数据" class="headerlink" title="设置数据"></a>设置数据</h3><p>设置新列，自动按索引排列数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [45]: s1 &#x3D; pd.Series([1,2,3,4,5,6], index&#x3D;pd.date_range(&#39;20130102&#39;, periods&#x3D;6))</span><br><span class="line"></span><br><span class="line">In [46]: s1</span><br><span class="line">Out[46]: </span><br><span class="line">2013-01-02    1</span><br><span class="line">2013-01-03    2</span><br><span class="line">2013-01-04    3</span><br><span class="line">2013-01-05    4</span><br><span class="line">2013-01-06    5</span><br><span class="line">2013-01-07    6</span><br><span class="line">Freq: D, dtype: int64</span><br><span class="line"></span><br><span class="line">In [47]: df[&#39;F&#39;] &#x3D; s1</span><br></pre></td></tr></table></figure>
<p>通过标签来设定数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [48]: df.at[dates[0],&#39;A&#39;] &#x3D; 0</span><br></pre></td></tr></table></figure>
<p>通过位置索引来设定数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [49]: df.iat[0,1] &#x3D; 0</span><br></pre></td></tr></table></figure>
<p>通过分配一个numpy数组来设定数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [50]: df.loc[:,&#39;D&#39;] &#x3D; np.array([5] * len(df))</span><br></pre></td></tr></table></figure>
<p>之前操作的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [51]: df</span><br><span class="line">Out[51]: </span><br><span class="line">                   A         B         C  D    F</span><br><span class="line">2013-01-01  0.000000  0.000000 -1.509059  5  NaN</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209  5  1.0</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  5  2.0</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  5  3.0</span><br><span class="line">2013-01-05 -0.424972  0.567020  0.276232  5  4.0</span><br><span class="line">2013-01-06 -0.673690  0.113648 -1.478427  5  5.0</span><br></pre></td></tr></table></figure>
<p>带有<code>where</code>操作的设值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [52]: df2 &#x3D; df.copy()</span><br><span class="line"></span><br><span class="line">In [53]: df2[df2 &gt; 0] &#x3D; -df2</span><br><span class="line"></span><br><span class="line">In [54]: df2</span><br><span class="line">Out[54]: </span><br><span class="line">                   A         B         C  D    F</span><br><span class="line">2013-01-01  0.000000  0.000000 -1.509059 -5  NaN</span><br><span class="line">2013-01-02 -1.212112 -0.173215 -0.119209 -5 -1.0</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929 -5 -2.0</span><br><span class="line">2013-01-04 -0.721555 -0.706771 -1.039575 -5 -3.0</span><br><span class="line">2013-01-05 -0.424972 -0.567020 -0.276232 -5 -4.0</span><br><span class="line">2013-01-06 -0.673690 -0.113648 -1.478427 -5 -5.0</span><br></pre></td></tr></table></figure>
<h2 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h2><p>pandas主要使用<code>np.nan</code>来代表缺失数据。这些值将默认不会包含在计算中，详情请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/missing_data.html#missing-data">Missing Data section</a></p>
<p>Reindexing允许您更改/添加/删除指定轴上的索引。这将返回数据的副本。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [55]: df1 &#x3D; df.reindex(index&#x3D;dates[0:4], columns&#x3D;list(df.columns) + [&#39;E&#39;])</span><br><span class="line"></span><br><span class="line">In [56]: df1.loc[dates[0]:dates[1],&#39;E&#39;] &#x3D; 1</span><br><span class="line"></span><br><span class="line">In [57]: df1</span><br><span class="line">Out[57]: </span><br><span class="line">                   A         B         C  D    F    E</span><br><span class="line">2013-01-01  0.000000  0.000000 -1.509059  5  NaN  1.0</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209  5  1.0  1.0</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  5  2.0  NaN</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  5  3.0  NaN</span><br></pre></td></tr></table></figure>
<p>删除所有具有缺失值的数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [58]: df1.dropna(how&#x3D;&#39;any&#39;)</span><br><span class="line">Out[58]: </span><br><span class="line">                   A         B         C  D    F    E</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209  5  1.0  1.0</span><br></pre></td></tr></table></figure>
<p>填充缺失数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [59]: df1.fillna(value&#x3D;5)</span><br><span class="line">Out[59]: </span><br><span class="line">                   A         B         C  D    F    E</span><br><span class="line">2013-01-01  0.000000  0.000000 -1.509059  5  5.0  1.0</span><br><span class="line">2013-01-02  1.212112 -0.173215  0.119209  5  1.0  1.0</span><br><span class="line">2013-01-03 -0.861849 -2.104569 -0.494929  5  2.0  5.0</span><br><span class="line">2013-01-04  0.721555 -0.706771 -1.039575  5  3.0  5.0</span><br></pre></td></tr></table></figure>
<p>获取值为nan的布尔值掩码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [60]: pd.isna(df1)</span><br><span class="line">Out[60]: </span><br><span class="line">                A      B      C      D      F      E</span><br><span class="line">2013-01-01  False  False  False  False   True  False</span><br><span class="line">2013-01-02  False  False  False  False  False  False</span><br><span class="line">2013-01-03  False  False  False  False  False   True</span><br><span class="line">2013-01-04  False  False  False  False  False   True</span><br></pre></td></tr></table></figure>
<h2 id="相关操作"><a href="#相关操作" class="headerlink" title="相关操作"></a>相关操作</h2><p>详情请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/basics.html#basics-binop">Basic section on Binary Ops</a></p>
<h3 id="统计"><a href="#统计" class="headerlink" title="统计"></a>统计</h3><p>一般操作不包括丢失的数据。</p>
<p>执行描述性统计操作(沿数值方向求均值)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [61]: df.mean()</span><br><span class="line">Out[61]: </span><br><span class="line">A   -0.004474</span><br><span class="line">B   -0.383981</span><br><span class="line">C   -0.687758</span><br><span class="line">D    5.000000</span><br><span class="line">F    3.000000</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<p>在另一个轴上做相同的操作(沿水平方向求均值)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [62]: df.mean(1)</span><br><span class="line">Out[62]: </span><br><span class="line">2013-01-01    0.872735</span><br><span class="line">2013-01-02    1.431621</span><br><span class="line">2013-01-03    0.707731</span><br><span class="line">2013-01-04    1.395042</span><br><span class="line">2013-01-05    1.883656</span><br><span class="line">2013-01-06    1.592306</span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure>
<p>使用具有不同维度且需要对齐的对象进行操作。另外，pandas会沿指定的尺寸自动广播。</p>
<blockquote>
<p>注意：1-np.nan 输出结果为NaN</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">In [63]: s &#x3D; pd.Series([1,3,5,np.nan,6,8], index&#x3D;dates).shift(2)</span><br><span class="line"></span><br><span class="line">In [64]: s</span><br><span class="line">Out[64]: </span><br><span class="line">2013-01-01    NaN</span><br><span class="line">2013-01-02    NaN</span><br><span class="line">2013-01-03    1.0</span><br><span class="line">2013-01-04    3.0</span><br><span class="line">2013-01-05    5.0</span><br><span class="line">2013-01-06    NaN</span><br><span class="line">Freq: D, dtype: float64</span><br><span class="line"></span><br><span class="line">In [65]: df.sub(s, axis&#x3D;&#39;index&#39;)</span><br><span class="line">Out[65]: </span><br><span class="line">                   A         B         C    D    F</span><br><span class="line">2013-01-01       NaN       NaN       NaN  NaN  NaN</span><br><span class="line">2013-01-02       NaN       NaN       NaN  NaN  NaN</span><br><span class="line">2013-01-03 -1.861849 -3.104569 -1.494929  4.0  1.0</span><br><span class="line">2013-01-04 -2.278445 -3.706771 -4.039575  2.0  0.0</span><br><span class="line">2013-01-05 -5.424972 -4.432980 -4.723768  0.0 -1.0</span><br><span class="line">2013-01-06       NaN       NaN       NaN  NaN  NaN</span><br></pre></td></tr></table></figure>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>将函数应用于数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 累加操作</span><br><span class="line">In [66]: df.apply(np.cumsum)</span><br><span class="line">Out[66]: </span><br><span class="line">                   A         B         C   D     F</span><br><span class="line">2013-01-01  0.000000  0.000000 -1.509059   5   NaN</span><br><span class="line">2013-01-02  1.212112 -0.173215 -1.389850  10   1.0</span><br><span class="line">2013-01-03  0.350263 -2.277784 -1.884779  15   3.0</span><br><span class="line">2013-01-04  1.071818 -2.984555 -2.924354  20   6.0</span><br><span class="line">2013-01-05  0.646846 -2.417535 -2.648122  25  10.0</span><br><span class="line">2013-01-06 -0.026844 -2.303886 -4.126549  30  15.0</span><br><span class="line"></span><br><span class="line">In [67]: df.apply(lambda x: x.max() - x.min())</span><br><span class="line">Out[67]: </span><br><span class="line">A    2.073961</span><br><span class="line">B    2.671590</span><br><span class="line">C    1.785291</span><br><span class="line">D    0.000000</span><br><span class="line">F    4.000000</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<h3 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h3><p>详情请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/basics.html#basics-discretization">Histogramming and Discretization</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">In [68]: s &#x3D; pd.Series(np.random.randint(0, 7, size&#x3D;10))</span><br><span class="line"></span><br><span class="line">In [69]: s</span><br><span class="line">Out[69]: </span><br><span class="line">0    4</span><br><span class="line">1    2</span><br><span class="line">2    1</span><br><span class="line">3    2</span><br><span class="line">4    6</span><br><span class="line">5    4</span><br><span class="line">6    4</span><br><span class="line">7    6</span><br><span class="line">8    4</span><br><span class="line">9    4</span><br><span class="line">dtype: int64</span><br><span class="line"></span><br><span class="line">In [70]: s.value_counts()</span><br><span class="line">Out[70]: </span><br><span class="line">4    5</span><br><span class="line">6    2</span><br><span class="line">2    2</span><br><span class="line">1    1</span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure>
<h3 id="字符串方法"><a href="#字符串方法" class="headerlink" title="字符串方法"></a>字符串方法</h3><p>Series对象在其str属性中配备了一组字符串处理方法，可以很容易的应用到数组中的每个元素，如下段代码所示。更多详情请参考：<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/text.html#text-string-methods">Vectorized String Methods</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [71]: s &#x3D; pd.Series([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;Aaba&#39;, &#39;Baca&#39;, np.nan, &#39;CABA&#39;, &#39;dog&#39;, &#39;cat&#39;])</span><br><span class="line"></span><br><span class="line">In [72]: s.str.lower()</span><br><span class="line">Out[72]: </span><br><span class="line">0       a</span><br><span class="line">1       b</span><br><span class="line">2       c</span><br><span class="line">3    aaba</span><br><span class="line">4    baca</span><br><span class="line">5     NaN</span><br><span class="line">6    caba</span><br><span class="line">7     dog</span><br><span class="line">8     cat</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure>
<h2 id="合并"><a href="#合并" class="headerlink" title="合并"></a>合并</h2><h3 id="Concat"><a href="#Concat" class="headerlink" title="Concat"></a>Concat</h3><p>Pandas提供了大量的方法能够轻松的对Series，DataFrame和Panel对象进行各种符合各种逻辑关系的合并操作。</p>
<p>具体请参阅：<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/merging.html#merging">Merging section</a></p>
<p>通过使用<code>concat()</code>来将pandas对象链接起来：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">In [73]: df &#x3D; pd.DataFrame(np.random.randn(10, 4))</span><br><span class="line"></span><br><span class="line">In [74]: df</span><br><span class="line">Out[74]: </span><br><span class="line">          0         1         2         3</span><br><span class="line">0 -0.548702  1.467327 -1.015962 -0.483075</span><br><span class="line">1  1.637550 -1.217659 -0.291519 -1.745505</span><br><span class="line">2 -0.263952  0.991460 -0.919069  0.266046</span><br><span class="line">3 -0.709661  1.669052  1.037882 -1.705775</span><br><span class="line">4 -0.919854 -0.042379  1.247642 -0.009920</span><br><span class="line">5  0.290213  0.495767  0.362949  1.548106</span><br><span class="line">6 -1.131345 -0.089329  0.337863 -0.945867</span><br><span class="line">7 -0.932132  1.956030  0.017587 -0.016692</span><br><span class="line">8 -0.575247  0.254161 -1.143704  0.215897</span><br><span class="line">9  1.193555 -0.077118 -0.408530 -0.862495</span><br><span class="line"></span><br><span class="line"># break it into pieces</span><br><span class="line">In [75]: pieces &#x3D; [df[:3], df[3:7], df[7:]]</span><br><span class="line"></span><br><span class="line">In [76]: pd.concat(pieces)</span><br><span class="line">Out[76]: </span><br><span class="line">          0         1         2         3</span><br><span class="line">0 -0.548702  1.467327 -1.015962 -0.483075</span><br><span class="line">1  1.637550 -1.217659 -0.291519 -1.745505</span><br><span class="line">2 -0.263952  0.991460 -0.919069  0.266046</span><br><span class="line">3 -0.709661  1.669052  1.037882 -1.705775</span><br><span class="line">4 -0.919854 -0.042379  1.247642 -0.009920</span><br><span class="line">5  0.290213  0.495767  0.362949  1.548106</span><br><span class="line">6 -1.131345 -0.089329  0.337863 -0.945867</span><br><span class="line">7 -0.932132  1.956030  0.017587 -0.016692</span><br><span class="line">8 -0.575247  0.254161 -1.143704  0.215897</span><br><span class="line">9  1.193555 -0.077118 -0.408530 -0.862495</span><br></pre></td></tr></table></figure>
<h3 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h3><p>类似于SQL类型的合并</p>
<p>具体请参阅：<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/merging.html#merging-join">Database style joining</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">In [77]: left &#x3D; pd.DataFrame(&#123;&#39;key&#39;: [&#39;foo&#39;, &#39;foo&#39;], &#39;lval&#39;: [1, 2]&#125;)</span><br><span class="line"></span><br><span class="line">In [78]: right &#x3D; pd.DataFrame(&#123;&#39;key&#39;: [&#39;foo&#39;, &#39;foo&#39;], &#39;rval&#39;: [4, 5]&#125;)</span><br><span class="line"></span><br><span class="line">In [79]: left</span><br><span class="line">Out[79]: </span><br><span class="line">   key  lval</span><br><span class="line">0  foo     1</span><br><span class="line">1  foo     2</span><br><span class="line"></span><br><span class="line">In [80]: right</span><br><span class="line">Out[80]: </span><br><span class="line">   key  rval</span><br><span class="line">0  foo     4</span><br><span class="line">1  foo     5</span><br><span class="line"></span><br><span class="line">In [81]: pd.merge(left, right, on&#x3D;&#39;key&#39;)</span><br><span class="line">Out[81]: </span><br><span class="line">   key  lval  rval</span><br><span class="line">0  foo     1     4</span><br><span class="line">1  foo     1     5</span><br><span class="line">2  foo     2     4</span><br><span class="line">3  foo     2     5</span><br></pre></td></tr></table></figure>
<p>另一个可以给出的例子是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">In [82]: left &#x3D; pd.DataFrame(&#123;&#39;key&#39;: [&#39;foo&#39;, &#39;bar&#39;], &#39;lval&#39;: [1, 2]&#125;)</span><br><span class="line"></span><br><span class="line">In [83]: right &#x3D; pd.DataFrame(&#123;&#39;key&#39;: [&#39;foo&#39;, &#39;bar&#39;], &#39;rval&#39;: [4, 5]&#125;)</span><br><span class="line"></span><br><span class="line">In [84]: left</span><br><span class="line">Out[84]: </span><br><span class="line">   key  lval</span><br><span class="line">0  foo     1</span><br><span class="line">1  bar     2</span><br><span class="line"></span><br><span class="line">In [85]: right</span><br><span class="line">Out[85]: </span><br><span class="line">   key  rval</span><br><span class="line">0  foo     4</span><br><span class="line">1  bar     5</span><br><span class="line"></span><br><span class="line">In [86]: pd.merge(left, right, on&#x3D;&#39;key&#39;)</span><br><span class="line">Out[86]: </span><br><span class="line">   key  lval  rval</span><br><span class="line">0  foo     1     4</span><br><span class="line">1  bar     2     5</span><br></pre></td></tr></table></figure>
<h3 id="Append"><a href="#Append" class="headerlink" title="Append"></a>Append</h3><p>将一行连接到一个DataFrame上。</p>
<p>详情请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/merging.html#merging-concatenation">Appending</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">In [87]: df &#x3D; pd.DataFrame(np.random.randn(8, 4), columns&#x3D;[&#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;D&#39;])</span><br><span class="line"></span><br><span class="line">In [88]: df</span><br><span class="line">Out[88]: </span><br><span class="line">          A         B         C         D</span><br><span class="line">0  1.346061  1.511763  1.627081 -0.990582</span><br><span class="line">1 -0.441652  1.211526  0.268520  0.024580</span><br><span class="line">2 -1.577585  0.396823 -0.105381 -0.532532</span><br><span class="line">3  1.453749  1.208843 -0.080952 -0.264610</span><br><span class="line">4 -0.727965 -0.589346  0.339969 -0.693205</span><br><span class="line">5 -0.339355  0.593616  0.884345  1.591431</span><br><span class="line">6  0.141809  0.220390  0.435589  0.192451</span><br><span class="line">7 -0.096701  0.803351  1.715071 -0.708758</span><br><span class="line"></span><br><span class="line">In [89]: s &#x3D; df.iloc[3]</span><br><span class="line"></span><br><span class="line">In [90]: df.append(s, ignore_index&#x3D;True)</span><br><span class="line">Out[90]: </span><br><span class="line">          A         B         C         D</span><br><span class="line">0  1.346061  1.511763  1.627081 -0.990582</span><br><span class="line">1 -0.441652  1.211526  0.268520  0.024580</span><br><span class="line">2 -1.577585  0.396823 -0.105381 -0.532532</span><br><span class="line">3  1.453749  1.208843 -0.080952 -0.264610</span><br><span class="line">4 -0.727965 -0.589346  0.339969 -0.693205</span><br><span class="line">5 -0.339355  0.593616  0.884345  1.591431</span><br><span class="line">6  0.141809  0.220390  0.435589  0.192451</span><br><span class="line">7 -0.096701  0.803351  1.715071 -0.708758</span><br><span class="line">8  1.453749  1.208843 -0.080952 -0.264610</span><br></pre></td></tr></table></figure>
<h2 id="分组（Grouping）"><a href="#分组（Grouping）" class="headerlink" title="分组（Grouping）"></a>分组（Grouping）</h2><p>对于”group by”操作，我们通常是指以下一个或多个操作步骤：</p>
<ul>
<li><strong>（Splitting）</strong>按照一些规则将数据分为不同的组；</li>
<li><strong>（Applying）</strong>对于每组数据分别执行一个函数；</li>
<li><strong>（Combining）</strong>将结果组合到一个数据结构中；</li>
</ul>
<p>详情请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/groupby.html#groupby">Grouping section</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">In [91]: df &#x3D; pd.DataFrame(&#123;&#39;A&#39; : [&#39;foo&#39;, &#39;bar&#39;, &#39;foo&#39;, &#39;bar&#39;,</span><br><span class="line">   ....:                           &#39;foo&#39;, &#39;bar&#39;, &#39;foo&#39;, &#39;foo&#39;],</span><br><span class="line">   ....:                    &#39;B&#39; : [&#39;one&#39;, &#39;one&#39;, &#39;two&#39;, &#39;three&#39;,</span><br><span class="line">   ....:                           &#39;two&#39;, &#39;two&#39;, &#39;one&#39;, &#39;three&#39;],</span><br><span class="line">   ....:                    &#39;C&#39; : np.random.randn(8),</span><br><span class="line">   ....:                    &#39;D&#39; : np.random.randn(8)&#125;)</span><br><span class="line">   ....: </span><br><span class="line"></span><br><span class="line">In [92]: df</span><br><span class="line">Out[92]: </span><br><span class="line">     A      B         C         D</span><br><span class="line">0  foo    one -1.202872 -0.055224</span><br><span class="line">1  bar    one -1.814470  2.395985</span><br><span class="line">2  foo    two  1.018601  1.552825</span><br><span class="line">3  bar  three -0.595447  0.166599</span><br><span class="line">4  foo    two  1.395433  0.047609</span><br><span class="line">5  bar    two -0.392670 -0.136473</span><br><span class="line">6  foo    one  0.007207 -0.561757</span><br><span class="line">7  foo  three  1.928123 -1.623033</span><br></pre></td></tr></table></figure>
<p>分组，然后将函数总和<code>sum</code>应用于结果组。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [93]: df.groupby(&#39;A&#39;).sum()</span><br><span class="line">Out[93]: </span><br><span class="line">            C        D</span><br><span class="line">A                     </span><br><span class="line">bar -2.802588  2.42611</span><br><span class="line">foo  3.146492 -0.63958</span><br></pre></td></tr></table></figure>
<p>按多列分组会形成一个分层索引，然后我们应用这个函数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [94]: df.groupby([&#39;A&#39;,&#39;B&#39;]).sum()</span><br><span class="line">Out[94]: </span><br><span class="line">                  C         D</span><br><span class="line">A   B                        </span><br><span class="line">bar one   -1.814470  2.395985</span><br><span class="line">    three -0.595447  0.166599</span><br><span class="line">    two   -0.392670 -0.136473</span><br><span class="line">foo one   -1.195665 -0.616981</span><br><span class="line">    three  1.928123 -1.623033</span><br><span class="line">    two    2.414034  1.600434</span><br></pre></td></tr></table></figure>
<h2 id="Reshaping"><a href="#Reshaping" class="headerlink" title="Reshaping"></a>Reshaping</h2><p>详情请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/advanced.html#advanced-hierarchical">Hierarchical Indexing</a>和<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-stacking">Reshaping</a>。</p>
<h3 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">In [95]: tuples &#x3D; list(zip(*[[&#39;bar&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;baz&#39;,</span><br><span class="line">   ....:                      &#39;foo&#39;, &#39;foo&#39;, &#39;qux&#39;, &#39;qux&#39;],</span><br><span class="line">   ....:                     [&#39;one&#39;, &#39;two&#39;, &#39;one&#39;, &#39;two&#39;,</span><br><span class="line">   ....:                      &#39;one&#39;, &#39;two&#39;, &#39;one&#39;, &#39;two&#39;]]))</span><br><span class="line">   ....: </span><br><span class="line"></span><br><span class="line">In [96]: index &#x3D; pd.MultiIndex.from_tuples(tuples, names&#x3D;[&#39;first&#39;, &#39;second&#39;])</span><br><span class="line"></span><br><span class="line">In [97]: df &#x3D; pd.DataFrame(np.random.randn(8, 2), index&#x3D;index, columns&#x3D;[&#39;A&#39;, &#39;B&#39;])</span><br><span class="line"></span><br><span class="line">In [98]: df2 &#x3D; df[:4]</span><br><span class="line"></span><br><span class="line">In [99]: df2</span><br><span class="line">Out[99]: </span><br><span class="line">                     A         B</span><br><span class="line">first second                    </span><br><span class="line">bar   one     0.029399 -0.542108</span><br><span class="line">      two     0.282696 -0.087302</span><br><span class="line">baz   one    -1.575170  1.771208</span><br><span class="line">      two     0.816482  1.100230</span><br></pre></td></tr></table></figure>
<p><code>stack()</code>方法“压缩”了DataFrame列中的级别。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [100]: stacked &#x3D; df2.stack()</span><br><span class="line"></span><br><span class="line">In [101]: stacked</span><br><span class="line">Out[101]: </span><br><span class="line">first  second   </span><br><span class="line">bar    one     A    0.029399</span><br><span class="line">               B   -0.542108</span><br><span class="line">       two     A    0.282696</span><br><span class="line">               B   -0.087302</span><br><span class="line">baz    one     A   -1.575170</span><br><span class="line">               B    1.771208</span><br><span class="line">       two     A    0.816482</span><br><span class="line">               B    1.100230</span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure>
<p>对于“堆叠的(stacked)”DataFrame或Series（以MultiIndex为索引），<code>stack()</code>的反向操作是<code>unstack()</code>，默认情况下，它将卸载<strong>最后一层</strong>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">In [102]: stacked.unstack()</span><br><span class="line">Out[102]: </span><br><span class="line">                     A         B</span><br><span class="line">first second                    </span><br><span class="line">bar   one     0.029399 -0.542108</span><br><span class="line">      two     0.282696 -0.087302</span><br><span class="line">baz   one    -1.575170  1.771208</span><br><span class="line">      two     0.816482  1.100230</span><br><span class="line"></span><br><span class="line">In [103]: stacked.unstack(1)</span><br><span class="line">Out[103]: </span><br><span class="line">second        one       two</span><br><span class="line">first                      </span><br><span class="line">bar   A  0.029399  0.282696</span><br><span class="line">      B -0.542108 -0.087302</span><br><span class="line">baz   A -1.575170  0.816482</span><br><span class="line">      B  1.771208  1.100230</span><br><span class="line"></span><br><span class="line">In [104]: stacked.unstack(0)</span><br><span class="line">Out[104]: </span><br><span class="line">first          bar       baz</span><br><span class="line">second                      </span><br><span class="line">one    A  0.029399 -1.575170</span><br><span class="line">       B -0.542108  1.771208</span><br><span class="line">two    A  0.282696  0.816482</span><br><span class="line">       B -0.087302  1.100230</span><br></pre></td></tr></table></figure>
<h3 id="数据透视表"><a href="#数据透视表" class="headerlink" title="数据透视表"></a>数据透视表</h3><p>详情请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-pivot">Pivot Tables</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">In [105]: df &#x3D; pd.DataFrame(&#123;&#39;A&#39; : [&#39;one&#39;, &#39;one&#39;, &#39;two&#39;, &#39;three&#39;] * 3,</span><br><span class="line">   .....:                    &#39;B&#39; : [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;] * 4,</span><br><span class="line">   .....:                    &#39;C&#39; : [&#39;foo&#39;, &#39;foo&#39;, &#39;foo&#39;, &#39;bar&#39;, &#39;bar&#39;, &#39;bar&#39;] * 2,</span><br><span class="line">   .....:                    &#39;D&#39; : np.random.randn(12),</span><br><span class="line">   .....:                    &#39;E&#39; : np.random.randn(12)&#125;)</span><br><span class="line">   .....: </span><br><span class="line"></span><br><span class="line">In [106]: df</span><br><span class="line">Out[106]: </span><br><span class="line">        A  B    C         D         E</span><br><span class="line">0     one  A  foo  1.418757 -0.179666</span><br><span class="line">1     one  B  foo -1.879024  1.291836</span><br><span class="line">2     two  C  foo  0.536826 -0.009614</span><br><span class="line">3   three  A  bar  1.006160  0.392149</span><br><span class="line">4     one  B  bar -0.029716  0.264599</span><br><span class="line">5     one  C  bar -1.146178 -0.057409</span><br><span class="line">6     two  A  foo  0.100900 -1.425638</span><br><span class="line">7   three  B  foo -1.035018  1.024098</span><br><span class="line">8     one  C  foo  0.314665 -0.106062</span><br><span class="line">9     one  A  bar -0.773723  1.824375</span><br><span class="line">10    two  B  bar -1.170653  0.595974</span><br><span class="line">11  three  C  bar  0.648740  1.167115</span><br></pre></td></tr></table></figure>
<p>我们可以很容易地从这些数据生成数据透视表：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [107]: pd.pivot_table(df, values&#x3D;&#39;D&#39;, index&#x3D;[&#39;A&#39;, &#39;B&#39;], columns&#x3D;[&#39;C&#39;])</span><br><span class="line">Out[107]: </span><br><span class="line">C             bar       foo</span><br><span class="line">A     B                    </span><br><span class="line">one   A -0.773723  1.418757</span><br><span class="line">      B -0.029716 -1.879024</span><br><span class="line">      C -1.146178  0.314665</span><br><span class="line">three A  1.006160       NaN</span><br><span class="line">      B       NaN -1.035018</span><br><span class="line">      C  0.648740       NaN</span><br><span class="line">two   A       NaN  0.100900</span><br><span class="line">      B -1.170653       NaN</span><br><span class="line">      C       NaN  0.536826</span><br></pre></td></tr></table></figure>
<h2 id="时间序列"><a href="#时间序列" class="headerlink" title="时间序列"></a>时间序列</h2><p>Pandas在对频率转换进行重新采样时拥有简单、强大且高效的功能（如将按秒采样的数据转换为按5分钟为单位进行采样的数据）。这种操作在金融领域非常常见。</p>
<p>详情请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/timeseries.html#timeseries">Time Series section</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [108]: rng &#x3D; pd.date_range(&#39;1&#x2F;1&#x2F;2012&#39;, periods&#x3D;100, freq&#x3D;&#39;S&#39;)</span><br><span class="line"></span><br><span class="line">In [109]: ts &#x3D; pd.Series(np.random.randint(0, 500, len(rng)), index&#x3D;rng)</span><br><span class="line"></span><br><span class="line">In [110]: ts.resample(&#39;5Min&#39;).sum()</span><br><span class="line">Out[110]: </span><br><span class="line">2012-01-01    25083</span><br><span class="line">Freq: 5T, dtype: int64</span><br></pre></td></tr></table></figure>
<p>时区表示</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">In [111]: rng &#x3D; pd.date_range(&#39;3&#x2F;6&#x2F;2012 00:00&#39;, periods&#x3D;5, freq&#x3D;&#39;D&#39;)</span><br><span class="line"></span><br><span class="line">In [112]: ts &#x3D; pd.Series(np.random.randn(len(rng)), rng)</span><br><span class="line"></span><br><span class="line">In [113]: ts</span><br><span class="line">Out[113]: </span><br><span class="line">2012-03-06    0.464000</span><br><span class="line">2012-03-07    0.227371</span><br><span class="line">2012-03-08   -0.496922</span><br><span class="line">2012-03-09    0.306389</span><br><span class="line">2012-03-10   -2.290613</span><br><span class="line">Freq: D, dtype: float64</span><br><span class="line"></span><br><span class="line">In [114]: ts_utc &#x3D; ts.tz_localize(&#39;UTC&#39;)</span><br><span class="line"></span><br><span class="line">In [115]: ts_utc</span><br><span class="line">Out[115]: </span><br><span class="line">2012-03-06 00:00:00+00:00    0.464000</span><br><span class="line">2012-03-07 00:00:00+00:00    0.227371</span><br><span class="line">2012-03-08 00:00:00+00:00   -0.496922</span><br><span class="line">2012-03-09 00:00:00+00:00    0.306389</span><br><span class="line">2012-03-10 00:00:00+00:00   -2.290613</span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure>
<p>转换成其他时区</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [116]: ts_utc.tz_convert(&#39;US&#x2F;Eastern&#39;)</span><br><span class="line">Out[116]: </span><br><span class="line">2012-03-05 19:00:00-05:00    0.464000</span><br><span class="line">2012-03-06 19:00:00-05:00    0.227371</span><br><span class="line">2012-03-07 19:00:00-05:00   -0.496922</span><br><span class="line">2012-03-08 19:00:00-05:00    0.306389</span><br><span class="line">2012-03-09 19:00:00-05:00   -2.290613</span><br><span class="line">Freq: D, dtype: float64</span><br></pre></td></tr></table></figure>
<p>在时间跨度表示之间进行转换</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">In [117]: rng &#x3D; pd.date_range(&#39;1&#x2F;1&#x2F;2012&#39;, periods&#x3D;5, freq&#x3D;&#39;M&#39;)</span><br><span class="line"></span><br><span class="line">In [118]: ts &#x3D; pd.Series(np.random.randn(len(rng)), index&#x3D;rng)</span><br><span class="line"></span><br><span class="line">In [119]: ts</span><br><span class="line">Out[119]: </span><br><span class="line">2012-01-31   -1.134623</span><br><span class="line">2012-02-29   -1.561819</span><br><span class="line">2012-03-31   -0.260838</span><br><span class="line">2012-04-30    0.281957</span><br><span class="line">2012-05-31    1.523962</span><br><span class="line">Freq: M, dtype: float64</span><br><span class="line"></span><br><span class="line">In [120]: ps &#x3D; ts.to_period()</span><br><span class="line"></span><br><span class="line">In [121]: ps</span><br><span class="line">Out[121]: </span><br><span class="line">2012-01   -1.134623</span><br><span class="line">2012-02   -1.561819</span><br><span class="line">2012-03   -0.260838</span><br><span class="line">2012-04    0.281957</span><br><span class="line">2012-05    1.523962</span><br><span class="line">Freq: M, dtype: float64</span><br><span class="line"></span><br><span class="line">In [122]: ps.to_timestamp()</span><br><span class="line">Out[122]: </span><br><span class="line">2012-01-01   -1.134623</span><br><span class="line">2012-02-01   -1.561819</span><br><span class="line">2012-03-01   -0.260838</span><br><span class="line">2012-04-01    0.281957</span><br><span class="line">2012-05-01    1.523962</span><br><span class="line">Freq: MS, dtype: float64</span><br></pre></td></tr></table></figure>
<p>周期和时间戳之间的转换可以使用一些方便的算术功能。在下面的例子中，我们将季度结束时间从11月份转换为季末结束时的上午9点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [123]: prng &#x3D; pd.period_range(&#39;1990Q1&#39;, &#39;2000Q4&#39;, freq&#x3D;&#39;Q-NOV&#39;)</span><br><span class="line"></span><br><span class="line">In [124]: ts &#x3D; pd.Series(np.random.randn(len(prng)), prng)</span><br><span class="line"></span><br><span class="line">In [125]: ts.index &#x3D; (prng.asfreq(&#39;M&#39;, &#39;e&#39;) + 1).asfreq(&#39;H&#39;, &#39;s&#39;) + 9</span><br><span class="line"></span><br><span class="line">In [126]: ts.head()</span><br><span class="line">Out[126]: </span><br><span class="line">1990-03-01 09:00   -0.902937</span><br><span class="line">1990-06-01 09:00    0.068159</span><br><span class="line">1990-09-01 09:00   -0.057873</span><br><span class="line">1990-12-01 09:00   -0.368204</span><br><span class="line">1991-03-01 09:00   -1.144073</span><br><span class="line">Freq: H, dtype: float64</span><br></pre></td></tr></table></figure>
<h2 id="Categorical"><a href="#Categorical" class="headerlink" title="Categorical"></a>Categorical</h2><p>pandas可以在DataFrame中引入categorical数据。详情请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/categorical.html#categorical">categorical introduction</a>和<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/api.html#api-categorical">API documentation</a>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [127]: df &#x3D; pd.DataFrame(&#123;&quot;id&quot;:[1,2,3,4,5,6], &quot;raw_grade&quot;:[&#39;a&#39;, &#39;b&#39;, &#39;b&#39;, &#39;a&#39;, &#39;a&#39;, &#39;e&#39;]&#125;)</span><br></pre></td></tr></table></figure>
<p>将原始的grade转换为Categorical数据类型：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [128]: df[&quot;grade&quot;] &#x3D; df[&quot;raw_grade&quot;].astype(&quot;category&quot;)</span><br><span class="line"></span><br><span class="line">In [129]: df[&quot;grade&quot;]</span><br><span class="line">Out[129]: </span><br><span class="line">0    a</span><br><span class="line">1    b</span><br><span class="line">2    b</span><br><span class="line">3    a</span><br><span class="line">4    a</span><br><span class="line">5    e</span><br><span class="line">Name: grade, dtype: category</span><br><span class="line">Categories (3, object): [a, b, e]</span><br></pre></td></tr></table></figure>
<p>将类别重命名为更有意义的名称</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [130]: df[&quot;grade&quot;].cat.categories &#x3D; [&quot;very good&quot;, &quot;good&quot;, &quot;very bad&quot;]</span><br></pre></td></tr></table></figure>
<p>重新排列类别并同时添加缺少的类别（Series .cat下的方法默认返回一个新的系列）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">In [131]: df[&quot;grade&quot;] &#x3D; df[&quot;grade&quot;].cat.set_categories([&quot;very bad&quot;, &quot;bad&quot;, &quot;medium&quot;, &quot;good&quot;, &quot;very good&quot;])</span><br><span class="line"></span><br><span class="line">In [132]: df[&quot;grade&quot;]</span><br><span class="line">Out[132]: </span><br><span class="line">0    very good</span><br><span class="line">1         good</span><br><span class="line">2         good</span><br><span class="line">3    very good</span><br><span class="line">4    very good</span><br><span class="line">5     very bad</span><br><span class="line">Name: grade, dtype: category</span><br><span class="line">Categories (5, object): [very bad, bad, medium, good, very good]</span><br></pre></td></tr></table></figure>
<p>排序是按类别排序的，而不是词汇顺序。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [133]: df.sort_values(by&#x3D;&quot;grade&quot;)</span><br><span class="line">Out[133]: </span><br><span class="line">   id raw_grade      grade</span><br><span class="line">5   6         e   very bad</span><br><span class="line">1   2         b       good</span><br><span class="line">2   3         b       good</span><br><span class="line">0   1         a  very good</span><br><span class="line">3   4         a  very good</span><br><span class="line">4   5         a  very good</span><br></pre></td></tr></table></figure>
<h2 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h2><p><a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/visualization.html#visualization">Plotting</a>文档</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [135]: ts &#x3D; pd.Series(np.random.randn(1000), index&#x3D;pd.date_range(&#39;1&#x2F;1&#x2F;2000&#39;, periods&#x3D;1000))</span><br><span class="line"></span><br><span class="line">In [136]: ts &#x3D; ts.cumsum()</span><br><span class="line"></span><br><span class="line">In [137]: ts.plot()</span><br><span class="line">Out[137]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x1122ad630&gt;</span><br></pre></td></tr></table></figure>
<p><img src="http://pandas.pydata.org/pandas-docs/stable/_images/series_plot_basic.png" alt=""></p>
<p>在DataFrame上，<code>plot()</code>方便绘制所有带标签的列：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [138]: df &#x3D; pd.DataFrame(np.random.randn(1000, 4), index&#x3D;ts.index,</span><br><span class="line">   .....:                   columns&#x3D;[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])</span><br><span class="line">   .....: </span><br><span class="line"></span><br><span class="line">In [139]: df &#x3D; df.cumsum()</span><br><span class="line"></span><br><span class="line">In [140]: plt.figure(); df.plot(); plt.legend(loc&#x3D;&#39;best&#39;)</span><br><span class="line">Out[140]: &lt;matplotlib.legend.Legend at 0x115033cf8&gt;</span><br></pre></td></tr></table></figure>
<p><img src="http://pandas.pydata.org/pandas-docs/stable/_images/frame_plot_basic.png" alt=""></p>
<h2 id="导入和保存数据"><a href="#导入和保存数据" class="headerlink" title="导入和保存数据"></a>导入和保存数据</h2><h3 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h3><p><a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/io.html#io-store-in-csv">Writing to a csv file</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [141]: df.to_csv(&#39;foo.csv&#39;)</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/io.html#io-read-csv-table">Reading from a csv file</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">In [142]: pd.read_csv(&#39;foo.csv&#39;)</span><br><span class="line">Out[142]: </span><br><span class="line">     Unnamed: 0          A          B         C          D</span><br><span class="line">0    2000-01-01   0.266457  -0.399641 -0.219582   1.186860</span><br><span class="line">1    2000-01-02  -1.170732  -0.345873  1.653061  -0.282953</span><br><span class="line">2    2000-01-03  -1.734933   0.530468  2.060811  -0.515536</span><br><span class="line">3    2000-01-04  -1.555121   1.452620  0.239859  -1.156896</span><br><span class="line">4    2000-01-05   0.578117   0.511371  0.103552  -2.428202</span><br><span class="line">5    2000-01-06   0.478344   0.449933 -0.741620  -1.962409</span><br><span class="line">6    2000-01-07   1.235339  -0.091757 -1.543861  -1.084753</span><br><span class="line">..          ...        ...        ...       ...        ...</span><br><span class="line">993  2002-09-20 -10.628548  -9.153563 -7.883146  28.313940</span><br><span class="line">994  2002-09-21 -10.390377  -8.727491 -6.399645  30.914107</span><br><span class="line">995  2002-09-22  -8.985362  -8.485624 -4.669462  31.367740</span><br><span class="line">996  2002-09-23  -9.558560  -8.781216 -4.499815  30.518439</span><br><span class="line">997  2002-09-24  -9.902058  -9.340490 -4.386639  30.105593</span><br><span class="line">998  2002-09-25 -10.216020  -9.480682 -3.933802  29.758560</span><br><span class="line">999  2002-09-26 -11.856774 -10.671012 -3.216025  29.369368</span><br><span class="line"></span><br><span class="line">[1000 rows x 5 columns]</span><br></pre></td></tr></table></figure>
<h3 id="HDF5"><a href="#HDF5" class="headerlink" title="HDF5"></a>HDF5</h3><p>从<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/io.html#io-hdf5">HDFStores</a>读取和写入数据</p>
<p>写入HDF5存储：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [143]: df.to_hdf(&#39;foo.h5&#39;,&#39;df&#39;)</span><br></pre></td></tr></table></figure>
<p>从HDF5存储中读取：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">In [144]: pd.read_hdf(&#39;foo.h5&#39;,&#39;df&#39;)</span><br><span class="line">Out[144]: </span><br><span class="line">                    A          B         C          D</span><br><span class="line">2000-01-01   0.266457  -0.399641 -0.219582   1.186860</span><br><span class="line">2000-01-02  -1.170732  -0.345873  1.653061  -0.282953</span><br><span class="line">2000-01-03  -1.734933   0.530468  2.060811  -0.515536</span><br><span class="line">2000-01-04  -1.555121   1.452620  0.239859  -1.156896</span><br><span class="line">2000-01-05   0.578117   0.511371  0.103552  -2.428202</span><br><span class="line">2000-01-06   0.478344   0.449933 -0.741620  -1.962409</span><br><span class="line">2000-01-07   1.235339  -0.091757 -1.543861  -1.084753</span><br><span class="line">...               ...        ...       ...        ...</span><br><span class="line">2002-09-20 -10.628548  -9.153563 -7.883146  28.313940</span><br><span class="line">2002-09-21 -10.390377  -8.727491 -6.399645  30.914107</span><br><span class="line">2002-09-22  -8.985362  -8.485624 -4.669462  31.367740</span><br><span class="line">2002-09-23  -9.558560  -8.781216 -4.499815  30.518439</span><br><span class="line">2002-09-24  -9.902058  -9.340490 -4.386639  30.105593</span><br><span class="line">2002-09-25 -10.216020  -9.480682 -3.933802  29.758560</span><br><span class="line">2002-09-26 -11.856774 -10.671012 -3.216025  29.369368</span><br><span class="line"></span><br><span class="line">[1000 rows x 4 columns]</span><br></pre></td></tr></table></figure>
<h3 id="Excel"><a href="#Excel" class="headerlink" title="Excel"></a>Excel</h3><p>从<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/io.html#io-excel">MS Excel</a>中读取和写入数据</p>
<p>写入一个excel文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [145]: df.to_excel(&#39;foo.xlsx&#39;, sheet_name&#x3D;&#39;Sheet1&#39;)</span><br></pre></td></tr></table></figure>
<p>读取一个excel文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">In [146]: pd.read_excel(&#39;foo.xlsx&#39;, &#39;Sheet1&#39;, index_col&#x3D;None, na_values&#x3D;[&#39;NA&#39;])</span><br><span class="line">Out[146]: </span><br><span class="line">                    A          B         C          D</span><br><span class="line">2000-01-01   0.266457  -0.399641 -0.219582   1.186860</span><br><span class="line">2000-01-02  -1.170732  -0.345873  1.653061  -0.282953</span><br><span class="line">2000-01-03  -1.734933   0.530468  2.060811  -0.515536</span><br><span class="line">2000-01-04  -1.555121   1.452620  0.239859  -1.156896</span><br><span class="line">2000-01-05   0.578117   0.511371  0.103552  -2.428202</span><br><span class="line">2000-01-06   0.478344   0.449933 -0.741620  -1.962409</span><br><span class="line">2000-01-07   1.235339  -0.091757 -1.543861  -1.084753</span><br><span class="line">...               ...        ...       ...        ...</span><br><span class="line">2002-09-20 -10.628548  -9.153563 -7.883146  28.313940</span><br><span class="line">2002-09-21 -10.390377  -8.727491 -6.399645  30.914107</span><br><span class="line">2002-09-22  -8.985362  -8.485624 -4.669462  31.367740</span><br><span class="line">2002-09-23  -9.558560  -8.781216 -4.499815  30.518439</span><br><span class="line">2002-09-24  -9.902058  -9.340490 -4.386639  30.105593</span><br><span class="line">2002-09-25 -10.216020  -9.480682 -3.933802  29.758560</span><br><span class="line">2002-09-26 -11.856774 -10.671012 -3.216025  29.369368</span><br><span class="line"></span><br><span class="line">[1000 rows x 4 columns]</span><br></pre></td></tr></table></figure>
<h2 id="陷阱"><a href="#陷阱" class="headerlink" title="陷阱"></a>陷阱</h2><p>如果你正在尝试一个操作，你会看到一个异常：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; if pd.Series([False, True, False]):</span><br><span class="line">    print(&quot;I was true&quot;)</span><br><span class="line">Traceback</span><br><span class="line">    ...</span><br><span class="line">ValueError: The truth value of an array is ambiguous. Use a.empty, a.any() or a.all().</span><br></pre></td></tr></table></figure>
<p>请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/basics.html#basics-compare">Comparisons</a>以获取解释以及如何处理。</p>
<p>同时请参阅<a target="_blank" rel="noopener" href="http://pandas.pydata.org/pandas-docs/stable/gotchas.html#gotchas">Gotchas</a>。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/09/24/%E4%B8%8D%E7%94%A8%E4%B8%80%E5%8F%A5%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%AF%E8%AF%AD%E6%9D%A5%E8%AE%B2%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%90%E4%BD%9C%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="DannyLee">
      <meta itemprop="description" content="愿你的努力终取得成果">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="圣巢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/09/24/%E4%B8%8D%E7%94%A8%E4%B8%80%E5%8F%A5%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9C%AF%E8%AF%AD%E6%9D%A5%E8%AE%B2%E8%A7%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%90%E4%BD%9C%E5%8E%9F%E7%90%86/" class="post-title-link" itemprop="url">【原创】不用一句深度学习术语来讲解神经网络运作原理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-09-24 01:11:00" itemprop="dateCreated datePublished" datetime="2017-09-24T01:11:00+00:00">2017-09-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-10 17:00:48" itemprop="dateModified" datetime="2021-02-10T17:00:48+00:00">2021-02-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <blockquote>
<p>原创文章，转载请注明出处</p>
</blockquote>
<h2 id="神经网络-多层级组织架构的公司"><a href="#神经网络-多层级组织架构的公司" class="headerlink" title="神经网络==多层级组织架构的公司"></a>神经网络==多层级组织架构的公司</h2><p>假设有一家公司，这家公司的组织架构是下面这种多层级的结构：</p>
<p><img src="/img/17_09_24/001.png" alt=""></p>
<p>公司每天接待一批固定数量的用户，这些用户会将自己的数据告诉给公司，公司做的事情就是通过每个用户上报的数据来推测当前用户群体整体所表现出来的状态。</p>
<p><img src="/img/17_09_24/002.png" alt=""></p>
<p>公司中直接与用户打交道的只有基层业务员，小部门经理只与基层业务员打交道，大部门经理只与小部门经理打交道…依此类推，层层递进，直到CEO这一层。</p>
<p>并且其中每一个基层业务员会了解每个用户的数据，每个小部门经理也会了解每个基层业务员输出的情况，…，依次类推，直到CEO。而CEO需要了解的是每个副总经理输出的情况。</p>
<p>公司拿到一批用户的数据之后，首先交给基层业务员。每个基层业务员看到了每个用户的数据之后，都会针对每一个用户出一份数据分析报表（由于每个人的观点不同，所以每个人得出的报表都不一样）；然后每个小部门经理也会分别去看每个业务员输出的报表，然后自己再输出一个针对每一个基层业务员输出的数据的分析报表；同样，每个大部门经理也会去这样看每个小部门经理输出的报表，然后出一份针对每一个小部门经理输出的数据的分析报表；…；以此类推，最终CEO会输出一个针对每一个副总经理输出的数据的分析报表，这份报表里就是公司当前对用户状态的理解。</p>
<p><img src="/img/17_09_24/003.png" alt=""></p>
<p>那么公司对用户状态把握到底准确不准确呢？这需要一个衡量标准。</p>
<p>所以我们需要对公司进行考核，将一部分已知状态的用户数据给到公司，看公司是否能足够准确的预测出这个状态。换句话说，就是CEO最后输出的这份报表，与用户的真实状态之间相差有多大。</p>
<p><img src="/img/17_09_24/004.png" alt=""></p>
<p>如果CEO发现自己的预测和真实情况偏差很大，它会带头思考自己工作上到底哪里做的不够好导致最终的判断失误，以及自己需要如何调整状态才能使公司表现更好，然后号召副总经理反思并调整状态。副总经理反思调整之后，会号召他的直属下级部门反思并调整状态。以此类推，直到基层业务员。但其实每个人都不能完全保证调整的状态是否可靠，所以大家就比较保守的<strong>稍微调整一下</strong>自己的工作状态。</p>
<p>当全公司员工调整状态完成之后，在面对新的用户数据，看是否能更加准确的预测用户群体的状态。如果发现上面的调整确实有效，那么继续按照上面的方式调整：由CEO再次依次号召下面的员工来调整工作状态，调整之后继续面对新的用户。重复执行上面的操作若干次之后，直到公司的预测效果趋于稳定为止（和真实状态对比之后，差值基本不再变化了）。</p>
<p><img src="/img/17_09_24/005.png" alt=""></p>
<p>此时的公司就相当于经历了若干次碰壁，并且若干次全员反思、调整状态之后，各个员工都成为了精兵强将了，对于用户数据的把握也更加准确了。</p>
<p>现在，我们回头看看公司接待的客户。假设公司每天共接待1024位用户，每个用户都举着一个纯色的卡片，卡片颜色是灰度值介于0到255之间的某个颜色。</p>
<p><img src="/img/17_09_24/006.png" alt=""></p>
<p>将这些用户按顺序排在32×32的平面上，每个用户占一格。当他们将手里的纯色卡片高举并拼凑起来之后，我们会看到一个写有数字的图片。</p>
<p><img src="/img/17_09_24/007.png" alt=""></p>
<p>公司做的事情就是每天接待这1024个用户，他们会告诉公司自己手里卡片的灰度值，但不会告诉公司卡片拼起来的图片是什么，然后公司经过层层分析来得出当前所有用户卡片拼起来的图像是什么。</p>
<p>这就是一个用户识别手写数字的DNN模型的形象比喻。</p>
<hr>
<h3 id="几个问题的思考"><a href="#几个问题的思考" class="headerlink" title="几个问题的思考"></a>几个问题的思考</h3><h4 id="公司员工数量一定的情况下，组织架构是越扁平越好，还是层级越多越好？"><a href="#公司员工数量一定的情况下，组织架构是越扁平越好，还是层级越多越好？" class="headerlink" title="公司员工数量一定的情况下，组织架构是越扁平越好，还是层级越多越好？"></a>公司员工数量一定的情况下，组织架构是越扁平越好，还是层级越多越好？</h4><p>扁平化的架构带来的好处是快速直接触达用户，但最终的准确率会比较低；多层级的架构带来的好处是更合理的分工，但会带来沟通和管理上的开销和数据损失。</p>
<p>所以如何设置公司层级是一门学问。</p>
<h4 id="每个员工是如何生成报表的？"><a href="#每个员工是如何生成报表的？" class="headerlink" title="每个员工是如何生成报表的？"></a>每个员工是如何生成报表的？</h4><p>每个员工根据自己对每个数据的重要程度的看法，计算出自己对每个数据的看法。然后在经过一层加工处理之后输出报表。</p>
<h4 id="公司招聘员工的时候，应该招聘类似的人群，还是招聘差异化的人群？"><a href="#公司招聘员工的时候，应该招聘类似的人群，还是招聘差异化的人群？" class="headerlink" title="公司招聘员工的时候，应该招聘类似的人群，还是招聘差异化的人群？"></a>公司招聘员工的时候，应该招聘类似的人群，还是招聘差异化的人群？</h4><p>应该招聘差异化大的人群，这样每个人能够产生对数据的不同看法。如果公司大部分人背景相似，那么他们对待同一类问题，产生的看法也都相似，没有多样化的观点，也容易导致公司做出错误判断。</p>
<hr>
<h3 id="带入术语"><a href="#带入术语" class="headerlink" title="带入术语"></a>带入术语</h3><ul>
<li>神经网络 -&gt; 多层级结构的公司</li>
<li>神经网络架构 -&gt; 公司组织架构</li>
<li>神经元 -&gt; 每一位员工</li>
<li>损失函数/代价函数 -&gt; 公司最终预测结果 - 真实结果</li>
<li>输入数据源 -&gt; 每天所有用户的卡片灰度值向量</li>
<li>输入数据标签值 -&gt; 所有用户卡片拼凑起来的数字图像的真实数值</li>
<li>反向传播 -&gt; 由CEO牵头，依次带领全公司员工反思</li>
<li>正向传递 -&gt; 带入每天的用户数据，层层递进，输出最终预测结果</li>
<li>激活函数 -&gt; 每个员工对数据的加工</li>
<li>参数 -&gt; 每个员工对数据的主观看法</li>
<li>随机初始化参数 -&gt; 招聘差异化人群</li>
<li>输入层 -&gt; 用户层</li>
<li>隐藏层 -&gt; 除了CEO之外的所有员工层级</li>
<li>输出层 -&gt; CEO层</li>
<li>梯度下降 -&gt; 公司朝着缩小预测错误程度的方向全员反思调整状态的过程</li>
<li>学习率 -&gt; 每次调整状态的程度α</li>
<li>训练/学习 -&gt; 带入大量已知状态的用户数据来根据公司的预测结果调整全员状态的过程</li>
</ul>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>神经网络是一个灵活的结构，当带入图片像素值以及图片标签数据时，它训练的就是一个图片识别模型；当带入的数据是邮件特征数据，以及邮件是否为垃圾邮件的类别数据时，它可能就是一个垃圾邮件识别模型。</p>
<p>这里的类比并不严谨，准确的定义还需要参考标准定义。不过通过形象化的类比，可以使我们对神经网络建立起系统化的认知。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/08/08/%E3%80%90Tensorflow%20r1.0%20%E7%A8%8B%E5%BA%8F%E5%91%98%E6%8C%87%E5%8D%97%E3%80%91-%E5%8F%98%E9%87%8F%EF%BC%9A%E5%88%9B%E5%BB%BA%EF%BC%8C%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%8C%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="DannyLee">
      <meta itemprop="description" content="愿你的努力终取得成果">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="圣巢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/08/%E3%80%90Tensorflow%20r1.0%20%E7%A8%8B%E5%BA%8F%E5%91%98%E6%8C%87%E5%8D%97%E3%80%91-%E5%8F%98%E9%87%8F%EF%BC%9A%E5%88%9B%E5%BB%BA%EF%BC%8C%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%8C%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD/" class="post-title-link" itemprop="url">【Tensorflow r1.0 程序员指南】-变量：创建，初始化，保存和加载</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-08 22:08:58" itemprop="dateCreated datePublished" datetime="2017-08-08T22:08:58+00:00">2017-08-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-10 17:00:48" itemprop="dateModified" datetime="2021-02-10T17:00:48+00:00">2021-02-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Tensorflow/" itemprop="url" rel="index"><span itemprop="name">Tensorflow</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>当你训练一个模型时，您可以使用<a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_guides/python/state_ops">variables</a>来保存和更新参数。variables是包含张量的内存缓冲区。variables必须明确地被初始化，并在训练期间和之后将其保存到磁盘。在之后您可以恢复保存的值，以运行或分析模型。</p>
<p>本文档引用了以下TensorFlow类。请参阅其参考手册的链接，了解其API的完整说明：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/Variable">tf.Variable</a></li>
<li><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/train/Saver">tf.train.Saver</a></li>
</ul>
<h2 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h2><p>当您创建一个<a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_guides/python/state_ops">Variable</a>时，您将<code>Tensor</code>作为其初始值传递给<code>Variable()</code>构造函数。TensorFlow提供了一个操作的集合，它们产生经常用于从<a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_guides/python/constant_op">常量或随机初始化的</a>张量。</p>
<p>请注意，所有这些操作都需要您指定张量的形状。该形状自动变为变量的形状。变量通常具有固定的形状，但是TensorFlow提供了重新变换变量的高级机制。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/08/08/%E3%80%90Tensorflow%20r1.0%20%E7%A8%8B%E5%BA%8F%E5%91%98%E6%8C%87%E5%8D%97%E3%80%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="DannyLee">
      <meta itemprop="description" content="愿你的努力终取得成果">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="圣巢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/08/%E3%80%90Tensorflow%20r1.0%20%E7%A8%8B%E5%BA%8F%E5%91%98%E6%8C%87%E5%8D%97%E3%80%91/" class="post-title-link" itemprop="url">【Tensorflow r1.0 程序员指南】</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-08 21:12:58" itemprop="dateCreated datePublished" datetime="2017-08-08T21:12:58+00:00">2017-08-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-10 17:00:48" itemprop="dateModified" datetime="2021-02-10T17:00:48+00:00">2021-02-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Tensorflow/" itemprop="url" rel="index"><span itemprop="name">Tensorflow</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="程序员指南"><a href="#程序员指南" class="headerlink" title="程序员指南"></a>程序员指南</h2><p>这一部分文档将深入到TensorFlow的代码细节。这一节由以下几个指南开始，每一个指南都介绍了TensorFlow的一个特定的方面：</p>
<ul>
<li><a href="">变量：创建，初始化，保存和加载</a>，详细介绍了TensorFlow变量的机制。</li>
<li><a href="">张量等级，形状和类型</a>，这部分说明了Tensor等级（维数），形状（每个维的大小）和数据类型。</li>
<li><a href="">共享变量</a>，这部分解释了在构建复杂模型时如何共享和管理大量变量。</li>
<li><a href="">线程和队列</a>，这部分说明了TensorFlow的富队列系统。</li>
<li><a href="">读取数据</a>，其中记录了将数据导入TensorFlow程序的三种不同机制。</li>
</ul>
<p>以下指南适用于对复杂模型的多天训练：</p>
<ul>
<li><a href="">监督：多天训练的训练助手</a>，介绍如何在长时间的训练过程中妥善处理系统崩溃。</li>
</ul>
<p>TensorFlow提供了一个名叫<code>tfdbg</code>的调试器，它的文档见下面两个指南：</p>
<ul>
<li><p><a href="">TensorFlow Debugger（tfdbg）命令行界面教程：MNIST</a>，它将引导您使用<code>tfdbg</code>在低级TensorFlow API中编写的应用程序。</p>
</li>
<li><p><a href="">如何在tf.contrib.learn中使用TensorFlow Debugger（tfdbg）</a>，它演示了如何在Estimators API中使用<code>tfdbg</code>。</p>
</li>
</ul>
<p><code>MetaGraph</code>由计算图及其相关元数据组成。<code>MetaGraph</code>包含持续训练，执行评估或在先前训练过的图表上运行推断所需的信息。以下指南是<code>MetaGraph</code>对象的详细说明：</p>
<ul>
<li><a href="">MetaGraph的导入和导出</a></li>
</ul>
<p><code>SavedModel</code>是Tensorflow模型的通用序列化格式。TensorFlow提供SavedModel CLI（命令行界面）作为在<code>SavedModel</code>中检查和执行<code>MetaGraph</code>的工具。以下指南中记录了详细的用法和示例：</p>
<ul>
<li><a href="">SavedModel CLI（命令行界面）</a></li>
</ul>
<p>要了解TensorFlow版本控制方案，请参阅以下两个指南：</p>
<ul>
<li><a href="">TensorFlow版本语义</a>，这说明了TensorFlow的版本控制术语和兼容性规则。</li>
<li><a href="">TensorFlow数据版本控制：GraphDefs和检查点</a>，这解释了TensorFlow如何将版本信息添加到计算图形和检查点，以便支持跨版本的兼容性。</li>
</ul>
<p>结束本部分有关TensorFlow编程的常见问题：</p>
<ul>
<li><a href="">常见问题</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/08/03/%E3%80%90%E6%96%AF%E5%9D%A6%E7%A6%8Fcs231n%E3%80%912-2%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="DannyLee">
      <meta itemprop="description" content="愿你的努力终取得成果">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="圣巢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/08/03/%E3%80%90%E6%96%AF%E5%9D%A6%E7%A6%8Fcs231n%E3%80%912-2%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB/" class="post-title-link" itemprop="url">【斯坦福cs231n】2-2线性分类</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-08-03 23:39:00" itemprop="dateCreated datePublished" datetime="2017-08-03T23:39:00+00:00">2017-08-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-10 17:00:48" itemprop="dateModified" datetime="2021-02-10T17:00:48+00:00">2021-02-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cs231n/" itemprop="url" rel="index"><span itemprop="name">cs231n</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="线性分类"><a href="#线性分类" class="headerlink" title="线性分类"></a>线性分类</h2><p>在最后一节中，我们介绍了图像分类的问题，这是从一组固定的类别向一个图像分配单个标签的任务。更多的，我们描述了通过将图像与来自训练集的（注释）图像进行比较来标记图像的k-最近邻（kNN）分类器。我们看到，kNN有一些缺点：</p>
<ul>
<li>分类器必须记住所有的训练数据并将其存储，以便将来与测试数据进行比较。这在空间上是低效的，因为数据集的大小可能很容易达到千兆字节。</li>
<li>分类器执行对单个测试样本进行预测的操作是昂贵的，因为它需要与所有训练图像进行比较。</li>
</ul>
<p><strong>概述.</strong>我们现在要开发更强大的图像分类方法，我们最终将自然地扩展到整个神经网络和卷积神经网络。该方法将有两个主要部分：一个<strong>得分函数</strong>，这个函数是原始数据到预测分类的得分的映射；以及<strong>损失函数</strong>，这个函数衡量了预测得分与真实结果之间的差值。然后，我们将图像分类问题作为一个最小化相对于得分函数的损失函数的优化问题。</p>
<h2 id="从图像到标签分数的参数化映射"><a href="#从图像到标签分数的参数化映射" class="headerlink" title="从图像到标签分数的参数化映射"></a>从图像到标签分数的参数化映射</h2><p>该方法的第一个组成部分是定义将图像的像素值映射到每个类的置信度得分的分数函数。我们将以具体的例子来介绍这种方法。像以前一样，我们假设一个图像训练数据集$x_i \in R^D$，每个图像都有一个相关的标签$y_i$。在这里，我们定义$i = 1 \dots N$，并且$y_i \in { 1 \dots K }$。也就是说我们拥有$N$个样本（每个样本的维数都是$D$）和$K$个不同的类别。例如，在CIFAR-10中，我们有一个训练集，它有$N=50,000$张图片，其中每张图片都是$D=32 x 32 x 3 = 3072$像素，并且由于一共有10个不同的类别（狗，猫，车等等），所以$K=10$。我们现在将定义将原始图像像素映射到类分数的分数函数：$f: R^D \mapsto R^K$。</p>
<p><strong>线性分类器.</strong>在这个模块中，我们可以从最简单的一个线性映射函数开始：</p>
<script type="math/tex; mode=display">
f(x_i, W, b) =  W x_i + b</script><p>在上述等式中，我们假设图像$x_i$将其所有像素平坦化形状为[D x 1]的列向量。矩阵$W$(大小是[K x D])，向量$b$（大小是[K x 1]）是函数的<strong>参数</strong>。在CIFAR-10中，$x_i$包含第i张图中的所有像素，并且展开成为单列的尺寸为[3072 x 1]的向量，$W$尺寸是[10 x 3072]，$b$的尺寸是[10 x 1]，所以这个函数每次有3072个参数输入（原始像素值），并且有10个参数输出（10个类别的得分）。参数$W$通常被称为<strong>权重(weights)</strong>，$b$被称为<strong>偏差向量(bias vector)</strong>，因为它会在不与实际输入数据$x_i$发生交互的情况下，影响输出分数值。但是，您经常会听到人们用<em>权重</em>或者<em>参数</em>这样的术语来描述这一概念。</p>
<p>有一些注意事项：</p>
<ul>
<li>首先，注意$Wx_i$的矩阵乘法部分，正在对10个独立的分类器进行并行的评估，其中$W$的每一行分别是一个类别的分类器。</li>
<li>同时也要注意，给定的输入数据$(x_i, y_i)$是不可变的，但是我们可以控制调节参数$W,b$。我们的目标是通过设置这些参数，使得最终分类器计算出来的得分与整个训练集中的真实标签数据相匹配。我们将详细介绍如何做到这一点，但从直觉上来说，我们希望被正确分类的分数是高于错误分类的分数的。</li>
<li>这种方法的一个优点是训练数据被用于学习参数$W,b$，但一旦学习完成，我们就可以忽略训练数据集，并且只保留学习得到的参数值即可。这是因为一个新的测试图像可以通过调用这个方法来基于已经算出的分数进行分类。</li>
<li>最后，注意测试图像分类涉及到一个单个的矩阵乘法和加法操作，这明显比将测试图像与所有训练图像进行比较更快。</li>
</ul>
<blockquote>
<p>卷积：卷积神经访问将图像像素映射到如上所示的分数，但映射(f)更复杂，并且包含更多的参数。</p>
</blockquote>
<h2 id="解释线性分类器"><a href="#解释线性分类器" class="headerlink" title="解释线性分类器"></a>解释线性分类器</h2><p>请注意，线性分类器将其分类计算为其所有3个颜色通道中的所有像素值的加权和。分类结果取决于我们为这些权重设置什么具体值，该函数具有在图像中某些位置的某些颜色的喜欢或者不喜欢的能力（取决于每个权重的符号）。例如，你可以想象，如果图像的边缘部分有很多的蓝色（这部分可能是水），那么这张图片是“船”的类别的可能性更大。你可能希望“船”分类器在其蓝色通道有着正权重（蓝色增加“船”类别的分值），而在红色/绿色通道中有着负权重（红色/绿色的存在降低“船”类别的分值）。</p>
<hr>
<p><img src="/img/17_08_03/001.jpg" alt=""></p>
<blockquote>
<p>一个将图像到分类得分的映射例子。为了方便可视化，我们假设图像只有4个像素（4个单色像素，这里我们不考虑彩色通道），我们有三个类别（红色（猫），绿色（狗），蓝色（船））。（说明：这里的颜色简单的表示了3个类别，但与RGB通道无关。）我们将图像像素拉伸成一列，并执行矩阵乘法以得到每个类的分数。请注意，这里给定的权重W不是很好：我们传入一张猫的图片，通过这个权重计算得到的对应的猫的得分很低。实际上，这套权重对应得到的得分似乎在说明它看到的是一条狗。</p>
</blockquote>
<hr>
<p><strong>将图像比作高维点.</strong>由于图像被拉伸成高维列向量，我们可以将每个图像解释为该空间中的单个点（例如，CIFAR-10中的每个图像是32×32×3像素的3072维空间中的点）。类似地，整个数据集是一个（被标记的）的点集合。</p>
<p>由于我们将每一个类的分数定义为所有图像像素的加权和，所以每个类对应的分数在这个空间上是一个线性函数。我们无法想象3072维空间的样子，但如果我们想象将所有的维度都挤压到两个维度时，那么我们就可以试着去可视化分类器正在做的事情：</p>
<p><img src="/img/17_08_03/002.jpeg" alt=""></p>
<blockquote>
<p>图像空间中，每个图像都是单个点，并且有三个分类器被可视化。使用汽车分类器（红色）的示例，红色线显示空间中为汽车分类得分为0的所有点。红色箭头表示的是分数增加方向，所以红线右侧的所有点都是正（线性增加）得分，并且左边的所有点都是负（线性递减）得分。</p>
</blockquote>
<hr>
<p>正如我们上面所见到的，权重矩阵$W$的每一行都对应一个类别的分类器。这些数字的几何解释是：当我们更改$W$的其中一行时，像素控件中的相应行将沿不同方向旋转。另一方面，偏置量$b$允许我们的分类器转换行。特别要注意的是，没有偏置量时，插入$x_i=0$时，不管权值为何值，最终得到的分数总是0，所以所有分类器的线条都被迫穿过原点。</p>
<p><strong>将线性分类器解释为模板匹配.</strong>对于权重$W$的另外一种解释是每一行都对应一个类的模板（有时也称为原型）。然后，通过使用<em>内积</em>（或<em>点积</em>）逐个比较每个模板与图像，以获得最适合的图像，从而获得每个类的分数。当我们执行内积操作的时候，线性分类器正在进行模板匹配，其中模板是通过学习得到的。另一种看待这个问题的方法是我们依然在执行最邻近操作，但是，相比与成千上万的训练图像进行比较，我们这里只是使用单个图像进行比较（尽管我们会学习这张图，但它不一定是训练集中的图像），并且我们使用（负）内积作为距离而不是L1或L2距离。</p>
<p><img src="/img/17_08_03/003.jpg" alt=""></p>
<blockquote>
<p>CIFAR-10学习结束时得到的权重示例。注意，例如，船模板包含大量蓝色像素。因此，一旦与其内部在海洋上的船舶图像相匹配，该模板就会得到高分。</p>
</blockquote>
<hr>
<p>此外，请注意，马模板似乎包含一个双头马，这是由于数据集中有左右两匹马造成的。线性分类器将这两种模式的马在数据中合并成一个模板。类似地，汽车分类器似乎已经将多种模式合并成了单个模板，其必须从各方面以及所有颜色识别汽车。特别地，这个模板最终表现是红色的，这暗示着CIFAR-10数据集中红色的车占汽车类别的大部分。线性分类器太弱，无法正确识别不同颜色的汽车，但正如我们将看到的，神经网络将允许我们执行此任务。神经网络能够通过其隐藏层来开发出可以检测特定汽车类型的中间神经元（例如面向左方的绿色汽车，面向前方的蓝色汽车等），并且下一层的神经元可以通过各个车辆检测器的加权和来将它们组合成更准确的车辆分数。</p>
<p><strong>偏置技巧.</strong>在继续下面的内容之前，我们将介绍一个通用的简化技巧，将两个参数$W,b$表示为一个参数。回想一下，我们将得分函数定义为：</p>
<script type="math/tex; mode=display">
f(x_i, W, b) =  W x_i + b</script><p>对两个参数分别跟踪考虑（偏置$b$和重量$W$）是有点麻烦的。一个常用的技巧是将两组参数组合成一个单一的矩阵，我们通过将向量$x_i$扩展一个额外的维度，其值为常数1—一个默认的偏置维度。使用额外的维度，新的分数函数将简化为单个矩阵乘法：</p>
<script type="math/tex; mode=display">
f(x_i, W) =  W x_i</script><p>在我们的CIFAR-10例子中，$x_i$现在的维度由[3072 x 1]变为了[3073 x 1]-（额外的维度的值为常数1），$W$现在由[10 x 3072]变为了[10 x 3073]。现在$W$矩阵额外增加的那一列对应了偏置量$b$。下面是一个帮助我们理解的例子：</p>
<p><img src="/img/17_08_03/004.jpeg" alt=""></p>
<blockquote>
<p>上图介绍了调整偏置量的小技巧。执行一次矩阵乘法，然后将结果与偏置量（左侧）相加，等效于对所有输入向量添加常数为1的偏置维度，并将权重矩阵向右扩展一列偏置列（右侧）。因此，如果我们通过将其附加到所有向量来预处理我们的数据，我们只需要学习一个权重矩阵，而不是保存权重和偏差两个矩阵。</p>
</blockquote>
<hr>
<p><strong>图像数据预处理.</strong>请注意，在上面的例子中，我们使用了原始像素值（范围从[0 … 255]）。在机器学习中，对输入数据进行归一化操作是非常常见的做法（在图像识别的例子中，每一个像素被认为是一个特征）。特别地，通过减去每个特征的平均值来<strong>确定数据的中心值</strong>是很重要的。在图像识别的例子中，这对应于计算训练图像上的平均图像，并从每个图像中减去它，以获得像素范围大约在[-127 … 127]的图像。进一步的常用预处理是缩放每个输入特征，使其值范围落在[-1,1]的区间内。其中，均值为0是更为重要的步骤，但我们理解动态梯度下降之后我们才可以解释这一原因。</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>在上一节中，我们定义了由一组权重$W$参数化的像素到得分的映射函数。此外，我们并没有控制数据$(x_i,y_i)$(这些数据是外部给到并不可改变的)，但我们控制了权重，并且我们希望通过设置这些权值来预测分类得分，从而达到与真实标签相符合的效果。</p>
<p>例如，回到我们前面的那个将猫的图片分类到“猫”，“狗”和“船”的例子中，我们可以看到那个例子中的特定定权值并不是非常好：我们传入了一张画有猫的图片，但对于猫的分类得分，相比对于其他类别（狗的得分是437.9，船的得分是61.95）却非常低(-96.8)。我们可以通过<strong>损失函数</strong>（有时也被称为<strong>代价函数</strong>或<strong>目标</strong>）来衡量我们的分类器有多差。直观的说，如果我们在训练集上分类的效果不好，那么损失值将会很高，反之，则会很低。</p>
<h3 id="多类SVM损失函数"><a href="#多类SVM损失函数" class="headerlink" title="多类SVM损失函数"></a>多类SVM损失函数</h3><p>有几种方法来定义损失函数的细节。作为第一个例子，我们将首先开发一种称为<strong>多类别支持向量机（SVM）</strong>损失函数的常用损失函数。SVM损失函数被设置为使得SVM“想要”每个图像的正确类别具有比不正确类别高得多的固定的余量$\Delta$。请注意，如上所述，有时有助于拟合损失函数：SVM“想要”某种结果，意味着结果将产生较低的损失（这是好的）。</p>
<p>我们来看一下更准确的描述。回想一下我们给出的第i个样本的图像$x_i$以及其标识对应类别的标签$y_i$。得分函数$f(x_i, W)$接受像素值并且计算出得分向量，我们简称为$s$(分数的简写)。例如，第j个类别的得分是函数结果的第j个元素：$s_j = f(x_i, W)_j$。然后将第i个例子的多类SVM损失函数表示如下形式：</p>
<script type="math/tex; mode=display">
L\_i = \sum\_{j\neq y_i} \max(0, s\_j - s\_{y_i} + \Delta)</script><p><strong>例如.</strong>让我们通过一个例子来了解他是如何工作的。假设我们有三个类，可以得到$s = [13, -7, 11]$，第一个类别对应的是true（即$y_i = 0$）。并且假设$\Delta$（一个我们稍后会介绍到的超参数）的值是10。根据上面的针对错误分类得分的求和表达式（$j \neq y_i$），我们可以得到下面的结果：</p>
<script type="math/tex; mode=display">
L_i = \max(0, -7 - 13 + 10) + \max(0, 11 - 13 + 10)</script><p>你可以看到第一部分的结果是0，因为[-7 - 13 + 10]得出的是一个负数，然后通过函数$max(0,-)$将其阈值化为0。我们得到的损失值为0，因为正确分类的得分（13）比不正确分类的得分（-7）相距大于10。事实上，他们的距离是20，这个值是远大于10的，但SVM只关心差值最多在10以内；任何高于此间距的额外差值被取最大值操作控制在了0的位置上。第二部分关于[11 - 13 + 10]的计算结果是8。也就是说，即使正确的分类比不正确的分类（13&gt;11）有更高的分数，但并没有超过10的间隔值。其差值仅仅为2，所以其损失值为8（即，差额要高出多少才能超过间隔值）。总而言之，SVM损失函数希望被正确分类的到$y_i$的得分要比不正确分类的得分至少要大$\Delta$。如果不是这样，我们就会累计损失值。</p>
<p>请注意，在这个特定的模块中我们正在使用线性评分函数($f(x_i; W) =  W x_i$)，所以我们也可以以等效的方式重写损失函数：</p>
<script type="math/tex; mode=display">
L\_i = \sum\_{j\neq y_i} \max(0, w\_j^T x\_i - w\_{y_i}^T x\_i + \Delta)</script><p>这里的$w_j$是权重矩阵$W$的第j行转化为列的形式。然而，在更复杂的评分函数$f$的形式中，不一定是这样的。</p>
<p>在我们完成本节之前，我们将提到的最后一个术语是值域为0的$max(0,-)$函数，我们通常称为<strong>转折点损失(hinge loss)</strong>。有时候您会听到有关人们使用形式为$max(0,-)^2$的对违规惩罚更强烈（二次而不是线性）的平方转折点损失SVM（或L2-SVM）。无平方计算的是更为标准的版本，但在某些数据集中，平方转折点损失可以工作的更好。这一点可以在交叉验证期间确定。</p>
<blockquote>
<p>损失函数量化了我们对训练集的预测结果的不满意程度。</p>
</blockquote>
<hr>
<p><img src="/img/17_08_03/005.jpg" alt=""></p>
<blockquote>
<p>多类别支持向量机“想要”正确分类的分数比其他分数至少多出delta的大小。如果任何类别在红色区域内（或者更高）都有分数，那么就会有累计的损失。否则损失值为0。</p>
</blockquote>
<hr>
<p><strong>正则化.</strong>上面提到的损失函数有一个bug。假设我们有一个数据集，并且有一组用于正确分类每个样本的参数$W$（例如，所有的分数都是满足所有的边距值，并且对于所有的i都有$L_i = 0$）。问题是这套$W$不一定是唯一的：可能有许多与$W$类似的参数可以正确分类示例。一种看待这个问题的简单的方式是如果$W$的一些参数正确分类了所有样本（对于每个样本来说损失值为0），那么任意倍数的这些参数$\lambda W$（其中$\lambda &gt; 1$）也可以得出损失值为0的结果，因为这种变换均匀地拉伸了所有的得分幅度，以及它们的绝对差异。但是，如果正确分类的和最近的不正确分类的分数差异为15，然后将$W$的所有元素乘以2会使得新的差异值为30。</p>
<p>换句话说，我们希望对某些权重$W$进行一些偏好编码，以消除这种歧义。我们可以通过用<strong>正则化乘法$R(W)$</strong>来扩展损失函数，做到这一点。最常见的正则化惩罚是<strong>L2</strong>范数，通过对所有参数进行二次方的惩罚来阻止大权重出现：</p>
<script type="math/tex; mode=display">
R(W) = \sum\_k\sum\_l W\_{k,l}^2</script><p>在上面的表达式中，我们将$W$中所有元素的平方求和。请注意，正则化函数不是基于数据的函数，它只是基于权重。包括了正则化惩罚在内的完整的多类支持向量机的损失函数由两部分组成：<strong>数据损失</strong>(这是全部样本中平均损失值$L_i$)和<strong>正则化损失</strong>。也就是说，完整的多类SVM损失函数变为以下形式：</p>
<p><img src="/img/17_08_03/006.png" alt=""></p>
<p>或者将其扩展为完整形式：</p>
<script type="math/tex; mode=display">
L = \frac{1}{N} \sum\_i \sum\_{j\neq y\_i} 
\left[ \max(0, f(x\_i; W)\_j - f(x\_i; W)\_{y\_i} + \Delta) \right] + \lambda \sum\_k\sum\_l W\_{k,l}^2</script><p>其中$N$是训练样本的数量。正如你所见的，我们将正则化惩罚附加到损失目标上，由超参数$\lambda$加权。这个超参数通常是由交叉验证来设置，除此之外没有别的简单的方法。</p>
<p>事实上关于引入正则化惩罚除了上述的动机之外，正则化惩罚还给我们带来了许多理想的性质，其中有许多内容我们将在后面的部分讲到。例如，包括L2惩罚在内的SVM中的<strong>最大间隔</strong>属性（如果你感兴趣的话，见<a target="_blank" rel="noopener" href="http://cs229.stanford.edu/notes/cs229-notes3.pdf">CS229</a>）。</p>
<p>正则化最具吸引力的功能是可以惩罚大量的权重值使其倾向于增强泛化性能，因此这意味着没有输入数据的情况下也可以通过其自身大幅度的影响评分分值。例如，假设我们有一些输入向量$x = [1,1,1,1]$，以及两个权重向量$w_1 = [1,0,0,0]$，$w_2 = [0.25,0.25,0.25,0.25]$。然后可以得到$w_1^Tx = w_2^Tx = 1$，因此可见两个权重向量得到了相同的结果，但$w_1$的L2惩罚是1.0而$w_2$的L2惩罚仅仅是0.25。因此，根据L2惩罚的结果来看，权重向量$w2$应该被优先选择，因为它实现了较低的正则化损失。从直觉上来看，这是因为$w_2$的权重值更小并且更扩散。由于L2惩罚倾向于更小且更弥散的权重向量，所以最终的分类器更倾向于是将所有的维度都考虑到，而不是一小部分输入维度影响很大。正如我们在稍后的课程中看到的，这种效果可以提高分类器在测试图像上的泛化性能，并防止产生<em>过拟合</em>。</p>
<p>注意，偏置量具有与权重不同的效果，它不能控制输入数据的影响力。因此，我们通常只对权重$W$进行正则化操作，而不是偏置量$b$。但是，在实践中，这一点通常会忽略不计（即我们统一使用权重和偏置量组合后的矩阵来计算偏差）。最后，请注意，由于正则化惩罚，所以我们绝对不能在所有的样本中的损失值完全为0，除非你错误的把权重矩阵设置为了$W=0$。</p>
<p><strong>代码.</strong>这是在Python中实现的损失函数（无正则化），这是无向量化以及半向量化的形式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_i</span>(<span class="params">x, y, W</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  unvectorized version. Compute the multiclass svm loss for a single example (x,y)</span></span><br><span class="line"><span class="string">  - x is a column vector representing an image (e.g. 3073 x 1 in CIFAR-10)</span></span><br><span class="line"><span class="string">    with an appended bias dimension in the 3073-rd position (i.e. bias trick)</span></span><br><span class="line"><span class="string">  - y is an integer giving index of correct class (e.g. between 0 and 9 in CIFAR-10)</span></span><br><span class="line"><span class="string">  - W is the weight matrix (e.g. 10 x 3073 in CIFAR-10)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  delta = <span class="number">1.0</span> <span class="comment"># see notes about delta later in this section</span></span><br><span class="line">  scores = W.dot(x) <span class="comment"># scores becomes of size 10 x 1, the scores for each class</span></span><br><span class="line">  correct_class_score = scores[y]</span><br><span class="line">  D = W.shape[<span class="number">0</span>] <span class="comment"># number of classes, e.g. 10</span></span><br><span class="line">  loss_i = <span class="number">0.0</span></span><br><span class="line">  <span class="keyword">for</span> j <span class="keyword">in</span> xrange(D): <span class="comment"># iterate over all wrong classes</span></span><br><span class="line">    <span class="keyword">if</span> j == y:</span><br><span class="line">      <span class="comment"># skip for the true class to only loop over incorrect classes</span></span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    <span class="comment"># accumulate loss for the i-th example</span></span><br><span class="line">    loss_i += <span class="built_in">max</span>(<span class="number">0</span>, scores[j] - correct_class_score + delta)</span><br><span class="line">  <span class="keyword">return</span> loss_i</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_i_vectorized</span>(<span class="params">x, y, W</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  A faster half-vectorized implementation. half-vectorized</span></span><br><span class="line"><span class="string">  refers to the fact that for a single example the implementation contains</span></span><br><span class="line"><span class="string">  no for loops, but there is still one loop over the examples (outside this function)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  delta = <span class="number">1.0</span></span><br><span class="line">  scores = W.dot(x)</span><br><span class="line">  <span class="comment"># compute the margins for all classes in one vector operation</span></span><br><span class="line">  margins = np.maximum(<span class="number">0</span>, scores - scores[y] + delta)</span><br><span class="line">  <span class="comment"># on y-th position scores[y] - scores[y] canceled and gave delta. We want</span></span><br><span class="line">  <span class="comment"># to ignore the y-th position and only consider margin on max wrong class</span></span><br><span class="line">  margins[y] = <span class="number">0</span></span><br><span class="line">  loss_i = np.<span class="built_in">sum</span>(margins)</span><br><span class="line">  <span class="keyword">return</span> loss_i</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L</span>(<span class="params">X, y, W</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  fully-vectorized implementation :</span></span><br><span class="line"><span class="string">  - X holds all the training examples as columns (e.g. 3073 x 50,000 in CIFAR-10)</span></span><br><span class="line"><span class="string">  - y is array of integers specifying correct class (e.g. 50,000-D array)</span></span><br><span class="line"><span class="string">  - W are weights (e.g. 10 x 3073)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="comment"># evaluate loss over all examples in X without using any for loops</span></span><br><span class="line">  <span class="comment"># left as exercise to reader in the assignment</span></span><br></pre></td></tr></table></figure>
<p>这一部分主要介绍了：SVM损失函数采用一种特定的方法来衡量训练数据的预测与实际标签的一致性。此外，对训练集进行良好预测也等同于最大限度地减少损失值。</p>
<blockquote>
<p>我们现在要做的是找到一种可以减少损失值的权重的方法。</p>
</blockquote>
<h3 id="实际操作中的注意事项"><a href="#实际操作中的注意事项" class="headerlink" title="实际操作中的注意事项"></a>实际操作中的注意事项</h3><p><strong>设置Delta值.</strong>请注意，我们已经学习过超参数$\Delta$以及其设置。那么应该选择设么样的值才是合适的呢？我们是否必须通过交叉验证才能得到呢？事实证明，这个超参数可以在任何情况下被安全的设置为$\Delta = 1.0$。超参数$\Delta$和$\lambda$看起来似乎是两个不同的超参数，但事实上他们控制着相同的操作：都是数据损失和正则化损失直接的权衡。理解这一点的关键是，权重$W$的大小对最终评分有直接影响（这也是他们之间的差异）：当我们缩小$W$的所有数值时，评分的差异将变得更小，反之当我们放大权值$W$时，评分结果的差异也将变大。因此，评分之间的准确的间隔值（例如$\Delta = 1$或者$\Delta = 100$）在某种意义上是无意义的。因为权值可以被任意的缩小或放大。因此，唯一真正的权衡指标是我们允许权值增长的成都（通过正则化强度$\lambda$来控制）。</p>
<p><strong>与二分类支持向量机的关系.</strong>你可能在参加这个课程之前了解过二分类支持向量机，所以，其中第i个样本的损失可以写成：</p>
<script type="math/tex; mode=display">
L\_i = C \max(0, 1 - y\_i w^Tx\_i) + R(W)</script><p>这里的$C$是一个超参数，并且$y_i \in ｛ -1,1 ｝$。你可以尝试自己证明，我们本节所讨论的多类别SVM实际上是包含了二分类SVM这一特例的。也就是说，如果我们只有两个类，那么损失值就降低到上面的二分类SVM损失函数的表达形式。此外，这个表达式中的$C$与之前的$\lambda$对结果起着相同的控制作用，他们之间的关系是：$C \propto \frac{1}{\lambda}$。</p>
<p><strong>题外话：原始优化.</strong>如果你在此课程之前就已经知道了SVM，那么你可能还听说过SVM的内核，对偶，以及SMO算法等等。在这节课中（与神经网络的情况一样）我们将在无约束的原始形式的情况下优化目标。许多目标在技术上是不可区分的（例如，函数max(x,y)在x=y时无法区分哪一个是大的），但实际上这不是问题，并且常见的是使用子梯形图。</p>
<p><strong>题外话：其他SVM表达式.</strong>值得注意的是，本节介绍的多类别SVM是在几个多类别SVM中的其中一个。另外一个常用的形式是<em>一对全部One-Vs-All(OVA)</em>SVM，其中每个类别分别对应一个独立的该类别到全部其他类别的二分类SVM。与之相关的一个在实践中不常用到的是<em>全部对全部All-vs-All(AVA)</em>策略。我们的策略是遵循<a target="_blank" rel="noopener" href="https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es1999-461.pdf">Weston和Watkins 1999（pdf）</a>的版本，这是一个比OVA更强大的版本（在这个版本的SVM中，您可以构建多类别的数据集，并且实现数据损失为0，但OVA无法做到这一点。如果对此感兴趣，请参阅论文中的细节）。最后一个你可能会见到的表达式是<em>结构化SVM</em>，这最大限度地提高了正确分类的得分与不正确得分中第二高的得分的间隔值的大小。对于这些SVM表达形式的差异的讨论超出了本课程的范畴。这些版本的SVM在实践过程中是可以安全的使用的，但是即使是最简单的OVA策略的形式也可以有效的分类（关于这些讨论，Rikin等人在2004年的<a target="_blank" rel="noopener" href="http://www.jmlr.org/papers/volume5/rifkin04a/rifkin04a.pdf">In Defense of One-Vs-All Classification (pdf)</a>也有提到）。</p>
<h3 id="Softmax分类器"><a href="#Softmax分类器" class="headerlink" title="Softmax分类器"></a>Softmax分类器</h3><p>结果表明，SVM是两种常用的分类器之一。另外一个流行的选择是<strong>Softmax分类器</strong>，它拥有与SVM不同的损失函数。如果你之前有听过二分类逻辑回归分类器，那么对于Softmax分类器来说，实际上就是它在多类别上的泛化形式。不同于SVM那样通过函数$f(x_i,W)$为每个类别输出评分（未经校准的评分可能很难定义），Softmax分类器给出了一个稍微更直观的输出（归一化的分类概率），并且还有一个对于概率的解释，我们将在稍后介绍。在Softmax分类器中，映射函数$f(x_i; W) =  W x_i$保持不变，但是我们现在将这些分数解释为每个类的归一化对数概率，并用<strong>交叉熵损失</strong>代替<em>合页损失(hinge loss)</em>：</p>
<script type="math/tex; mode=display">
L\_i = -\log\left(\frac{e^{f\_{y\_i}}}{ \sum\_j e^{f\_j} }\right) \hspace{0.5in} \text{or equivalently} \hspace{0.5in} L\_i = -f\_{y\_i} + \log\sum\_j e^{f\_j}</script><p>这里我们使用了符号$f_j$来表示类别分数向量$f$的第j个元素。如上所述，数据集的完全损失是所有训练样本中的$L_i$均值与正则化项$R(W)$所组成。函数$f_j(z) = \frac{e^{z_j}}{\sum_k e^{z_k}}$称为<strong>softmax函数</strong>：它接受一个包含任意真实值的分数向量($z$)，并将其向量值压缩到总和为1的0到1之间的值。如果你是第一次看到涉及softmax功能的完整的交叉熵损失函数，可能会觉得看起来很恐怖，但对于它的功能的理解是相对简单的。</p>
<p><strong>信息论的观点.</strong>真实分布$p$与假设分布$q$之间的交叉熵定义为：</p>
<script type="math/tex; mode=display">
H(p,q) = - \sum_x p(x) \log q(x)</script><p>Softmax分类器最小化了预测分类的概率分布（正如上面所见到的$q = e^{f<em>{y_i}}  / \sum_j e^{f_j}$）与真实分类的的概率分布的交叉熵，在这里我们指的是所有在正确类别上的概率分布（例如$p = [0, \ldots 1, \ldots, 0]$只包含在$y_i$处的一个1）。此外，由于交叉熵可以写作熵和Kullback-Leibler分歧的和的形式：$H(p,q) = H(p) + D</em>{KL}(p||q)$，并且delta函数$p$的熵是0，这也相当于最小化两个分布之间的KL分歧（距离的度量）。换句话说，交叉熵的目标是希望对于正确类别的预测结果的分布与真实分布达到一致。</p>
<p><strong>概率的解释.</strong>看看下面的表达式：</p>
<script type="math/tex; mode=display">
P(y\_i \mid x\_i; W) = \frac{e^{f\_{y\_i}}}{\sum\_j e^{f\_j} }</script><p>这个式子可以解释为对于给定图片$x_i$，并由$W$参数化的分配给正确标签$y_i$的（归一化）概率。为了理解这一点，请回忆一下Softmax分类器将输出向量$f$中的评分值解释为没有归一化的对数概率。那么以这些数值做指数函数的幂就得到了没有归一化的概率，而除法操作则对数据进行了归一化处理，使得这些概率的和为1。从概率论的角度来理解，我们就是在最小化正确分类的负对数概率，这可以看做是在进行<em>最大似然估计</em>（MLE）。该解释的另一个好处是，损失函数中的正则化部分$R(W)$可以被看做是权重矩阵$W$的高斯先验，这里进行的是最大后验估计（MAP）而不是最大似然估计。提及这些解释只是为了让读者形成直观的印象，具体细节就超过本课程范围了。</p>
<p><strong>实操事项：数值稳定。</strong>编程实现softmax函数计算的时候，中间项$e^{f_{y_i}}$和$\sum_j e^{f_j}$因为存在指数函数，所以数值可能非常大。除以大数值可能导致数值计算的不稳定，所以学会使用归一化技巧非常重要。如果在分式的分子和分母都乘以一个常数C，并把它变换到求和之中，就能得到一个从数学上等价的公式：</p>
<script type="math/tex; mode=display">
\frac{e^{f\_{y\_i}}}{\sum\_j e^{f\_j}}
= \frac{Ce^{f\_{y\_i}}}{C\sum\_j e^{f\_j}}
= \frac{e^{f\_{y\_i} + \log C}}{\sum\_j e^{f\_j + \log C}}</script><p>$C$的值可自由选择，不会影响计算结果，通过使用这个技巧可以提高计算中的数值稳定性。通常将$C$设为$logC=-max_jf_j$。该技巧简单地说，就是应该将向量$f$中的数值进行平移，使得最大值为0。代码实现如下：</p>
<h3 id="SVM-vs-Softmax"><a href="#SVM-vs-Softmax" class="headerlink" title="SVM vs Softmax"></a>SVM vs Softmax</h3><h2 id="线性分类的可交互网页演示"><a href="#线性分类的可交互网页演示" class="headerlink" title="线性分类的可交互网页演示"></a>线性分类的可交互网页演示</h2><h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/07/30/%E3%80%90%E6%96%AF%E5%9D%A6%E7%A6%8Fcs231n%E3%80%912-1%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="DannyLee">
      <meta itemprop="description" content="愿你的努力终取得成果">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="圣巢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/07/30/%E3%80%90%E6%96%AF%E5%9D%A6%E7%A6%8Fcs231n%E3%80%912-1%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" class="post-title-link" itemprop="url">【斯坦福cs231n】2-1图像分类</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-07-30 13:27:00" itemprop="dateCreated datePublished" datetime="2017-07-30T13:27:00+00:00">2017-07-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-10 17:00:48" itemprop="dateModified" datetime="2021-02-10T17:00:48+00:00">2021-02-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/cs231n/" itemprop="url" rel="index"><span itemprop="name">cs231n</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h2><p><strong>动机.</strong>在这一部分，我们将介绍图像分类问题，这是将输入图像分配到一组固定类别标签中的某一个标签的任务。尽管这个问题很简单，但它是计算机视觉的核心问题之一，并且有着各种各样的实际应用。此外，正如我们将在后面看到的，许多其它不同的计算机视觉任务（例如对象检测，分割）都可以被简化为图像识别问题。</p>
<p><strong>示例.</strong>例如，在下面的图像识别的例子中，图像分类模型接收单张图片，并对四个标签{cat，dog，hat，mug}的概率赋值。如图所示，请记住，对于计算机而言，图像被表示为一个大的三维数组。在这个例子中，猫图像是248像素宽，400像素高，并且有三个颜色通道：红色，绿色，蓝色（或简称RGB）。因此，该图像由248 x 400 x 3数字组成，总共297,600个数字。其中每个数字都是一个范围在0（黑色）到255（白色）的整数。我们的任务就是把这将近30万个数字转成像{cat}这样的单一的标签。</p>
<p><img src="/img/17_07_30/001.png" alt=""></p>
<blockquote>
<p>图像分类的任务是预测给定图像的单个标签（或者类似这里的一个标签的概率分布，用于表示我们信心）。图像是包含0到255整数的3维整数，大小是宽度x高度x3。其中3表示RGB三色通道。</p>
</blockquote>
<hr>
<p><strong>挑战.</strong>由于视觉识别问题（例如识别“猫”的例子）对于人类来说，是再简单不过的问题，但从计算机视觉算法的角度来重新审视这个问题，就充满了挑战。在我们下面提出的这些挑战中，请记住图像的原始表示形式为3-D阵列的亮度值：</p>
<ul>
<li><strong>不同的观察点(Viewpoint variation)</strong>照相机可以从多个方向来拍摄同一个实例对象。</li>
<li><strong>大小变化(Scale variation)</strong>视觉分类通常会出现不同的尺寸变化（这里包含在现实世界中的尺寸，不仅仅是针对图像中的大小程度）。</li>
<li><strong>变形(Deformation)</strong>许多物体并不是刚体，并且可以以极端的方式变形。</li>
<li><strong>闭塞(Occlusion)</strong>我们所观察的目标对象可能处于被遮挡的状态。有的时候我们只能看到对象的一小部分（像素比较少）。</li>
<li><strong>光照情况(Illumination conditions)</strong>照明的效果在像素级上的影响是剧烈的。</li>
<li><strong>背景杂波(Background clutter)</strong>我们所观察的对象可能融入到他们的背景环境中，使其难以识别。</li>
<li><strong>类型内部变化(Intra-class variation)</strong>我们所关心的类别通常会比较宽泛，比如椅子。不同类型的椅子有着不同的外观，但他们都属于“椅子”这一类别。</li>
</ul>
<p>一个好的图片识别分类模型必须在所有这些情况交叉出现的情况下，都能产出不变的结果输出，同时保持类别变化时的敏感性。</p>
<p><img src="/img/17_07_30/002.jpeg" alt=""></p>
<hr>
<p><strong>数据驱动的方法.</strong>如何编写一个将图像分类到不同类别的算法呢？与编写一个像数字排序这样的算法不同的是，如何编写一个识别猫的算法的方法并不是显式的。我们不会视图在代码中指定每个不同的类别在代码中是什么样的，我们所采取的方法就像是在教一个小孩子一样：我们首先为每个类别提供许多个实例，然后开发学习算法，通过学习算法来输入这些类别实例图像，学习到这些每个类别的视觉外观。这种方法被称为数据驱动方法，因为它依赖于事先已经被标记过的标签的图像的训练数据集：</p>
<p><img src="/img/17_07_30/003.jpg" alt=""></p>
<blockquote>
<p>上图是四个视觉类别的训练集示例。在实际情况中，我们可能会有数千种类别和数十万种图像。</p>
</blockquote>
<hr>
<p><strong>图像分类流水线.</strong>正如我们已经看到的，图像分类中的任务是使用一个像素数组来代表一个图像，并且为其分配一个标签。完整的流水线可以表示成如下的流程：</p>
<ul>
<li><strong>输入：</strong>我们的输入由一组N个图像组成，每一个都标有K个不同的类别。我们将这些数据称为训练集。</li>
<li><strong>学习：</strong>我们的任务是使用训练集来了解每一个类别的样子。我们将此步骤称为<em>训练分类器（training a classifier）</em>，或者<em>学习模型（learning a model）</em>。</li>
<li><strong>评估：</strong>最后，我们通过预测一组从未见过的新图像的标签来评估分类器的质量。然后，我们将这些图像的真实标签与分类器预测的图像进行比较。直观地说，我们希望达到的效果是大多数预测结果与真实答案（我们称之为ground truth）相匹配。</li>
</ul>
<h2 id="最邻近分类器（Nearest-Neighbor-Classifier）"><a href="#最邻近分类器（Nearest-Neighbor-Classifier）" class="headerlink" title="最邻近分类器（Nearest Neighbor Classifier）"></a>最邻近分类器（Nearest Neighbor Classifier）</h2><p>我们将开发一种叫做<strong>最邻近分类器</strong>，来作为我们的第一个图片分类的实现。这种分类器与卷积网络无关，在实践中很少使用，但它可以使我们了解处理图像分类问题的基本方法。</p>
<p><strong>示例图像分类数据集：CIFAR-10.</strong><a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>是一个流行的toy级别的图像分类数据集。这个数据集包含60,000个长宽都是32像素的小图片。每个图片都有一个标签（例如“飞机，汽车，鸟等”）。这60,000张图像被划分为50,000张图像的训练集和10,000张图像的测试集。在下面的图片中，您可以看到10个类别中的每个类别的10个随机示例图像：</p>
<p><img src="/img/17_07_30/004.jpg" alt=""></p>
<blockquote>
<p>左图：来自CIFAR-10数据集的示例图像。右图：第一列显示几个测试图像，并且在每个测试图像旁边，我们根据像素差异显示训练集中的前10个最近邻居。</p>
</blockquote>
<hr>
<p>假设现在我们有50,000张训练图像（50,000张图像都有其对应的标签数据），并且我们希望为剩余的10,000张图片打标签。最邻近分类器将接收一个测试图片，与每一张训练图片做对比，然后以其最接近的训练图像的标签作为其预测标签。在上面的右图中，您可以看到10个示例图片的十个用这种方式得到的最相近的结果图片。请注意，在这10个示例中，有三个图片在检索相同的类别，而其他7个示例并非如此。例如，在第八行最接近“马头图片”的训练的图像是一个“红色汽车图片”，也许是由于它们都拥有黑色背景的原因。这种结果，使得这匹马的形象在这种情况下会被误认为是汽车。</p>
<p>您可能已经注意到，我们并没有详细的说明我们是如何比较这两个尺寸为32 x 32 x 3的图像的细节的。一种最简单的处理方式是对像素点逐个比较，然后求差值绝对值之和。换句话说，给出两个图像，并将其表示为向量$I_1, I_2$，比较他们的一种合理的方式是求<strong>L1距离</strong>:</p>
<script type="math/tex; mode=display">
d_1 (I_1, I_2) = \sum\_p \left| I^p_1 - I^p_2 \right|</script><p>下面是将这段程序可视化的过程：</p>
<p><img src="/img/17_07_30/005.jpeg" alt=""></p>
<blockquote>
<p>一个使用L1距离来比较图片像素差异的示例（在这里例子中只有一个颜色通道）。将两个图像元素相减，然后将所有差值相加到一个数字上。如果两个图像相同，则结果将为零。但如果图像非常不同，结果会很大。</p>
</blockquote>
<hr>
<p>我们来看看我们如何在代码中实现分类器。首先，我们将CIFAR-10数据作为4个阵列加载到内存中：用于训练的数据/标签集合，以及用于测试的数据/标签集合。在下面的代码中，<code>Xtr</code>(尺寸是50,000 x 32 x 32 x 3)包含全部的用于训练的图像数据，与之对应的是一个一维数组<code>Ytr</code>(长度是50,000)持有训练集标签(标签是0到9的类别)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Xtr, Ytr, Xte, Yte &#x3D; load_CIFAR10(&#39;data&#x2F;cifar10&#x2F;&#39;) # a magic function we provide</span><br><span class="line"># flatten out all images to be one-dimensional</span><br><span class="line">Xtr_rows &#x3D; Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Xtr_rows becomes 50000 x 3072</span><br><span class="line">Xte_rows &#x3D; Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows becomes 10000 x 3072</span><br></pre></td></tr></table></figure>
<p>现在我们把所有的图像都拉伸成行了，下面的代码演示了我们如何训练并且评估一个分类器：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nn &#x3D; NearestNeighbor() # create a Nearest Neighbor classifier class</span><br><span class="line">nn.train(Xtr_rows, Ytr) # train the classifier on the training images and labels</span><br><span class="line">Yte_predict &#x3D; nn.predict(Xte_rows) # predict labels on the test images</span><br><span class="line"># and now print the classification accuracy, which is the average number</span><br><span class="line"># of examples that are correctly predicted (i.e. label matches)</span><br><span class="line">print &#39;accuracy: %f&#39; % ( np.mean(Yte_predict &#x3D;&#x3D; Yte) )</span><br></pre></td></tr></table></figure>
<p>请注意，作为评估标准，我们通常使用<strong>准确率(accuracy)</strong>来衡量预测结果的准确性。请注意，我们将构建的所有分类器都满足这一个常见的API：它们有一个接受用来学习的数据和标签的<code>train(X,y)</code>函数。在内部，该类应该建立一些标签的模型，以及如何从数据中预测结果的逻辑。同时还需要有一个用来接受新数据并且预测其标签的<code>predict(X)</code>函数。下面是一个L1距离的最邻近分类器的一个简单实现，它满足这套模板：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">class NearestNeighbor(object):</span><br><span class="line">  def __init__(self):</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">  def train(self, X, y):</span><br><span class="line">    &quot;&quot;&quot; X is N x D where each row is an example. Y is 1-dimension of size N &quot;&quot;&quot;</span><br><span class="line">    # the nearest neighbor classifier simply remembers all the training data</span><br><span class="line">    self.Xtr &#x3D; X</span><br><span class="line">    self.ytr &#x3D; y</span><br><span class="line"></span><br><span class="line">  def predict(self, X):</span><br><span class="line">    &quot;&quot;&quot; X is N x D where each row is an example we wish to predict label for &quot;&quot;&quot;</span><br><span class="line">    num_test &#x3D; X.shape[0]</span><br><span class="line">    # lets make sure that the output type matches the input type</span><br><span class="line">    Ypred &#x3D; np.zeros(num_test, dtype &#x3D; self.ytr.dtype)</span><br><span class="line"></span><br><span class="line">    # loop over all test rows</span><br><span class="line">    for i in xrange(num_test):</span><br><span class="line">      # find the nearest training image to the i&#39;th test image</span><br><span class="line">      # using the L1 distance (sum of absolute value differences)</span><br><span class="line">      distances &#x3D; np.sum(np.abs(self.Xtr - X[i,:]), axis &#x3D; 1)</span><br><span class="line">      min_index &#x3D; np.argmin(distances) # get the index with smallest distance</span><br><span class="line">      Ypred[i] &#x3D; self.ytr[min_index] # predict the label of the nearest example</span><br><span class="line"></span><br><span class="line">    return Ypred</span><br></pre></td></tr></table></figure>
<p>如果你运行了上面的代码，你将看到这个分类器在CIFAR-10的数据集上只有<strong>38.6%</strong>的准确率。比我们随机选取的结果准确率高一些（随机选取的准确率是10%，因为我们有10个类别），但这个结果与人类真实的识别准确率（估计<a target="_blank" rel="noopener" href="http://karpathy.github.io/2011/04/27/manually-classifying-cifar10/">约为94%</a>）或者最先进的卷积神经网络能达到的95%准确率相比，差的很远。（见CIFAR-10在Kaggle上的<a target="_blank" rel="noopener" href="http://www.kaggle.com/c/cifar-10/leaderboard">排行榜</a>）</p>
<p><strong>距离的选择.</strong>有许多其他的方式来计算两个向量之间的距离。一种比较常用的方式是计算两个向量之间的欧几里得距离，即<strong>L2距离</strong>。公式如下:</p>
<script type="math/tex; mode=display">
d\_2 (I\_1, I\_2) = \sqrt{\sum\_{p} \left( I^p\_1 - I^p\_2 \right)^2}</script><p>换句话说，我们之前需要计算两者的像素差，而这一次，我们需要计算像素差的平方，并且把他们加起来之后开根号。在numpy中，我们可以用一行代码来实现上述的计算：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distances &#x3D; np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis &#x3D; 1))</span><br></pre></td></tr></table></figure>
<p>请注意，在上面的计算中，我引入了<code>np.sqrt</code>，但在实际的最邻近应用中，我们可以省略求平方根的操作，因为平方根是一个单调函数。也就是说，它对距离的绝对值的差值起到了缩放的作用，但它依然保留了排序结果，因此对于最邻近问题来说，有没有这一步开根号的运算，其结果都是相同的。如果你在CIFAR-10上运行这个L2最邻近分类器，那么你得到的准确率是<strong>35.4%</strong>（比L1的结果略低一些）。</p>
<p><strong>L1 vs L2.</strong>这两者之间存在什么样的差异呢？这是一个很有意思的问题。在特定的情况下，当涉及两个向量之间的差异时，L2距离比L1距离更糟一些。L1和L2距离（或等效地，一对图像之间的差异的L1 / L2范数）是<a target="_blank" rel="noopener" href="http://planetmath.org/vectorpnorm">p范数</a>最常用的特殊情况。</p>
<h3 id="KNN分类器（k-Nearest-Neighbor-Classifier）"><a href="#KNN分类器（k-Nearest-Neighbor-Classifier）" class="headerlink" title="KNN分类器（k - Nearest Neighbor Classifier）"></a>KNN分类器（k - Nearest Neighbor Classifier）</h3><p>您可能已经注意到，当我们想进行预测时，只使用最接近的一个图像的标签是很奇怪的。事实上，通过使用所谓的<strong>KNN分类器</strong>，人们可以做得更好。实际上这个想法很简单：不是在训练集中找到单个最接近的图像，我们将找到最接近的<strong>k</strong>个图像，并让他们对测试图像的标签进行投票。尤其是，当$k=1$的时候，我们KNN分类器实际上就是最邻近分类器。从直觉上来说，较高的<strong>k</strong>值有更平滑的效果，使得分类器更能抵抗离群值：</p>
<p><img src="/img/17_07_30/006.jpeg" alt=""></p>
<blockquote>
<p>上图中，使用二维散点图用三种颜色（红、蓝、绿）来表示三种类别，分别展示了原始数据在最邻近分类器上和在5-NN分类器上的效果。彩色的区域显示在L2距离下生成的<strong>判定边界</strong>。白色区域显示出不能被明确分类的点（即，类别投票至少被分为两类）。请注意，在使用最邻近分类器的情况下，异常值数据点（例如蓝色区域中的绿点）会产生可能不正确的预测的区块，而5-NN分类器在这种情况下会得到相对平滑的效果，这也意味着对测试数据的<strong>泛化</strong>能力更好（未被显示）。还要注意，5-NN图像中的灰色区域是由最邻近的几个邻居颜色不同导致的（例如，有两个是红色的，两个是蓝色的，一个是绿色的）。</p>
</blockquote>
<hr>
<p>在实践中，当我们使用kNN分类器时，应该选择什么样的k值才合适呢？接下来我们来谈谈这个问题。</p>
<h2 id="验证集，交叉验证，超参数调谐"><a href="#验证集，交叉验证，超参数调谐" class="headerlink" title="验证集，交叉验证，超参数调谐"></a>验证集，交叉验证，超参数调谐</h2><p>kNN分类器需要指定一个k值，但是当k取什么值时效果最好呢？另外，我们还可以选择L1范数、L2范数，等，以及许多我们甚至没有考虑到的选择。这些选择被称为<strong>超参数（Hyperparameter）</strong>，他们在许多机器学习算法的设计过程中都会出现。通常这些值应该被设置为多少，并不是十分显而易见。</p>
<p>你也许会试图建议我们尝试许多不同的值，然后看看哪些值的效果最好。这的确是一个好办法，这也是我们接下来要做的，但这个过程必须非常仔细地进行。特别要说吗的是，<strong>我们不能使用测试集来调整参数</strong>。当您在设计一款机器学习算法时，您应该将将测试集视为一个非常宝贵的资源，在理想情况下，除非在测试阶段，都不要去触碰它。否则，你调整的参数将会作用域测试集上，这样做非常危险，因为当你开始在真实的数据上使用该模型时，你会发现性能显著降低。在实践过程中，我们称这种现象为<strong>过拟合</strong>测试集。关于这一现象的另一种解释是，如果你在测试集上调整了参数，你实际上是在把测试集当做训练集在使用，因此，你实现的模型的性能对于实际观察到的情况来说都是过于乐观的。但与之相反的，如果我们只是在最后的测试过程中使用一次测试集，那么它仍然是测量分类器<strong>泛化</strong>的一个很好的代理（我们将在以后的课程中看到更多关于泛化的讨论）。</p>
<blockquote>
<p>评估测试集在每次训练结束后只运行一次。</p>
</blockquote>
<p>幸运的是，有一种不触碰测试集的调整超参数的方法。这个方法就是将我们的训练集分为两部分：其中稍微小一些的那部分训练集，我们称之为<strong>验证集(validation set)</strong>。使用CIFAR-10为例，我们使用49,000的样本作为训练集，然后使用剩下的1,000个样本作为验证集。这个验证集是用来调整超参数的一个假测试集。</p>
<p>在CIFAR-10中，这个例子看起来可能是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># assume we have Xtr_rows, Ytr, Xte_rows, Yte as before</span><br><span class="line"># recall Xtr_rows is 50,000 x 3072 matrix</span><br><span class="line">Xval_rows &#x3D; Xtr_rows[:1000, :] # take first 1000 for validation</span><br><span class="line">Yval &#x3D; Ytr[:1000]</span><br><span class="line">Xtr_rows &#x3D; Xtr_rows[1000:, :] # keep last 49,000 for train</span><br><span class="line">Ytr &#x3D; Ytr[1000:]</span><br><span class="line"></span><br><span class="line"># find hyperparameters that work best on the validation set</span><br><span class="line">validation_accuracies &#x3D; []</span><br><span class="line">for k in [1, 3, 5, 10, 20, 50, 100]:</span><br><span class="line">  </span><br><span class="line">  # use a particular value of k and evaluation on validation data</span><br><span class="line">  nn &#x3D; NearestNeighbor()</span><br><span class="line">  nn.train(Xtr_rows, Ytr)</span><br><span class="line">  # here we assume a modified NearestNeighbor class that can take a k as input</span><br><span class="line">  Yval_predict &#x3D; nn.predict(Xval_rows, k &#x3D; k)</span><br><span class="line">  acc &#x3D; np.mean(Yval_predict &#x3D;&#x3D; Yval)</span><br><span class="line">  print &#39;accuracy: %f&#39; % (acc,)</span><br><span class="line"></span><br><span class="line">  # keep track of what works on the validation set</span><br><span class="line">  validation_accuracies.append((k, acc))</span><br></pre></td></tr></table></figure>
<p>在此过程结束之前，我们可以绘制一个图表，来显示哪个k值表现的更好。然后我们使用这个最好的k值，对真正的测试集进行一次评估。</p>
<blockquote>
<p>将你的训练集分割为训练集和验证集。使用验证集来调整所有的超参数。最后在测试集上仅运行一次评估操作，并上报结果。</p>
</blockquote>
<p><strong>交叉验证.</strong>在你的训练集（同时也包括验证集）可能非常小的情况下，人们有时使用一个更复杂叫做<strong>交叉验证</strong>的技术来调节超参数。作用于我们之前的例子中，取代之前我们选取1000个数据点来作为验证集、剩下的部分用做测试集这种方式，我们通过迭代不同的验证集以及求得他们的平均表现这种方式，来得到一个更好的，噪音更小的k值。举个例子，在5倍交叉验证中，我们将数据分为5等份，使用其中4份来训练，用剩余的1份作为验证。然后我们迭代所有其他份数据来作为验证集，计算每一份作为验证集的最终表现，最终将每次得到的表现求和在求平均值。</p>
<p><img src="/img/17_07_30/007.png" alt=""></p>
<blockquote>
<p>参数k的五倍交叉验证运行示例。对于k的每个值，我们都在4份数据上训练，并且在第5份数据上评估。因此，对于每个k，我们在交叉验证上都会有5个评估得到的准确率（y轴是准确率，每个结果对应一个点）。趋势曲线通过每个k的结果的平均值绘制，错误条表明标准偏差。注意在这里的一个特定场景，交叉验证集建议我们选取的k=7，此时在数据集上的预测效果最好（对应于图中的峰值处）。如果我们使用超过5份的数据，我们也许会看到一个更平滑（低噪音）的曲线。</p>
</blockquote>
<hr>
<p><strong>实践.</strong>在实践中，人们更倾向于避免使用交叉验证，人们更愿意接受单个的验证集分割，因为交叉验证的计算是十分昂贵的。人们倾向使用的分割方式是将训练集分割50%-90%用作训练，剩下的部分用作验证。然而，这取决于多个因素：例如如果超参数数量很大，你也许更倾向于使用一个更大的验证集分割。如果验证集样本的数量很少（可能只有几百个），那么使用交叉验证则更安全一些。正如你所见的，典型的交叉验证可能会是三等分、5等分或者10等分的交叉验证。</p>
<p><img src="/img/17_07_30/008.jpeg" alt=""></p>
<blockquote>
<p>常见的数据分割。给定训练集和测试集。训练集被分割为几等份（例如这里的五等分）。第1-4份数据作为训练集。一份作为验证集（例如这里的黄颜色的第五份），用来调节超参数。交叉验证更进一步的操作是迭代循环这5份数据，分别作为验证集的预测结果。这被称为5倍交叉验证。一旦模型被训练，并且确定了所有的最佳的超参数，最终在测试集（红色）上单词评估干模型。</p>
</blockquote>
<hr>
<h2 id="最近邻分类器的优缺点"><a href="#最近邻分类器的优缺点" class="headerlink" title="最近邻分类器的优缺点"></a>最近邻分类器的优缺点</h2><p>思考最邻近分类器的优缺点是一件值得做的事情。很明显，一个优点是：它的实现很简单，理解起来也很简单。此外，这个分类器不需要训练的时间，因为用于预测结果的数据全部来自于被存储的以及可能被索引的训练数据。但是，我们需要消耗一次测试的时间，因为对测试数据进行分类，我们需要将每个训练样本进行比较。这是一种不好的方式，因为在实践过程中，我们往往很在意测试运行的时间，而不太在意训练所花费的时间。事实上，我们将在稍后的深度神经网络课程中，我们将看到另一个极端：它会在训练样本的过程中花费巨大的开销，但一旦训练结束，在一个新的测试样本上执行分类任务时的开销是非常小的。这种模式在实践中更为理想。</p>
<p>除此之外，关于最邻近分类器的计算复杂度问题，一直是一个活跃的研究领域，并且有一些可以加速数据集中最邻近数据的查找的<strong>近似最邻近（Approximate Nearest Neighbor(ANN)）</strong>算法和库存在（例如<a target="_blank" rel="noopener" href="http://www.cs.ubc.ca/research/flann/">FLANN</a>）。这些算法允许在检索期间以其空间/时间复杂度来折衷最近相邻检索的正确性，并且通常依赖于涉及构建kdtree或运行k-means算法的预处理/索引阶段。</p>
<p>在某些场景中，最近邻分类器有时可能是一个很好的选择（特别是如果数据是低维数据），但很少适用于实际的图像分类场景。其中一个问题是图像是高维度对象（即它们通常包含许多像素），并且高维空间的距离是非常不直观的。下面的图像说明了我们上面开发的基于像素的L2相似度与人类感知相似性的区别：</p>
<p><img src="/img/17_07_30/009.png" alt=""></p>
<blockquote>
<p>高维数据（尤其是图像）上基于像素的距离可能非常不直观。基于L2像素距离，原始图像（左）和旁边的三个其他图像都距离它们相同。显然，像素方向的距离并不能与人类感知上的相似性相对应。</p>
</blockquote>
<hr>
<p>这里有更多的可视化数据来说服你，使用像素差异来比较图像是不够的。我们可以使用一种名为t-SNE的可视化技术来拍摄CIFAR-10图像，并将其嵌入到二维空间中，使其（局部）成对距离最好地保留下来。在这种可视化中，根据我们上面开发的L2像素距离，我们将其L2距离相对较小的图像聚集在一起：</p>
<p><img src="/img/17_07_30/010.jpg" alt=""></p>
<blockquote>
<p>使用t-SNE嵌入二维的CIFAR-10图像。该图像附近的图像被认为是基于L2像素距离接近的。注意到背景的强烈影响，而不是语义层次的差异。点击<a target="_blank" rel="noopener" href="http://cs231n.github.io/assets/pixels_embed_cifar10_big.jpg">这里</a>查看这个可视化的更大版本。</p>
</blockquote>
<hr>
<p>特别地，请注意，彼此相邻的图像更多是图像的平均颜色分布或背景的类型相似的图像，而不是其相似的标签类型的图像。例如，可以看到一张狗的图片和一张青蛙的照片像邻，因为两者都是在白色背景上。理想情况下，我们希望所有10个类中的图像形成自己的集群，使得同一类的图像在彼此附近，而不管不相关的特征和变化（如背景）。然而，要获得这个属性，我们将不得不超越像素级别的去考虑问题。</p>
<h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p>综上所述：</p>
<ul>
<li>我们引入了<strong>图像分类</strong>的问题，其中给出了一组全部标记为单一类别的图像。然后，我们要求为这些类别预测一组新的测试图像，并测量预测的准确性。</li>
<li>我们引入了一个称为<strong>最近邻分类器</strong>的简单分类<strong>器</strong>。我们看到有与此分类器相关联的多个超参数（如k值或用于比较示例的距离类型），并没有明显的选择方式。</li>
<li>我们看到设置这些超参数的正确方法是将训练数据分为两个：训练集和假测试集，我们称之为<strong>验证集</strong>。我们尝试不同的超参数值，并保持在验证集上达到最佳性能的值。</li>
<li>如果缺乏培训数据是一个问题，我们讨论了一个称为<strong>交叉验证</strong>的过程，它可以帮助减少噪声，以估计哪些超参数最有效。</li>
<li>一旦找到了最佳的超参数，我们修复它们，并对实际测试集执行单个<strong>评估</strong>。</li>
<li>我们看到最近邻居可以在CIFAR-10上获得约40％的准确性。它实现起来很简单，但要求我们存储整个训练集，并且在测试图像上进行评估是很昂贵的。</li>
<li>最后，我们看到在原始像素值上使用L1或L2距离是不够的，因为这些距离与图像的背景和颜色分布相比，与其语义内容相比更强烈。</li>
</ul>
<p>在接下来的课程中，我们将着手解决这些挑战，最终达成90％精度的解决方案，让我们在完成学习后完全丢弃训练集，并允许我们在不到一毫秒内评估测试图像。</p>
<h2 id="总结：在实践中应用kNN"><a href="#总结：在实践中应用kNN" class="headerlink" title="总结：在实践中应用kNN"></a>总结：在实践中应用kNN</h2><p>如果您希望在实践中应用kNN（希望不是在图像上），请按如下步骤进行：</p>
<ul>
<li>1.预处理数据：规范数据中的特征（例如图像中的一个像素），使其具有零均值和单位方差。我们将在后面的章节中更详细地介绍这一点，并且选择不覆盖本节中的数据规范化，因为图像中的像素通常是均匀的，并且不会展现出广泛不同的分布，从而减轻了数据规范化的需要。</li>
<li>2.如果您的数据非常高，请考虑使用维度降低技术，如PCA（<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Principal_component_analysis">wiki ref</a>，<a target="_blank" rel="noopener" href="http://cs229.stanford.edu/notes/cs229-notes10.pdf">CS229ref</a>，<a target="_blank" rel="noopener" href="http://www.bigdataexaminer.com/cgi-sys/suspendedpage.cgi">博客引用</a>），甚至使用<a target="_blank" rel="noopener" href="http://scikit-learn.org/stable/modules/random_projection.html">随机投影</a>。</li>
<li>3.将您的训练数据随机分成训练集/验证集。根据经验，70-90％的数据通常会分配到训练集上。此设置取决于您拥有多少超参数以及您期望他们拥有多少影响力。如果有很多超参数需要估计，那么您应该在验证集更大的一边进行有效的估计。如果您的验证数据集比较小，最好将训练数据拆分为几等分，并执行交叉验证。如果你能负担得起计算机的运算量，那么交叉验证（更多的份数越好，但是更昂贵）总是更安全。</li>
<li>4.对于k的许多选择（比如越多越好）和不同距离类型（L1和L2都是不错的选择），对验证数集（对于所有份数，如果进行交叉验证）训练和评估kNN分类器。</li>
<li>5.如果您的kNN分类器运行时间过长，请考虑使用近似最近邻库（<a target="_blank" rel="noopener" href="http://www.cs.ubc.ca/research/flann/">FLANN</a>）来加速检索（以某种精度为代价）。</li>
<li>6.记下提供最佳效果的超参数。有一个问题是您应该使用最佳超参数的完整训练集，因为如果要将验证数据折叠到训练集中（因为数据的大小会更大），最佳超参数可能会改变。实际上，在最终分类器中不使用验证数据更为清晰，并且在估计超参数时认为它被刻录。评估测试集上的最佳模型。上报在测试集上的准确率，这个结果作为kNN分类器的最终表现。</li>
</ul>
<h2 id="进一步阅读"><a href="#进一步阅读" class="headerlink" title="进一步阅读"></a>进一步阅读</h2><p>这里有一些（可选）链接，您可能会发现更多有趣的东西：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf">关于机器学习的一些有用的事情</a>，其中特别是第6部分是相关的，但这整篇文章都是值得一读的。</li>
<li><a target="_blank" rel="noopener" href="http://people.csail.mit.edu/torralba/shortCourseRLOC/index.html">认可和学习对象类别</a>，ICCV 2005的短期课程对象分类。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/06/13/%E3%80%90%E7%BF%BB%E8%AF%91%E3%80%91%E8%A7%86%E8%A7%89%E4%BF%A1%E6%81%AF%E8%AE%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="DannyLee">
      <meta itemprop="description" content="愿你的努力终取得成果">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="圣巢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/06/13/%E3%80%90%E7%BF%BB%E8%AF%91%E3%80%91%E8%A7%86%E8%A7%89%E4%BF%A1%E6%81%AF%E8%AE%BA/" class="post-title-link" itemprop="url">【翻译】图解信息论</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-06-13 12:23:00" itemprop="dateCreated datePublished" datetime="2017-06-13T12:23:00+00:00">2017-06-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-10 17:00:48" itemprop="dateModified" datetime="2021-02-10T17:00:48+00:00">2021-02-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><a target="_blank" rel="noopener" href="http://colah.github.io/posts/2015-09-Visual-Information/">原文地址</a></li>
</ul>
<p>我很喜欢那种获得一种新的方式来思考我们的世界时的那种感觉。尤其是在一些模糊的想法变成一个具体的概念的时候。<strong>信息论</strong>就是这样一种把模糊的概念具象化的典型的例子。</p>
<p>信息理论为我们描述很多事情提供了准确的语言。关于某个问题我到底有多不确定？问题A的答案会告诉我们多少关于问题B的答案的信息？一组信息和另一组信息的相似度如何衡量？在我小的时候，我就已经形成了一些关于这些问题的模糊的想法，但是信息论将我的这些想法形成了精确的强大的理论。这些理论有着巨大的应用范围，例如数据压缩、量子物理学、机器学习以及其他更广泛的领域。</p>
<p>不过，信息论看起来似乎有些不容易理解，但我不认为信息论应该是这样难以理解的。事实上，信息论中许多核心理论都可以完全用图解的方式来解释！</p>
<h2 id="可视化概率分布"><a href="#可视化概率分布" class="headerlink" title="可视化概率分布"></a>可视化概率分布</h2><p>在我们深入信息理论之前，让我们考虑一下如何可视化简单的概率分布。</p>
<p>我住在加利福尼亚州。有些时候这里是下雨天，但大多数时间里这里都是晴天！我们假设有75%的时间是晴天。我们很容易就可以将这些信息可视化的展示出来：</p>
<p><img src="/img/17_06_13/001.png" width=100 height=100 /></p>
<p>大多数的时间，我都穿T恤衫，但在某些时间，我会穿外套。那么假设我38%的时间里是穿外套的。可视化这个信息也很容易：</p>
<p><img src="/img/17_06_13/002.png" width=100 height=100 /></p>
<p>如果我想将这两件事同时可视化该怎么做呢？如果这两件事情相互不影响（相互独立），那么这很容易做到。例如，我穿T恤或者外套与下一周的天气并不相关。我们可以通过两个轴分别表示两种不同的变量的方式来可视化这些信息：</p>
<p><img src="/img/17_06_13/003.png" width=300 height=300 /></p>
<p>请注意水平方向和竖直方向上穿过的直线。<em>这就是独立性的标识！</em>我穿外套的概率并不受那一周天气都是下雨天而改变。换句话说，在下周要下雨并且我恰好也穿外套的概率，是我穿外套的概率与下雨天的概率之积。它们互不影响。</p>
<p>当变量之间相互作用时，对于某组相互排斥的变量而言，他们组成的概率会减少；而某组相互促进影响的变量而言，他们组成的概率会增加。对于在下雨天我穿外套的这种情况，会有额外的概率增加，因为下雨天和外套这两个变量是相关的，它们使得彼此之间更有可能发生。在下雨天我穿外套的概率，比我在其他某天穿外套的概率高。</p>
<p>可视化之后，这些看起来有肿胀的部分是因为额外增加的概率导致的，而其他收缩的部分，是因为这一对事件不太可能同时出现。</p>
<p><img src="/img/17_06_13/004.png" width=300 height=300 /></p>
<p>这张图虽然这看起来很酷，但对于理解具体发生了什么并不是很有帮助。</p>
<p>相反，让我们焦点集中在其中的某一个变量上，例如天气。我们知道某天是晴天或者下雨天的可能性。对于是否穿外套的两种情况，我们可以看看<em>条件概率</em>。我在晴天穿外套的可能性有多大？如果是下雨天，那么我穿外套的可能性又是多大？</p>
<p><img src="/img/17_06_13/005.png" width=500 height=300 /></p>
<p>有25%的时间是下雨天。如果是下雨天，那么有75%的可能性我会穿外套。所以，我在下雨天穿外套的概率是25%乘以75%，结果大约是19%。下雨天的概率乘以我在下雨天的情况下穿外套的概率，就是在所有情况下，天气为下雨天并且我穿外套的概率。我们用这样的式子来描述：</p>
<script type="math/tex; mode=display">
p(\text{rain}, \text{coat}) = p(\text{rain}) \cdot p(\text{coat} ~|~ \text{rain})</script><p>这就是概率论的最基本的定理之一：</p>
<script type="math/tex; mode=display">
p(x,y) = p(x)\cdot p(y|x)</script><p>我们把一个整体的概率拆分成两部分来看。首先，我们来看其中一个变量的概率的值，例如不同天气的概率。然后我们观察另一个变量，例如我的穿衣情况，观察它在第一个变量的条件下的概率。</p>
<p>具体选择哪个变量开始，是任意的。我们可以以我的穿衣情况为第一个被观察的条件，这也许会有点不直观，因为我们知道穿衣情况是受到天气情况影响的，而天气情况并不会受到我的穿衣情况影响的…但其实这里两种方式的效果是一样有效的！</p>
<p>让我们来看一个例子。我已经知道穿外套的概率是38%。假设我已经知道我在某一天是穿外套的，那么这一天下雨的概率有多大呢？我在下雨天比在晴天穿外套的可能性更大，但在加州是很少下雨的，所以有50%的概率这一天是下雨天。因此，某天是雨天并且我穿了外套的概率就等于我穿外套的概率（38%）乘以我穿外套的情况下是下雨天的概率（50%），结果大约是19%。</p>
<script type="math/tex; mode=display">
p(\text{rain}, \text{coat}) = p(\text{coat}) \cdot p(\text{rain} ~|~ \text{coat})</script><p>这为我们提供了第二种来可视化这些概率分布的方法：</p>
<p><img src="/img/17_06_13/006.png" width=300 height=500 /></p>
<p>注意，这里的标签与之前图中稍有不同：T恤和外套现在是<em>边际概率</em>，我穿外套的概率是不需要考虑天气情况的。另一方面，现在有两个雨天和晴天的标签，分别来标识我穿T恤情况下的概率和我穿外套情况下的概率。</p>
<blockquote>
<p>你可能已经听说过<strong>贝叶斯定理</strong>。其实你也完全可以使用贝叶斯定理来解释这部分内容。</p>
</blockquote>
<h2 id="Aside：辛普森悖论"><a href="#Aside：辛普森悖论" class="headerlink" title="Aside：辛普森悖论"></a>Aside：辛普森悖论</h2><p>这些可视化概率分布的技巧真的很有用吗？我认为的确很有用！在我们图解信息论之前，我还需要一些时间来用可视化的技术探索一下辛普森悖论。辛普森悖论是一种非常不直观的统计状况。它真的很不容易被直观的理解。迈克尔·尼尔森（Michael Nielsen）撰写了一篇很有爱的文章：<a target="_blank" rel="noopener" href="http://michaelnielsen.org/reinventing_explanation/">“创新说明”</a>，探讨了不同方式来解释它。而我想尝试使用我们在上一节中学到的技巧来解释它。</p>
<p>测试两种肾结石治疗方法。对一半的患者使用A治疗方案，而另一半则使用B治疗方案。接受治疗方案B的患者比接受治疗方案A的患者更容易存活。</p>
<p><img src="/img/17_06_13/007.png" width=400 height=400 /></p>
<p>然而，如果接受治疗方案A的话，患肾小结石的患者更有可能存活。然而大肾结石患者如果接受治疗方案A也更有可能存活！这怎么可能呢？</p>
<p>这个问题的核心是因为患者样本没有被正确随机分组。接受治疗方案A的患者大部分可能患有大肾结石，而接受治疗方案B的患者大部分可能患有小肾结石。</p>
<p><img src="/img/17_06_13/008.png" width=400 height=400 /></p>
<p>事实证明，肾结石较小的患者通常更有可能生存。</p>
<p>为了更好地理解这一点，我们可以将前两个图表组合为一个三维图，其中将小型和大型肾结石的存活率分开展示。</p>
<p><img src="/img/17_06_13/009.png" width=400 height=400 /></p>
<p>我们现在可以看到，在两种小肾结石和大肾结石的病例中，治疗方案A是超过治疗方案B的。治疗方案B看起来似乎更好，仅仅是因为应用它的患者本身更有可能存活！</p>
<h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h2><p>现在我们有了可视化概率的方法，我们可以深入到信息论中了。</p>
<p>首先我向你介绍一位我假想的朋友，Bob。Bob很喜欢动物。他一直不停在谈论动物。事实上，他只会说四个字：“dog”, “cat”, “fish” 和 “bird”。</p>
<p>几周前（虽然这只是我的想象)Bob搬到了澳大利亚。另外，他决定只想要使用二进制来交流。来自Bob的所有（虚构的）消息都是这样的：</p>
<p><img src="/img/17_06_13/010.png" width=300 height=100 /></p>
<p>为了沟通，Bob和我必须建立一个编码，一种将单词映射成位序列的方式。</p>
<p><img src="/img/17_06_13/011.png" width=300 height=300 /></p>
<p>要发送消息，Bob用相应的编码字来替换每个单词，然后将它们连接在一起形成编码的字符串。</p>
<p><img src="/img/17_06_13/012.png" width=300 height=150 /></p>
<h3 id="可变长度码"><a href="#可变长度码" class="headerlink" title="可变长度码"></a>可变长度码</h3><p>不幸的是，在假想中的澳大利亚，通信服务是昂贵的。从Bob收到的每条消息中，每一位（bit）数据我都必须支付5美元。我是不是还没有提到Bob喜欢说很多话这件事？为了防止我破产，Bob和我决定来研究一些可以使我们的平均消息长度变得更短的方法。</p>
<p>事实证明，并不是所有的词Bob都会经常说。Bob很喜欢狗，他一直在说“dog”。同时他也会不定期地说其他的动物，尤其是他的狗喜欢追的猫，但它大多数时间他还是在说“dog”。这是一个他的单词频率图：</p>
<p><img src="/img/17_06_13/013.png" width=300 height=200 /></p>
<p>这似乎看来是有优化空间的。因为我们可以看到，按照旧的编码方式，对于不同的词无论它们是多么常见，都在使用2位长的码字来表示。</p>
<p>我们可以用下面这张图来可视化这些信息。在下面这张图中，我们使用竖直方向的坐标轴来表示每个词的概率$p(x)$，水平方向的坐标轴来表示相应的码字的长度$L(x)$。可以看到在这种情况下平均码字是2位。</p>
<p><img src="/img/17_06_13/014.png" width=500 height=300 /></p>
<p>也许我们可以用一种非常聪明的方式来制作一种可变长度的编码方式，使得其中常用单词对应的码字特别短。这样做的挑战就是码字之间是存在竞争关系的，我们需要让一部分词对应的码字变短，而另一部分则会变长。为了最大限度地减少消息长度，我们希望理想状态下所有的码字都很短，尤其是那些常用的词我们更希望它们能变短。因此，最终得到的编码对于常用词（例如“dog”）具有较短的码字，并且较长的码字被应用到了不常用的词之上（例如“bird”）。</p>
<p><img src="/img/17_06_13/015.png" width=300 height=300 /></p>
<p>让我们再次可视化这些信息。注意那些最常用的词变短了，那些不常用的词变长了。经过这样处理之后，对于传递与之前相同的信息，我们的流量开销的确变少了。平均来说，码字长度现在是1.75位！</p>
<p><img src="/img/17_06_13/016.png" width=500 height=300 /></p>
<blockquote>
<p>你也许会好奇：为什么不用1来作为码字？因为可惜的是，如果我们这么做，当我们对编码的字符串进行解码时，会引起歧义。我们稍后会介绍这些内容。</p>
</blockquote>
<p>事实证明，这种编码方式是最好的。对于这个分配问题，没有其他的编码方式能带来平均码字长度小于1.75位的效果了。</p>
<p>这是一个简单的基本限制。这要求我们传达的信息平均码字长度至少是1.75位。无论我们用多么聪明的代码，都不可能让平均消息长度变得更短。我们称这种限制为<strong>熵</strong>。关于熵的内容，我们将在稍后详细讨论。</p>
<p><img src="/img/17_06_13/017.png" width=500 height=300 /></p>
<p>如果我们想了解这个平均最短码字长度的限制，这个问题的关键在于理解如何在使得一些码字变短但同时其他码字变长的过程中进行权衡。一旦我们弄明白了如何进行这种权衡，我们就能够找出最好的编码方式了。</p>
<h3 id="码字的空间"><a href="#码字的空间" class="headerlink" title="码字的空间"></a>码字的空间</h3><p>码字长度为1时，能表示2种编码：0和1的编码；码字长度为2时，能表示4中编码：00，01，10和11。下面是每增加一位码字长度，能表示的编码种类数量的递增情况：</p>
<p><img src="/img/17_06_13/018.png" width=350 height=300 /></p>
<p>但我们感兴趣的是那些可变长度编码。一种比较简单的情况是有八个长度为3位的码字。我们也可能有一些比较复杂的组合，比如长度为2的两个码字，与长度为3的四个码字的组合。那么究竟是什么决定了我们可以有不同长度的码字呢？</p>
<p>回想一下，Bob通过用它的码字替换每个单词并将它们连接在一起，将他的消息转换成编码的字符串。</p>
<p><img src="/img/17_06_13/019.png" width=300 height=200 /></p>
<p>当制作可变长度代码时，需要注意一个微妙的问题。我们如何将编码过的字符串分割回码字呢？当所有的码字长度相同时，这很简单。我们只需将这个字符串按照固定的码字长度分割成不同的码字即可。但是由于存在不同长度的码字，所以我们需要关注编码过的字符串的内容。</p>
<p>我们希望只有一种方式来解码编码过的字符串。我们不希望我们的编码方式在解码过程中变得含糊不清。如果我们有一些特殊的“码字结束”符号，这个问题这就会变得很容易。但其实我们没有这种符号，我们只能够发送0和1。因此，我们需要能够查看一系列连续的码字，并且说明每个码字应该停止的位置。</p>
<p>而这，很可能出现编码不能被唯一解码的情况。例如，假设0和01都是码字，那么我们就会搞不清楚符串0100111的第一个码字到底是什么。因为这个字符串的第一个码字既可以是0也可以是01！因此，我们想要的效果是没有哪个码字是另一个码字的前缀。这称为<strong>前缀属性</strong>，遵守它的编码称为<strong>前缀编码</strong>。</p>
<p>思考这个问题的一个好的方法是每个码字需要从可能的码字的空间中做出牺牲。如果我们取代码字01，那么我们就失去了使用任何以01前缀开头的码字的能力。我们不能使用010或011010110，因为会产生歧义。</p>
<p><img src="/img/17_06_13/020.png" width=400 height=400 /></p>
<p>由于所有码字中，有$\frac{1}{1}$都是从01开始，所以我们牺牲了$\frac{1}{1}$的所有可能的码字。这是我们付出的代价，而换来的结果只是使得其中一个码字的长度缩短到2位长！反过来，这种牺牲意味着所有其他码字需要更长一些。在不同码字的长度之间总是有这种折衷。为获取一个比较短的码字，需要你牺牲更多的其他码字的空间。而我们需要弄清楚，正确的权衡方式是什么？</p>
<h3 id="最佳编码"><a href="#最佳编码" class="headerlink" title="最佳编码"></a>最佳编码</h3><p>可以理解为简短编码的长度是有一个限定的度量在里面，每减短一个bit的密文就会牺牲一些编码的可能性从而让其它密文的长度增长。 </p>
<p>购买长度为0的码字的成本为1，会牺牲掉所有的码字空间，如果这样做，就不会有其他码字了。长度为1的码字（如“0”）的代价是$\frac{1}{2}$的码字空间，因为有一半的码字以“0”开始的。长度为2的码字的成本(例如“01”)是$\frac{1}{4}$码字空间，因为有$\frac{1}{4}$的码字以“01”开始的。一般来说，码字的代价随代码字的长度而呈指数减小。</p>
<p><img src="/img/17_06_13/021.png" width=600 height=300 /></p>
<p>如果代价是以指数衰减，那么这个高度和面积也是成指数衰减。</p>
<p>我们想要通过得到比较短的码字来缩短平均消息长度。每个码字的期望长度是每个码字出现的概率乘以码字的长度。假设我们有一个4bit的密文，出现概率是50%，那么我们的期望就是4*50%=2bit。我们可以作图来表示。</p>
<p><img src="/img/17_06_13/022.png" width=300 height=300 /></p>
<p>这两个值（代价和期望长度）与码字的长度相关。信息的长度决定了码字的平均长度。我们可以把这两者画在一起，就像这样。</p>
<p><img src="/img/17_06_13/023.png" width=600 height=300 /></p>
<p>短码字减少了平均消息长度，但是越短的码字越昂贵，而长码字增加了平均消息长度，但长码字相对便宜。</p>
<p><img src="/img/17_06_13/024.png" width=600 height=300 /></p>
<p>使用有限预算的最佳方法是什么？我们应该在每个事件的码字上投入多少花费呢？</p>
<p>就像一个人想要把较多的钱投入在经常定期使用的工具上一样，我们更愿意对那些频繁使用的码字支付更高的花费。有一种特别顺其自然的处理方式：按照事件的普遍程度分配我们的预算。如果一个事件发生的概率是50％，那么我们就花费预算的50％来购买这个短的码字。但是，如果一个事件的发生概率只有1％，那么我们就只花1％的预算，因为我们并不是很在意这个不常见的码字变得很长。</p>
<p>这是一件很顺其自然的解决方案，但它是最优解吗？没错，它是，我接下来会证明它！</p>
<p><em>以下是可视化的证明过程，应该是可以理解的，但理解起来有一定难度，而这部分绝对是这篇文章中最难的部分。读者应该自由地选择是否默认接受这一结论跳过这一部分。</em></p>
<p>我们来看一个具体的例子，我们需要比较两个可能发生的事件。事件a发生的概率是$p(a)$，事件b发生的概率是$p(b)$。我们按照上述自然的方式分配预算，花费$p(a)$的预算在a获得一个较短的码字上，花费$p(b)$的预算在b获得较短的码字上。</p>
<p><img src="/img/17_06_13/025.png" width=600 height=300 /></p>
<p>花费的成本和对应的长度贡献的边界完美的对齐了，这是否意味着什么？</p>
<p>那么，请考虑一个问题，如果我们稍微改变码字的长度，会对花费的成本和码字长度贡献值有什么样的影响呢？如果我们稍微增加码字的长度，则消息长度的贡献值将与其边界的高度成比例地增加，而成本则会与边界的高度成正比。</p>
<p><img src="/img/17_06_13/026.png" width=600 height=300 /></p>
<p>所以，使码字a缩短的代价的值是$p(a)$。同时，我们不关心每个码字的具体长度，我们关心的是使用它们的占比。在a这种情况下，占比就是$p(a)$。对我们来说，就是$p(a)$使码字a的长度变得更短一些。</p>
<p>然而有趣的是，这两者的导数都是一样的。这意味着我们的初始预算有一个有趣的属性，如果你花费了一些用于缩短码字的投入，那么这个投入对于投在任何码字上，效果都是一样的。我们真正关心的是最终的利益/成本比例 - 这就决定了我们应该投资多少。在这种情况下，这个比例是$\frac{p(a)}{p(a)}$等于1。这与$p(a)$的值无关，因为这个结果总是1。我们也可以将相同的参数应用于其他事件。利益/成本总是一，所以在其中任何一方投资更多是平等的。</p>
<p><img src="/img/17_06_13/027.png" width=600 height=300 /></p>
<p>无论如何，改变预算是没有意义的。但这不证明这是最好的预算。为了证明这一点，我们会考虑使用一个不同的预算。我们将在$b$中投资$ε$，并在$a$中投资相反的花费。这使得a的码字稍短一些，而b的码字稍长一些。</p>
<p>现在为a购买一个较短的码字的成本是$p(a)+ε$，为b购买较短码字的费用b是$p(b)-ε$。但收益还是一样的。这导致了购买$a$的收益成本比例为一个小于1的值：$\frac{p(a)}{p(a) + ε}$。而另一边，对于购买$b$的收益成本比例是一个大于1的值：$\frac{p(b)}{p(b) - ε}$</p>
<p><img src="/img/17_06_13/028.png" width=600 height=300 /></p>
<p>价格不再保持平衡。b相对于a来说是一笔更好的交易。投资者们尖叫道：“买b！卖a！”我们通过这样做，结束了我们原来的预算计划。所有预算都可以通过转向原始预算的方式来得到改进。</p>
<p>原始预算 - 按照我们使用频率的比例投入每个码字 - 这不仅仅是自然而然的事情，而且这是最好的方法。（虽然这个证明仅适用于两个码字，但它很容易泛化为更多的情况。）</p>
<blockquote>
<p>认真的读者可能已经注意到，我们的最优预算有可能提出码字具有分数长度的编码，这似乎很有用！这是意味着什么呢？当然，在实践中，如果你想通过发送一个单码字，你必须取整，但是我们稍后会看到，当我们一次发送很多码字时，可以发送分数码字！现在请你耐心的看我现在的讲解！</p>
</blockquote>
<h3 id="计算熵"><a href="#计算熵" class="headerlink" title="计算熵"></a>计算熵</h3><p>回想一下，一个长度为$L$的消息代价是$\frac{1}{2^L}$。再做一个简单的变换后，这个信息的长度就是：$\log_2\left(\frac{1}{\text{cost}}\right)$。因为我们对每个码字$x$花费$p(x)$的成本，长度是$\log_2\left(\frac{1}{p(x)}\right)$。这是长度的最佳选择。</p>
<p><img src="/img/17_06_13/029.png" width=600 height=300 /></p>
<p>早些时候，我们讨论了如何从一个特定的概率分布$p$中获取平均消息来传达事件的基本限制。这个将平均消息长度缩短到最优的编码的限制，我们称之为$p$的熵，$H(p)$。现在我们知道了码字的最佳长度，而且我们可以精确的计算出来！</p>
<script type="math/tex; mode=display">
H(p) = \sum_x p(x)\log_2\left(\frac{1}{p(x)}\right)</script><blockquote>
<p>人们通常将熵写作$H(p) = - \sum p(x)\log_2(p(x))$这种形式，因为$\log(1/a) = -\log(a)$。但我认为第一种写法更直观，并且我在这篇文章的后续部分会继续使用这种形式。</p>
</blockquote>
<p>无论我做什么，平均来说，如果我想要进行通信交流，信息平均长度最少都是这个值。</p>
<p>这个需要发送的信息的平均长度对信息的压缩有明显的影响，这个熵还有其它方面的意义吗？当然！它描述了随机性，并且提供了一种量化信息的方式。</p>
<p>如果我确实知道会发生什么事件，我根本就不必发消息！如果有两件可能发生的概率为50％，我只需要发送1bit的数据。如果有64个不同的事情可能以相等的概率发生，我必须发送6bit。发生的概率越集中在某一件事上，就越能用巧妙的编码方式来减少信息的平均长度。概率扩散的范围越大，信息越长。发生的概率越分散到不同事情上，我需要发送的信息平均长度就越长。</p>
<p>结果越不明确，在发生事情时就能学到越多的东西。</p>
<h2 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h2><p>在Bob搬到澳大利亚不久之后，他和我假想的另一个女孩Alice结婚了(让我惊讶的是，我脑海里居然还有其他角色)。然而Alice并不是一个狗狗爱好者。她是一个猫猫爱好者。尽管如此，他们俩也可以在仅有非常有限的关于动物的词汇的情况下，找到共同话题。</p>
<p><img src="/img/17_06_13/030.png" width=300 height=300 /></p>
<p>他们两以不同的频率说着相同的话。Bob总是谈论狗，而Alice却总是谈论猫。</p>
<p>最初，Alice使用Bob的编码向我发送消息。不幸的是，她的消息比他们实际需要的要长。Bob的编码是按照Bob的概率分布优化得到的。而Alice与Bob有不同的信息概率分布，并且Bob编码对她来说并不是最佳的。当Bob使用自己的编码时，码字的平均长度是1.75，但Alice在使用这组编码时，她的码字平均长度是2.25。如果他们两的概率密度越不相似，这个结果就越糟糕。</p>
<p>这种根据一边信息概率分布优化过的编码方式来传输另一种概率分布不同的信息时，消息的平均长度称为交叉熵。关于交叉熵，更正式的定义如下：</p>
<script type="math/tex; mode=display">
H_p(q) = \sum_x q(x)\log_2\left(\frac{1}{p(x)}\right)</script><p>在这种情况下，Alice的猫爱好者的词频与Bob的狗爱好者词频存在交叉熵。</p>
<p><img src="/img/17_06_13/031.png" width=300 height=300 /></p>
<p>为了让我们的通信的花费减少，我让Alice来使用她自己的编码。让我感到安慰的是，这使得她的平均消息长度变短了。但是，这也引入了一个新的问题：有时Bob会不小心使用Alice的编码。令人惊讶的是，Bob使用Alice的编码时，Bob信息的平均长度比Alice用Bob编码时的最优方式还长</p>
<p>所以，现在我们有四种可能的情况：</p>
<ul>
<li>Bob使用它自己的编码$(H(p) = 1.75 ~\text{bits})$</li>
<li>Alice使用Bob的编码$(H_p(q) = 2.25 ~\text{bits})$</li>
<li>Alice使用她自己的编码$(H(q) = 1.75 ~\text{bits})$</li>
<li>Bob使用Alice的编码$(H_q(p) = 2.375 ~\text{bits})$</li>
</ul>
<p>这并不能直观的展示出这种值之间的关联关系。我们可以使用下图来寻找它们之间的关系。</p>
<p>在下图中，每个子图分别表示这四种情况之一。每个子图以与之前相同的方式来显示平均消息长度。处于同一行的两种情况有相同的概率分布，处于同一列的两种情况有相同的编码方式。通过这种方式，可以可视化的观测到概率分布和编码方式的关系。</p>
<p><img src="/img/17_06_13/032.png" width=500 height=500 /></p>
<p>你能看出来为什么$H_p(q) \neq H_q(p)$吗？$H_q(p)$比较大因为在概率分布$p$之下有一个非常常见的码字比较长的事件（蓝色），因为这个事件在概率分布$q$的情况下并不常见。然而，另一边，在$q$的情况下比较常见的事件，在$p$的情况下比较少见，但差异较小，所以$H_p(q)$不是很高。</p>
<p>因此我们发现交叉熵是不对称的。</p>
<p>那么，为什么要关心交叉熵呢？交叉熵给我们一种表达两种概率分布不同的方法。概率分布$p$和$q$的差异越大，那么$p$关于$q$的交叉熵就比$p$的熵越大。</p>
<p><img src="/img/17_06_13/033.png" width=300 height=300 /></p>
<p>同样的，概率分布$p$和$q$差异越大，$q$关于$p$的交叉熵就比$q$本身的熵越大。</p>
<p><img src="/img/17_06_13/034.png" width=300 height=300 /></p>
<p>真正有趣的东西是熵与交叉熵之间的差异。差异在于我们的信息具体长多少，因为我们对不同的概率分布使用了同一套优化过的编码方式。如果概率分布相同，那么这个差异将为零。随着差异的增长，这个差值将变得更大。</p>
<p>我们称这种差异为Kullback-Leibler分歧，或者简称为KL分歧。概率分布$p$关于$q$的KL分歧$D_q(p)$定义如下：</p>
<script type="math/tex; mode=display">
D_q(p) = H_q(p) - H(p)</script><p>关于KL分歧真正在做的事情，其实就像是在衡量不同概率分布之间的差异程度。（如果继续研究这个概念就会进入信息几何的领域。）</p>
<p>交叉熵和KL分歧在机器学习中有着难以置信的用处。通常，我们希望一个分布与另一个分布相互靠近。例如，我们希望一个用于预测的概率分布与真实情况更接近。KL分歧为我们提供了一种很自然的方式来做到这一点，所以它在任何地方都有用武之地。</p>
<h2 id="熵和多变量"><a href="#熵和多变量" class="headerlink" title="熵和多变量"></a>熵和多变量</h2><p>让我回到之前关于天气和穿着的例子：</p>
<p><img src="/img/17_06_13/035.png" width=300 height=300 /></p>
<p>我的妈妈，就像大多数的家长一样，都会担心我的衣着跟天气不搭配。（她的这种担心不是没有道理的，因为我在冬天经常不穿外套。）所以她总是想要知道我这边有关天气和穿衣的信息。我需要发送几个bit的数据来传达这些信息呢？</p>
<p>为了更方便的分析这个问题，我们把概率扁平化分析：</p>
<p><img src="/img/17_06_13/036.png" width=600 height=300 /></p>
<p>现在我们可以找出这些概率的事件的最优码字，并计算平均消息长度：</p>
<p><img src="/img/17_06_13/037.png" width=600 height=300 /></p>
<p>我们把这个称之为$X$和$Y$的联合熵，定义如下：</p>
<script type="math/tex; mode=display">
H(X,Y) = \sum_{x,y} p(x,y) \log_2\left(\frac{1}{p(x,y)}\right)</script><p>这与我们关于熵的正规定义完全相同，唯一的区别就是这里有两个变量，而之前是一个。</p>
<p>我们再把这个图形表现得更形象话一些，加入码字长度作为第三个维度，让图形更立体。现在，熵的大小就是体积的大小。</p>
<p><img src="/img/17_06_13/038.png" width=300 height=600 /></p>
<p>假设我的妈妈已经知道了天气信息（她可以通过新闻知道这些信息）。那么现在我需要提供多少的信息量呢？</p>
<p>似乎我需要发送很多信息来传达我的穿衣情况。但实际情况，我发送的信息比之前要少，因为天气与我的衣着有着密切的联系！我们来分别思考关于下雨天和晴天下的两种情况。</p>
<p><img src="/img/17_06_13/039.png" width=400 height=400 /></p>
<p>在这两种情况下，平均来看，我不需要发送特别多的信息，因为天气信息对我的穿衣情况有着很好的预示。当阳光明媚的晴天，我可以使用一个特定的“晴天优化版”编码，对于下雨天，我可以使用一个特定的“雨天优化版”编码。分别在这两种情况下用不同的编码会比用同一种通用编码的长度少很多。为了得到我需要发送给我妈妈的平均信息量，我把这两个例子放在一起…</p>
<p><img src="/img/17_06_13/040.png" width=200 height=300 /></p>
<p>我们称之为条件熵。可以把它写成如下的数学表达式：</p>
<script type="math/tex; mode=display">
H(X|Y) = \sum_y p(y) \sum_x p(x|y) \log_2\left(\frac{1}{p(x|y)}\right)</script><script type="math/tex; mode=display">
~~~~ = \sum_{x,y} p(x,y) \log_2\left(\frac{1}{p(x|y)}\right)</script><h2 id="交互信息"><a href="#交互信息" class="headerlink" title="交互信息"></a>交互信息</h2><p>在上一节，我们得到一个结论，那就是在知道一个变量的情况下，可能会意味着导致传达另一个变量需要更少的信息。</p>
<p>一种思考这种情况的很好方式是将信息的总量想象成一个条。如果不同的消息之间在共享信息，就叠加显示。例如，$X$和$Y$存在一部分共享信息，因此$H(X)$和$H(Y)$是有重叠部分。并且$H(X,Y)$是两者的共同信息，是$H(X)$和$H(Y)$的集合。</p>
<p><img src="/img/17_06_13/041.png" width=300 height=200 /></p>
<p>一旦我们开始以这种方式思考事情，很多事情就变得简单了。</p>
<p>例如，我们之前注意到同时传递$X$和$Y$（“联合熵”$H(X,Y)$）比仅仅使用$X$来通信（“边际熵”$H(X)$）需要更多的信息。如果你已经知道了$Y$，那么它会用更少的信息来对$X$进行通信（“条件熵”$H(X|Y)$）。</p>
<p><img src="/img/17_06_13/042.png" width=500 height=400 /></p>
<p>这听起来有点复杂，但从条状显示图来看，就很简单了。$H(X|Y)$是指我们在向已经知道$Y$的信息的人在传达$X$的信息时的熵，蕴含在$X$中的信息并不包含在$Y$中。从视觉上来看，这意味着$H(X|Y)$是$H(X)$的条中，不与$H(Y)$重叠的那一部分。</p>
<p>你可以从下图中得出这个不等式:$H(X,Y) \geq H(X) \geq H(X|Y)$。</p>
<p><img src="/img/17_06_13/043.png" width=300 height=200 /></p>
<p>另一个特性：$H(X,Y) = H(Y) + H(X|Y)$。也就是说$X$和$Y$的信息也就是$Y$的信息加上不在$Y$中的$X$的信息。</p>
<p><img src="/img/17_06_13/044.png" width=500 height=400 /></p>
<p>从方程中很难看出这些信息，但如果你将这些信息用条状图显示出来，就变得容易了。</p>
<p>在这里，我们以多种方式组织了$X$和$Y$的信息。我们有每个变量所包含的信息$H(X)$和$H(Y)$。我们有着两种信息的交集$H(X,Y)$。我们有只存在与一个变量但不存在与另一个变量的信息$H(X|Y)$和$H(Y|X)$。还有很多这些围绕着变量之间共享的信息，即他们之间信息的交集。我们称之为“相互信息”$I(X,Y)$，定义如下：</p>
<script type="math/tex; mode=display">
I(X,Y) = H(X) + H(Y) - H(X,Y)</script><p>这个定义是有效的，因为$H(X) + H(Y)$存在有两个相互信息的副本，因为他们同时蕴含在$X$中以及$Y$中，而$H(X,Y)$只有一份。(想想上一个条形图。)</p>
<p>与信息密切相关的是信息的变化。信息的变化是变量之间不共享的信息。我们可以这样定义它：</p>
<script type="math/tex; mode=display">
V(X,Y) = H(X,Y) - I(X,Y)</script><p>信息的变化很有趣，因为它给了我们一个不同变量之间度量距离的概念。两个变量如果知道一个值的值可以得出另一个变量的值，那么这两者之间的信息变化是零，并且这个信息变化的值随着他们彼此之间变得更加独立而增加。</p>
<p>这和同样可以告诉我们距离信息的KL分歧之间的关系是什么呢？KL分歧给了我们两个分布之间在同一个变量或一组变量上的距离。相反，信息的变化给我们两个相同分布的变量之间的距离。KL分歧是应用在不同信息的概率分布中的，标识这概率分布中的信息变化。</p>
<p>我们可以将所有这些信息全部汇集成一个单独的图表：</p>
<p><img src="/img/17_06_13/045.png" width=400 height=400 /></p>
<h2 id="分数形式的位"><a href="#分数形式的位" class="headerlink" title="分数形式的位"></a>分数形式的位</h2><p>关于信息理论的一个非常不直观的事情是我们可以拥有小数位数。这看起来很奇怪，半个位(0.5bit)意味着什么？</p>
<p>有一种简单的答案：通常，我们对消息的平均长度感兴趣，而不是任何特定的消息长度。如果一半的时间发送一个位的长度，一半时间发送两个位的长度，那么平均发送的长度是1.5位。对于平均数是小数的情况并没有什么奇怪的。</p>
<p>但是，这个答案其实是在避开这个问题。通常，码字的最佳长度都是分数形式。这意味着什么呢？</p>
<p>具体来说，让我们考虑一个概率分布，其中事件$a$发生的概率是$71%$，另一个事件$b$发生的概率为$29%$。</p>
<p><img src="/img/17_06_13/046.png" width=300 height=300 /></p>
<p>最佳编码将使用0.5位来表示$a$，用1.7位来表示$b$。那么，如果我们要发送这些码字中的任何一个，都是不可能的。我们会强制被安排发送整数位数的信息，并且发送的平均消息长度是1位。</p>
<p>但是，如果我们一次性发送多条消息，我们可以处理的更好。让我们来考虑按照这种概率分布的情况下来同时传递两个事件。如果我们每次只发送一个事件，那么我们需要发送两位的长度。我们可以处理的更好吗？</p>
<p><img src="/img/17_06_13/047.png" width=300 height=300 /></p>
<p>有一半的概率，我们需要传递$aa$的信息，有21%的概率我们需要发送$ab$或者$ba$，而我们传递$bb$的概率只有8%。我们再一次把编码优化到理想的小数位数的形式。</p>
<p><img src="/img/17_06_13/048.png" width=500 height=300 /></p>
<p>如果我们对码字长度取整，我们将得到这样的结果：</p>
<p><img src="/img/17_06_13/049.png" width=500 height=300 /></p>
<p>这个编码给我们带来的平均消息长度为1.8位。这比我们每次分别只传递一个事件的平均消息长度2位要小。另一种思考这个问题的方式是我们平均每个事件发送的信息是0.9位。如果我们一次发送更多的事件，那么这个值会更小。由于$n$趋向于无穷大，取整造成的损失将逐渐减少，并且每个码字的位数将接近熵。</p>
<p>另外，请注意，$a$的理想码字为0.5位，$aa$的理想码字是1位。即使理想码字的长度是小数，它们的长度也在增加！所以，如果我们一次传达很多事件时，长度会增加。</p>
<p>即使在实际的编码中，只能使用整数长度的码字，这里也有使用小数位数码字的实际的意义。</p>
<blockquote>
<p>在实践中，人们使用在不同程度上有效的特定编码方案。<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Huffman_coding">霍夫曼编码</a>，是一种基本类似于我们在这里草拟的这种编码，并没有非常优雅地处理小数位。你必须像上面那样对符号进行分组，或者使用更复杂的技巧来处理熵限制。<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Arithmetic_coding">算术编码</a>有点不同，它优雅地处理了小数位以渐近最优。</p>
</blockquote>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>如果我们关心如何使用最少数量数据进行通信，那么这些想法显然是最基本的。如果我们关心压缩数据，信息理论将可以解决数据压缩的核心问题，并给出我们从根本上正确的抽象。但是，如果我们不在乎这些问题，那么除了好奇，我们还有其他什么原因呢？</p>
<p>来自信息理论的观点在很多情况下都会出现：机器学习，量子物理学，遗传学，热力学，甚至赌博。这些领域的从业者通常不关心信息理论。量子纠缠可以用熵来描述，通过假定关于你不知道的事物的最大熵，可以得出统计力学和热力学中的许多结果。赌徒的胜利或损失与KL分歧直接相关，特别是迭代设置。</p>
<p>信息理论在所有这些地方出现，因为它为许多我们需要表达的事情提供了具体的，有原则的形式化表示。它给了我们衡量和表达不确定性的方法，两组数据有多么的不同，不同概率分布之间的距离是多少，以及但对于某个问题的答案中蕴含了多少其他问题的信息：扩散概率是怎样的，概率分布之间的距离以及相互依赖的两个变量是怎样的。有其他类似的理论或者观点吗？当然。但是信息论的思想是干净的，它们具有很好的性质和原则性的起源。在某些情况下，它们正是你所关心的，而在其他情况下，它是混乱世界中的一个方便的代理。</p>
<p>机器学习是我最了解的领域，所以我们来谈一下。在机器学习中，分类是一种非常常见的问题。假设我们想看一张图片，并预测它是一只狗还是一只猫。我们的模型可能会告诉我们“这张图片中有80%的概率是一只狗，有20%的概率是一只猫”。那么我们就说正确答案是狗，那么我们以80%的概率做出的判断是好还是坏呢？以85%的概率做出的判断会比80%好多少呢？</p>
<p>这是一个重要的问题，因为我们需要一些衡量我们模型好坏的概念，以便把它优化的更好。我们应该优化什么呢？正确的答案确实取决于我们使用的模型：我们是只关心最顶部的猜测是否正确呢，还是关心我们在获取正确答案中的信心呢？错误的自信会有多糟？没有一个正确的答案。而且通常不可能知道正确的答案，因为我们不知道如何以精确的方式使用模型来形式化我们最终关心的内容。然而很多问题中，交叉熵都是我们真正需要在意的，但并不总是如此。更常见的情况是我们并不知道我们关心什么，而交叉熵就是解决这些问题的一个很好的工具。</p>
<p>信息为我们提供了一个强大的新框架来思考我们的世界。有时它能完美的解决一些问题，而有时并不可以，但它依然很有用。这篇文章仅仅是对信息论的一个概览，而信息论中还有许多其他主要的概念，例如我们没有提到的纠错码，但我希望我已经展示出了信息论是一个很美丽的主题，它并不是那么高不可攀。</p>
<h2 id="进一步阅读"><a href="#进一步阅读" class="headerlink" title="进一步阅读"></a>进一步阅读</h2><p>这里是<strong>克劳德·香农（Claude Shannon）</strong>关于信息论的原创论文<a target="_blank" rel="noopener" href="http://worrydream.com/refs/Shannon%20-%20A%20Mathematical%20Theory%20of%20Communication.pdf">通信数学理论</a>。（这在早期的信息论论文中，似乎是一个重复的模式。是时代原因吗？还是因为缺少页面限制？或者是来自贝尔实验室的文化？）</p>
<p>封面和托马斯的信息要素理论似乎是标准参考。我觉得很有帮助。</p>
<h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><p>我非常感谢<a target="_blank" rel="noopener" href="https://github.com/danmane">Dan Mané</a>，<a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~dga/">David Andersen</a>，<a target="_blank" rel="noopener" href="http://obsessionwithregression.blogspot.com/">Emma Pierson</a>和Dario Amodei抽出时间来给出这篇文章令人难以置信的详细和广泛征求意见。我也很感激<a target="_blank" rel="noopener" href="http://michaelnielsen.org/">Michael Nielsen</a>，<a target="_blank" rel="noopener" href="http://research.google.com/pubs/GregCorrado.html">Greg Corrado</a>，<a target="_blank" rel="noopener" href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html">Yoshua Bengio</a>，<a target="_blank" rel="noopener" href="https://aaroncourville.wordpress.com/">Aaron Courville</a>，<a target="_blank" rel="noopener" href="http://www.nickbeckstead.com/">Nick Beckstead</a>，<a target="_blank" rel="noopener" href="http://research.google.com/pubs/JonathonShlens.html">Jon Shlens</a>，Andrew Dai，<a target="_blank" rel="noopener" href="http://research.google.com/pubs/ChristianHoward.html">Christian Howard</a>和<a target="_blank" rel="noopener" href="http://www.bewitched.com/">Martin Wattenberg</a>的评论。</p>
<p>还感谢我的前两个神经网络研讨会系列作为这些想法的豚鼠。</p>
<p>最后，感谢读者发现错误和遗漏。尤其感谢Connor Zwick，Kai Arulkumaran，Jonathan Heusser，Otavio Good，以及匿名评论者。</p>
<h2 id="更多的文章"><a href="#更多的文章" class="headerlink" title="更多的文章"></a>更多的文章</h2><p><a target="_blank" rel="noopener" href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/">了解卷积</a></p>
<p><a target="_blank" rel="noopener" href="http://colah.github.io/posts/2014-12-Groups-Convolution/">分组和分组卷积</a></p>
<p><a target="_blank" rel="noopener" href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/">神经网络，歧管和拓扑</a></p>
<p><a target="_blank" rel="noopener" href="http://colah.github.io/posts/2015-01-Visualizing-Representations/">可视化展示深度学习和人类</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/06/05/%E6%96%AF%E5%9D%A6%E7%A6%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="DannyLee">
      <meta itemprop="description" content="愿你的努力终取得成果">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="圣巢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/06/05/%E6%96%AF%E5%9D%A6%E7%A6%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E6%B1%87%E6%80%BB/" class="post-title-link" itemprop="url">斯坦福机器学习课程汇总</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-06-05 23:37:00" itemprop="dateCreated datePublished" datetime="2017-06-05T23:37:00+00:00">2017-06-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-02-10 17:00:48" itemprop="dateModified" datetime="2021-02-10T17:00:48+00:00">2021-02-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>首先感谢<strong>吴恩达</strong>建立<a target="_blank" rel="noopener" href="https://www.coursera.org">Coursera</a>这样一个优秀的在线学习平台，以及他发布在这个平台上的<a target="_blank" rel="noopener" href="https://www.coursera.org/learn/machine-learning/">机器学习</a>课程。</p>
<p>这门课程将整个机器学习领域的基础知识，用浅显易懂的方式，深入浅出的进行了介绍。使得一个拥有高中数学知识的学生也能听得明白。</p>
<p>如果你想要涉足机器学习、人工智能领域，或者对这一领域有浓厚的兴趣想要深入了解，那么你会发现很多机器学习入门课程推荐的资料中，都有吴恩达老师的这一系列课程。甚至在大多数资料中，都把这门课放在了首选的位置上。</p>
<p>因此，我把吴恩达老师的课程整理成了MarkDown的格式，方便查阅学习。以下是具体章节的目录，其中每篇文章都有对应的视频连接地址：</p>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li>第一周<ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSC1bwH">欢迎来到机器学习</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSC1Ju5">监督学习</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSC1XxR">无监督学习</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSC1onR">一元线性回归</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSC1N6G">参数学习-梯度下降算法</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSC1WEE">线性代数复习</a></li>
</ul>
</li>
<li>第二周<ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSC1T2O">编程环境设置-Octave:MATLAB</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSC1RnN">多元线性回归分析</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSC1nj4">参数的计算分析</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSC1BP3">Octave/Matlab 使用说明</a></li>
</ul>
</li>
<li>第三周<ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSC1epl">分类和表达式</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBwf7">分类</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCB4bV">假设函数表达式</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBhNP">决策边界</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBccU">Logistic回归模型</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBMeK">逻辑回归的代价函数</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBogn">简化代价函数以及梯度下降</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBpkr">高级优化</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBWU1">多类别分类问题：一对多</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBjW6">正则化：解决过拟合问题</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBT6v">解决过拟合问题</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCB8Vt">代价函数</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBELF">正则化线性回归</a></li>
</ul>
</li>
</ul>
</li>
<li>第四周<ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBBZe">神经网络引入</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBDHu">非线性假设</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCBsN4">神经网络和大脑</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCrZ1M">神经网络</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCrUfK">神经网络应用实例</a></li>
</ul>
</li>
<li>第五周<ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCr5m2">训练神经网络</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCrf4H">代价函数</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCriIb">反向传播(B-P)</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCr9Rc">反向传播算法的直观介绍</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCr0yH">BP算法</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCrHqO">神经网络实现自动驾驶</a></li>
</ul>
</li>
<li>第六周<ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCruh7">评价一个学习算法</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCr1gH">如何少走弯路？</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCrd7a">评估假设函数</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCruh7">多项式模型的选择以及训练集/验证集/测试集的划分</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCdL5Q">偏差VS方差</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCdL5Q">偏差VS方差</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCd6C0">正则化和偏差/方差</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCdo2l">学习曲线(Learning Curves)</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCdCvC">重新审视决定下一步做什么</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCd0fl">机器学习系统设计</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCd0fl">构建垃圾邮件分类器</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCdH6b">误差分析</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSh83NE">操作偏斜数据</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCdBSe">偏移类的错误度量</a></li>
<li><a target="_blank" rel="noopener" href="http://sina.lt/eXAz">查准率和召回率练习</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCgyhD">使用大数据集</a></li>
</ul>
</li>
<li>第七周<ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCg4WP">大间距分类 SVM</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCg4WP#优化目标">优化目标</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCg4WP#大间距的直觉">大间距的直觉</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCg4WP#大间距分类器背后的数学原理(选学">大间距分类器背后的数学原理(选学)</a>)</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCgJw1">核函数</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCgXmt">使用SVM</a></li>
</ul>
</li>
<li>第八周<ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCgKuS">聚类</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCgKuS#">无监督学习介绍</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCgKuS#K-Means算法">K-Means算法</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCgKuS#优化目标">优化目标</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCgKuS#随机初始化">随机初始化</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCgKuS#选择簇的数量">选择簇的数量</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCg8PK">PCA 降维</a></li>
</ul>
</li>
<li>第九周<ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCgubu">密度估计&amp;异常检测</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCgBQV">构建一个异常检测系统</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCgDCU">多元高斯分布（选学）</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCevr6">预测电影评分</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCevr6#预测电影评分">预测电影评分</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCevr6#协同过滤">协同过滤</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCevr6#低秩矩阵分解">低秩矩阵分解</a></li>
</ul>
</li>
</ul>
</li>
<li>第十周<ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCeLpk">大数据集梯度下降</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCeLpk#处理大数据的学习算法">处理大数据的学习算法</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCeLpk#随机梯度下降">随机梯度下降</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCeLpk#小批量梯度下降">小批量梯度下降</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCeLpk#随机梯度下降的收敛">随机梯度下降的收敛</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCeii5">高级主题</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCeii5#在线学习">在线学习</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCeii5#MapReduce和数据并行">Map Reduce 和数据并行</a></li>
</ul>
</li>
</ul>
</li>
<li>第十一周<ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCe9Bv">照片OCR</a><ul>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCe9Bv#问题描述和流水线（Pipeline）">问题描述和流水线（Pipeline）</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCe9Bv#滑动窗体">滑动窗体</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCe9Bv#获取大量数据和人工数据">获取大量数据和人工数据</a></li>
<li><a target="_blank" rel="noopener" href="http://t.cn/RSCe9Bv#上限分析：流水线上的下一步工作是什么">上限分析：流水线上的下一步工作是什么</a></li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="DannyLee"
      src="/uploads/avatar.jpg">
  <p class="site-author-name" itemprop="name">DannyLee</p>
  <div class="site-description" itemprop="description">愿你的努力终取得成果</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">134</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">DannyLee</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


</body>
</html>
